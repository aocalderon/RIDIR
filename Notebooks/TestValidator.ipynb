{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spark-stubs\n",
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   // Or use any other 2.x version here\n",
       "//import $ivy.`sh.almond::almond-spark:0.3\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.serializer.KryoSerializer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.storage.StorageLevel\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.datasyslab.geospark.enums.{GridType, IndexType}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.datasyslab.geospark.spatialOperator.JoinQuery\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.datasyslab.geospark.formatMapper.shapefileParser.ShapefileReader\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.JavaConverters._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@b9bffae\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\u001b[39m\n",
       "\u001b[36mappID\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"local-1555573836313\"\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.0` // Or use any other 2.x version here\n",
    "//import $ivy.`sh.almond::almond-spark:0.3\n",
    "import $ivy.`sh.almond::ammonite-spark:0.4.0`\n",
    "import $ivy.`org.datasyslab:geospark:1.2.0`\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "import org.apache.spark.serializer.KryoSerializer\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "import org.datasyslab.geospark.enums.{GridType, IndexType}\n",
    "import org.datasyslab.geospark.spatialOperator.JoinQuery\n",
    "import org.datasyslab.geospark.formatMapper.shapefileParser.ShapefileReader\n",
    "import scala.collection.JavaConverters._\n",
    "import java.io._\n",
    "\n",
    "import org.apache.spark.sql._\n",
    "\n",
    "val spark = AmmoniteSparkSession.builder()\n",
    "    .master(\"local[*]\").appName(\"Validator\")\n",
    "    .getOrCreate()\n",
    "import spark.implicits._\n",
    "val appID = spark.sparkContext.applicationId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mgeopandas\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [_c0: string, _c1: string ... 1 more field]\n",
       "\u001b[36mres1_1\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m3551L\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val geopandas = spark.read.option(\"header\", \"false\").option(\"delimiter\", \"\\t\").csv(\"/tmp/geopandas_test.tsv\").distinct()\n",
    "geopandas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mgeospark\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [_c0: string, _c1: string ... 1 more field]\n",
       "\u001b[36mres2_1\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m3551L\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val geospark = spark.read.option(\"header\", \"false\").option(\"delimiter\", \"\\t\").csv(\"/tmp/geospark_test.tsv\").distinct()\n",
    "geospark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------------------+\n",
      "|   s1|   t1|               area1|\n",
      "+-----+-----+--------------------+\n",
      "|29687|29717|1.614938295666146...|\n",
      "|29687|29717|1.85468660373974e-05|\n",
      "|29687|29760|3.21945507378614e-06|\n",
      "|29687|29768|9.815855407129531...|\n",
      "|29687|29776|0.001695638600911...|\n",
      "|29687|29776|2.906758136637987...|\n",
      "|29687|29788|8.682791137812463...|\n",
      "|29688|29688|1.760629337085522...|\n",
      "|29688|29688|9.143849252974824...|\n",
      "|29688|29691|0.002261802876580881|\n",
      "|29688|29691|8.325716966533636...|\n",
      "|29688|29694|3.280440986754484...|\n",
      "|29689|29688|3.204189723011541...|\n",
      "|29689|29689|5.355474031120661...|\n",
      "|29689|29694|0.010430529987157496|\n",
      "|29689|29694|1.551437897124588...|\n",
      "|29689|29694|8.83334773046166e-06|\n",
      "|29689|29765|3.343313379484152...|\n",
      "|29690|29688|0.006504662812249704|\n",
      "|29690|29691|2.011815797738191...|\n",
      "+-----+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mp\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [s1: string, t1: string ... 1 more field]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val p = geopandas.toDF(\"s1\", \"t1\", \"area1\").orderBy(\"s1\", \"t1\", \"area1\")\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------------------+\n",
      "|   s2|   t2|               area2|\n",
      "+-----+-----+--------------------+\n",
      "|29687|29717|1.614938295666146...|\n",
      "|29687|29717|1.85468660373974e-05|\n",
      "|29687|29760|3.21945507378614e-06|\n",
      "|29687|29768|9.815855407129531...|\n",
      "|29687|29776|0.001695638600911...|\n",
      "|29687|29776|2.906758136637987...|\n",
      "|29687|29788|8.682791137812463...|\n",
      "|29688|29688|1.760629337085522...|\n",
      "|29688|29688|9.143849252974824...|\n",
      "|29688|29691|0.002261802876580881|\n",
      "|29688|29691|8.325716966533636...|\n",
      "|29688|29694|3.280440986754484...|\n",
      "|29689|29688|3.204189723011541...|\n",
      "|29689|29689|5.355474031120661...|\n",
      "|29689|29694|0.010430529987157496|\n",
      "|29689|29694|1.551437897124588...|\n",
      "|29689|29694|8.83334773046166e-06|\n",
      "|29689|29765|3.343313379484152...|\n",
      "|29690|29688|0.006504662812249704|\n",
      "|29690|29691|2.011815797738191...|\n",
      "+-----+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36ms\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [s2: string, t2: string ... 1 more field]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val s = geopandas.toDF(\"s2\", \"t2\", \"area2\").orderBy(\"s2\", \"t2\",\"area2\")\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36ma\u001b[39m: \u001b[32mRDD\u001b[39m[(\u001b[32mDouble\u001b[39m, \u001b[32mDouble\u001b[39m)] = ZippedPartitionsRDD2[262] at zip at cmd22.sc:1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val a = p.select(\"area1\").map(_.getString(0).toDouble).rdd.zip(s.select(\"area2\").map(_.getString(0).toDouble).rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.mllib.evaluation.RegressionMetrics\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.rdd.RDD\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-mllib:2.4.0`\n",
    "import org.apache.spark.mllib.evaluation.RegressionMetrics\n",
    "import org.apache.spark.rdd.RDD\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.6149382956661462E-6,1.6149382956661462E-6)\n",
      "(1.85468660373974E-5,1.85468660373974E-5)\n",
      "(3.21945507378614E-6,3.21945507378614E-6)\n",
      "(9.815855407129531E-6,9.815855407129531E-6)\n",
      "(0.0016956386009116466,0.0016956386009116466)\n",
      "(2.906758136637987E-6,2.906758136637987E-6)\n",
      "(8.682791137812463E-6,8.682791137812463E-6)\n",
      "(1.760629337085522E-5,1.760629337085522E-5)\n",
      "(9.143849252974824E-6,9.143849252974824E-6)\n",
      "(0.002261802876580881,0.002261802876580881)\n",
      "(8.325716966533636E-7,8.325716966533636E-7)\n",
      "(3.280440986754484E-7,3.280440986754484E-7)\n",
      "(3.2041897230115413E-5,3.2041897230115413E-5)\n",
      "(5.355474031120661E-6,5.355474031120661E-6)\n",
      "(0.010430529987157496,0.010430529987157496)\n",
      "(1.5514378971245882E-5,1.5514378971245882E-5)\n",
      "(8.83334773046166E-6,8.83334773046166E-6)\n",
      "(3.3433133794841528E-6,3.3433133794841528E-6)\n",
      "(0.006504662812249704,0.006504662812249704)\n",
      "(2.0118157977381915E-5,2.0118157977381915E-5)\n"
     ]
    }
   ],
   "source": [
    "a.take(5).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mreg\u001b[39m: \u001b[32mRegressionMetrics\u001b[39m = org.apache.spark.mllib.evaluation.RegressionMetrics@47b862a2\n",
       "\u001b[36mres27_1\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m1.0\u001b[39m\n",
       "\u001b[36mres27_2\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.0\u001b[39m\n",
       "\u001b[36mres27_3\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.0\u001b[39m\n",
       "\u001b[36mres27_4\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.0\u001b[39m"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val reg = new RegressionMetrics(a)\n",
    "reg.r2\n",
    "reg.meanAbsoluteError\n",
    "reg.meanSquaredError\n",
    "reg.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
