#!/bin/bash

NPARTITIONS=$1

HDFS_PATH=$2
INPUT1=$HDFS_PATH/A.wkt
INPUT2=$HDFS_PATH/B.wkt
LOCAL_PATH=$HOME/RIDIR/local_path/$HDFS_PATH

TOLERANCE=$3

#INPUT1=Test/S2/A.wkt
#INPUT2=Test/S2/B.wkt

#INPUT1=gadm/raw/level0
#INPUT2=gadm/raw/level1
#INPUT1=NC/A.wkt
#INPUT2=NC/B.wkt
#INPUT1=CA/CGAL2/A.wkt
#INPUT2=CA/CGAL2/B.wkt
#INPUT1=TX/CGAL/A.wkt
#INPUT2=TX/CGAL/B.wkt
#INPUT1=Test/S/A.wkt
#INPUT2=Test/S/B.wkt

LOCAL_DIR="$LOCAL_PATH/P$NPARTITIONS"
echo "Checking $LOCAL_DIR ..."
[ ! -d $LOCAL_DIR ] && mkdir $LOCAL_DIR

EXECUTORS=12
CORES=9
DMEMORY=12g
EMEMORY=30g
SPARK_JARS=$HOME/Spark/2.4/jars/
JAR=$HOME/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar
CLASS="edu.ucr.dblab.sdcel.QuadtreeGenerator"
LOG_FILE=$HOME/Spark/2.4/conf/log4j.properties
MASTER=local[10]

spark-submit \
    --master $MASTER \
    --jars $HOME/Spark/2.4/jars/geospark-1.2.0.jar,$HOME/Spark/2.4/jars/scallop_2.11-3.1.5.jar \
    --files $LOG_FILE \
    --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:$LOG_FILE \
    --jars ${SPARK_JARS}geospark-1.2.0.jar,${SPARK_JARS}scallop_2.11-3.1.5.jar,${SPARK_JARS}spark-measure_2.11-0.16.jar \
    --master $MASTER --deploy-mode client \
    --num-executors $EXECUTORS --executor-cores $CORES --executor-memory $EMEMORY --driver-memory $DMEMORY \
    --class $CLASS $JAR \
    --input1 $INPUT1 \
    --input2 $INPUT2 \
    --qpath $LOCAL_DIR/quadtree.wkt \
    --epath $LOCAL_DIR/boundary.wkt \
    --partitions $NPARTITIONS \
    --tolerance $TOLERANCE
