hdfs dfs -rm -f -r Census/S/
hdfs dfs -mkdir Census/S/
hdfs dfs -mkdir Census/S/AL/
hdfs dfs -put ~/Datasets/Census/AL/AL2000.wkt Census/S/AL/A.wkt
hdfs dfs -put ~/Datasets/Census/AL/AL2010.wkt Census/S/AL/B.wkt
./QuadPart -d Census/S/AL -p 511 -t 1e-3
DATASET    = Census/S/AL
TOLERANCE  = 1e-3
PARTITIONS = 511
./QuadPlusPart 511 Census/S/AL 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/AL/P511 ...
2022-03-20 22:23:54,650|2828|local-1647840232987|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AL/A.wkt --input2 Census/S/AL/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/AL/P511/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/AL/P511/boundary.wkt --partitions 511 --tolerance 1e-3
2022-03-20 22:23:54,651|2829|local-1647840232987|INFO|scale=1000.0
2022-03-20 22:23:54,659|2837|local-1647840232987|TIME|Start
2022-03-20 22:24:02,774|10952|local-1647840232987|INFO|edgesA=986914
2022-03-20 22:24:04,642|12820|local-1647840232987|INFO|edgesB=1046066
2022-03-20 22:24:05,099|13277|local-1647840232987|TIME|Read
2022-03-20 22:24:05,099|13277|Partition by number (511)
2022-03-20 22:24:05,103|13281|Fraction: 0.010305178836959623
2022-03-20 22:24:05,446|13624|local-1647840232987|INFO|partitions=1333
2022-03-20 22:24:05,447|13625|local-1647840232987|TIME|Partition
2022-03-20 22:24:05,450|13628|Saved /home/acald013/RIDIR/local_path/Census/S/AL/P511/boundary.wkt in 0.00s [1 records].
2022-03-20 22:24:05,564|13742|Saved /home/acald013/RIDIR/local_path/Census/S/AL/P511/quadtree.wkt in 0.00s [1333 records].
2022-03-20 22:24:05,726|13904|local-1647840232987|TIME|Close
Partitioning edges...
rm -f -r Census/S/AL/P511/edgesA/
rm -f -r Census/S/AL/P511/edgesB/
2022-03-20 22:24:22,562|13385|application_1639015019875_1290|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AL/A.wkt --input2 Census/S/AL/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/AL/P511/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/AL/P511/boundary.wkt --apath Census/S/AL/P511/edgesA --bpath Census/S/AL/P511/edgesB --tolerance 1e-3 --save
2022-03-20 22:24:22,562|13385|application_1639015019875_1290|INFO|scale=1000.0
2022-03-20 22:24:22,575|13398|application_1639015019875_1290|TIME|Start
2022-03-20 22:24:32,259|23082|application_1639015019875_1290|INFO|edgesA=986914
2022-03-20 22:24:38,170|28993|application_1639015019875_1290|INFO|edgesB=1046066
2022-03-20 22:24:38,179|29002|application_1639015019875_1290|TIME|Read
2022-03-20 22:24:53,883|44706|application_1639015019875_1290|TIME|Saving
./Perf -d Census/S/AL -p 511 -t 1e-3 -n 1
DATASET    = Census/S/AL
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 511
Run 1 ./sdcel2_debug Census/S/AL/P511 /home/acald013/RIDIR/local_path/Census/S/AL/P511/ 1e-3 "511_Census/S/AL_1e-3_1"
2022-03-20 22:25:11,152|13628|application_1639015019875_1291|13883|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AL/P511/edgesA --input2 Census/S/AL/P511/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/AL/P511//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/AL/P511//boundary.wkt --tolerance 1e-3 --qtag 511_Census/S/AL_1e-3_1 --debug --local
2022-03-20 22:25:11,261|13737|application_1639015019875_1291|INFO|scale=1000.0
2022-03-20 22:25:11,381|13857|Saved /tmp/edgesCells_511.wkt in 0.00s [1333 records].
2022-03-20 22:25:11,381|13857|application_1639015019875_1291|INFO|npartitions=1333
2022-03-20 22:25:11,381|13857|application_1639015019875_1291|229|TIME|start|511_Census/S/AL_1e-3_1
2022-03-20 22:25:25,033|27509|application_1639015019875_1291|INFO|nEdgesA=994131
2022-03-20 22:25:28,458|30934|application_1639015019875_1291|INFO|nEdgesB=1053567
2022-03-20 22:25:28,458|30934|application_1639015019875_1291|17077|TIME|read|511_Census/S/AL_1e-3_1
2022-03-20 22:25:31,397|33873|application_1639015019875_1291|2939|TIME|layer1S|511_Census/S/AL_1e-3_1
2022-03-20 22:25:33,304|35780|Saved /tmp/edgesFAC.wkt in 0.15s [5947 records].
2022-03-20 22:25:36,115|38591|application_1639015019875_1291|4718|TIME|layer2S|511_Census/S/AL_1e-3_1
2022-03-20 22:25:38,294|40770|Saved /tmp/edgesFBC.wkt in 0.20s [6189 records].
2022-03-20 22:26:11,924|74400|Saved /tmp/edgesS.wkt in 0.23s [15019 records].
2022-03-20 22:26:13,906|76382|application_1639015019875_1291|37791|TIME|overlayS|511_Census/S/AL_1e-3_1
2022-03-20 22:26:15,163|77639|Saved /tmp/edgesFE.wkt in 0.26s [2569 records].
2022-03-20 22:26:15,163|77639|application_1639015019875_1291|1257|TIME|end|511_Census/S/AL_1e-3_1
hdfs dfs -mkdir Census/S/AK/
mkdir: `Census/S/AK': File exists
hdfs dfs -put ~/Datasets/Census/AK/AK2000.wkt Census/S/AK/A.wkt
put: `Census/S/AK/A.wkt': File exists
hdfs dfs -put ~/Datasets/Census/AK/AK2010.wkt Census/S/AK/B.wkt
put: `Census/S/AK/B.wkt': File exists
./QuadPart -d Census/S/AK -p 144 -t 1e-3
DATASET    = Census/S/AK
TOLERANCE  = 1e-3
PARTITIONS = 144
./QuadPlusPart 144 Census/S/AK 1e-3
Making folders...
mkdir: `Census/S/AK/P144': File exists
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/AK/P144 ...
2022-03-20 22:26:33,175|2704|local-1647840391591|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AK/A.wkt --input2 Census/S/AK/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/AK/P144/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/AK/P144/boundary.wkt --partitions 144 --tolerance 1e-3
2022-03-20 22:26:33,176|2705|local-1647840391591|INFO|scale=1000.0
2022-03-20 22:26:33,185|2714|local-1647840391591|TIME|Start
2022-03-20 22:26:40,526|10055|local-1647840391591|INFO|edgesA=294765
2022-03-20 22:26:41,834|11363|local-1647840391591|INFO|edgesB=295539
2022-03-20 22:26:42,035|11564|local-1647840391591|TIME|Read
2022-03-20 22:26:42,035|11564|Partition by number (144)
2022-03-20 22:26:42,041|11570|Fraction: 0.01057436897309469
2022-03-20 22:26:42,686|12215|local-1647840391591|INFO|partitions=532
2022-03-20 22:26:42,686|12215|local-1647840391591|TIME|Partition
2022-03-20 22:26:42,691|12220|Saved /home/acald013/RIDIR/local_path/Census/S/AK/P144/boundary.wkt in 0.00s [1 records].
2022-03-20 22:26:42,756|12285|Saved /home/acald013/RIDIR/local_path/Census/S/AK/P144/quadtree.wkt in 0.00s [532 records].
2022-03-20 22:26:42,896|12425|local-1647840391591|TIME|Close
Partitioning edges...
rm -f -r Census/S/AK/P144/edgesA/
rm -f -r Census/S/AK/P144/edgesB/
2022-03-20 22:26:59,855|13705|application_1639015019875_1292|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AK/A.wkt --input2 Census/S/AK/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/AK/P144/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/AK/P144/boundary.wkt --apath Census/S/AK/P144/edgesA --bpath Census/S/AK/P144/edgesB --tolerance 1e-3 --save
2022-03-20 22:26:59,855|13705|application_1639015019875_1292|INFO|scale=1000.0
2022-03-20 22:26:59,869|13719|application_1639015019875_1292|TIME|Start
2022-03-20 22:27:09,248|23098|application_1639015019875_1292|INFO|edgesA=294765
2022-03-20 22:27:14,844|28694|application_1639015019875_1292|INFO|edgesB=295539
2022-03-20 22:27:14,853|28703|application_1639015019875_1292|TIME|Read
2022-03-20 22:27:26,141|39991|application_1639015019875_1292|TIME|Saving
./Perf -d Census/S/AK -p 144 -t 1e-3 -n 1
DATASET    = Census/S/AK
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 144
Run 1 ./sdcel2_debug Census/S/AK/P144 /home/acald013/RIDIR/local_path/Census/S/AK/P144/ 1e-3 "144_Census/S/AK_1e-3_1"
2022-03-20 22:27:43,946|14017|application_1639015019875_1293|14273|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AK/P144/edgesA --input2 Census/S/AK/P144/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/AK/P144//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/AK/P144//boundary.wkt --tolerance 1e-3 --qtag 144_Census/S/AK_1e-3_1 --debug --local
2022-03-20 22:27:44,029|14100|application_1639015019875_1293|INFO|scale=1000.0
2022-03-20 22:27:44,115|14186|Saved /tmp/edgesCells_144.wkt in 0.00s [532 records].
2022-03-20 22:27:44,116|14187|application_1639015019875_1293|INFO|npartitions=532
2022-03-20 22:27:44,116|14187|application_1639015019875_1293|170|TIME|start|144_Census/S/AK_1e-3_1
2022-03-20 22:27:55,182|25253|application_1639015019875_1293|INFO|nEdgesA=296525
2022-03-20 22:27:57,010|27081|application_1639015019875_1293|INFO|nEdgesB=297275
2022-03-20 22:27:57,010|27081|application_1639015019875_1293|12894|TIME|read|144_Census/S/AK_1e-3_1
2022-03-20 22:27:59,105|29176|application_1639015019875_1293|2095|TIME|layer1S|144_Census/S/AK_1e-3_1
2022-03-20 22:28:00,027|30098|Saved /tmp/edgesFAC.wkt in 0.06s [1569 records].
2022-03-20 22:28:01,243|31314|application_1639015019875_1293|2138|TIME|layer2S|144_Census/S/AK_1e-3_1
2022-03-20 22:28:02,177|32248|Saved /tmp/edgesFBC.wkt in 0.09s [1555 records].
2022-03-20 22:28:38,731|68802|Saved /tmp/edgesS.wkt in 0.10s [3262 records].
2022-03-20 22:28:40,305|70376|application_1639015019875_1293|39062|TIME|overlayS|144_Census/S/AK_1e-3_1
2022-03-20 22:28:40,669|70740|Saved /tmp/edgesFE.wkt in 0.08s [310 records].
2022-03-20 22:28:40,669|70740|application_1639015019875_1293|364|TIME|end|144_Census/S/AK_1e-3_1
hdfs dfs -mkdir Census/S/AZ/
hdfs dfs -put ~/Datasets/Census/AZ/AZ2000.wkt Census/S/AZ/A.wkt
hdfs dfs -put ~/Datasets/Census/AZ/AZ2010.wkt Census/S/AZ/B.wkt
./QuadPart -d Census/S/AZ -p 364 -t 1e-3
DATASET    = Census/S/AZ
TOLERANCE  = 1e-3
PARTITIONS = 364
./QuadPlusPart 364 Census/S/AZ 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/AZ/P364 ...
2022-03-20 22:29:00,952|2898|local-1647840539284|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AZ/A.wkt --input2 Census/S/AZ/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/AZ/P364/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/AZ/P364/boundary.wkt --partitions 364 --tolerance 1e-3
2022-03-20 22:29:00,952|2898|local-1647840539284|INFO|scale=1000.0
2022-03-20 22:29:00,961|2907|local-1647840539284|TIME|Start
2022-03-20 22:29:08,323|10269|local-1647840539284|INFO|edgesA=664194
2022-03-20 22:29:10,320|12266|local-1647840539284|INFO|edgesB=743496
2022-03-20 22:29:10,618|12564|local-1647840539284|TIME|Read
2022-03-20 22:29:10,619|12565|Partition by number (364)
2022-03-20 22:29:10,623|12569|Fraction: 0.010367693458612095
2022-03-20 22:29:11,032|12978|local-1647840539284|INFO|partitions=1051
2022-03-20 22:29:11,032|12978|local-1647840539284|TIME|Partition
2022-03-20 22:29:11,036|12982|Saved /home/acald013/RIDIR/local_path/Census/S/AZ/P364/boundary.wkt in 0.00s [1 records].
2022-03-20 22:29:11,159|13105|Saved /home/acald013/RIDIR/local_path/Census/S/AZ/P364/quadtree.wkt in 0.00s [1051 records].
2022-03-20 22:29:11,321|13267|local-1647840539284|TIME|Close
Partitioning edges...
rm -f -r Census/S/AZ/P364/edgesA/
rm -f -r Census/S/AZ/P364/edgesB/
2022-03-20 22:29:28,457|13751|application_1639015019875_1294|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AZ/A.wkt --input2 Census/S/AZ/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/AZ/P364/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/AZ/P364/boundary.wkt --apath Census/S/AZ/P364/edgesA --bpath Census/S/AZ/P364/edgesB --tolerance 1e-3 --save
2022-03-20 22:29:28,457|13751|application_1639015019875_1294|INFO|scale=1000.0
2022-03-20 22:29:28,470|13764|application_1639015019875_1294|TIME|Start
2022-03-20 22:29:37,968|23262|application_1639015019875_1294|INFO|edgesA=664194
2022-03-20 22:29:43,751|29045|application_1639015019875_1294|INFO|edgesB=743496
2022-03-20 22:29:43,761|29055|application_1639015019875_1294|TIME|Read
2022-03-20 22:29:56,802|42096|application_1639015019875_1294|TIME|Saving
./Perf -d Census/S/AZ -p 364 -t 1e-3 -n 1
DATASET    = Census/S/AZ
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 364
Run 1 ./sdcel2_debug Census/S/AZ/P364 /home/acald013/RIDIR/local_path/Census/S/AZ/P364/ 1e-3 "364_Census/S/AZ_1e-3_1"
2022-03-20 22:30:13,994|13452|application_1639015019875_1295|13716|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AZ/P364/edgesA --input2 Census/S/AZ/P364/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/AZ/P364//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/AZ/P364//boundary.wkt --tolerance 1e-3 --qtag 364_Census/S/AZ_1e-3_1 --debug --local
2022-03-20 22:30:14,099|13557|application_1639015019875_1295|INFO|scale=1000.0
2022-03-20 22:30:14,205|13663|Saved /tmp/edgesCells_364.wkt in 0.00s [1051 records].
2022-03-20 22:30:14,206|13664|application_1639015019875_1295|INFO|npartitions=1051
2022-03-20 22:30:14,206|13664|application_1639015019875_1295|212|TIME|start|364_Census/S/AZ_1e-3_1
2022-03-20 22:30:27,339|26797|application_1639015019875_1295|INFO|nEdgesA=668973
2022-03-20 22:30:30,266|29724|application_1639015019875_1295|INFO|nEdgesB=748853
2022-03-20 22:30:30,267|29725|application_1639015019875_1295|16061|TIME|read|364_Census/S/AZ_1e-3_1
2022-03-20 22:30:32,963|32421|application_1639015019875_1295|2696|TIME|layer1S|364_Census/S/AZ_1e-3_1
2022-03-20 22:30:34,346|33804|Saved /tmp/edgesFAC.wkt in 0.10s [4498 records].
2022-03-20 22:30:36,065|35523|application_1639015019875_1295|3102|TIME|layer2S|364_Census/S/AZ_1e-3_1
2022-03-20 22:30:37,732|37190|Saved /tmp/edgesFBC.wkt in 0.20s [5195 records].
2022-03-20 22:31:03,461|62919|Saved /tmp/edgesS.wkt in 0.20s [10960 records].
2022-03-20 22:31:05,018|64476|application_1639015019875_1295|28953|TIME|overlayS|364_Census/S/AZ_1e-3_1
2022-03-20 22:31:05,706|65164|Saved /tmp/edgesFE.wkt in 0.15s [1971 records].
2022-03-20 22:31:05,706|65164|application_1639015019875_1295|688|TIME|end|364_Census/S/AZ_1e-3_1
hdfs dfs -mkdir Census/S/AR/
hdfs dfs -put ~/Datasets/Census/AR/AR2000.wkt Census/S/AR/A.wkt
hdfs dfs -put ~/Datasets/Census/AR/AR2010.wkt Census/S/AR/B.wkt
./QuadPart -d Census/S/AR -p 429 -t 1e-3
DATASET    = Census/S/AR
TOLERANCE  = 1e-3
PARTITIONS = 429
./QuadPlusPart 429 Census/S/AR 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/AR/P429 ...
2022-03-20 22:31:25,596|2932|local-1647840683924|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AR/A.wkt --input2 Census/S/AR/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/AR/P429/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/AR/P429/boundary.wkt --partitions 429 --tolerance 1e-3
2022-03-20 22:31:25,597|2933|local-1647840683924|INFO|scale=1000.0
2022-03-20 22:31:25,606|2942|local-1647840683924|TIME|Start
2022-03-20 22:31:33,874|11210|local-1647840683924|INFO|edgesA=854578
2022-03-20 22:31:35,544|12880|local-1647840683924|INFO|edgesB=878852
2022-03-20 22:31:35,829|13165|local-1647840683924|TIME|Read
2022-03-20 22:31:35,829|13165|Partition by number (429)
2022-03-20 22:31:35,833|13169|Fraction: 0.010331167324434955
2022-03-20 22:31:36,301|13637|local-1647840683924|INFO|partitions=1135
2022-03-20 22:31:36,301|13637|local-1647840683924|TIME|Partition
2022-03-20 22:31:36,305|13641|Saved /home/acald013/RIDIR/local_path/Census/S/AR/P429/boundary.wkt in 0.00s [1 records].
2022-03-20 22:31:36,413|13749|Saved /home/acald013/RIDIR/local_path/Census/S/AR/P429/quadtree.wkt in 0.00s [1135 records].
2022-03-20 22:31:36,576|13912|local-1647840683924|TIME|Close
Partitioning edges...
rm -f -r Census/S/AR/P429/edgesA/
rm -f -r Census/S/AR/P429/edgesB/
2022-03-20 22:31:53,892|13852|application_1639015019875_1296|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AR/A.wkt --input2 Census/S/AR/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/AR/P429/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/AR/P429/boundary.wkt --apath Census/S/AR/P429/edgesA --bpath Census/S/AR/P429/edgesB --tolerance 1e-3 --save
2022-03-20 22:31:53,893|13853|application_1639015019875_1296|INFO|scale=1000.0
2022-03-20 22:31:53,906|13866|application_1639015019875_1296|TIME|Start
2022-03-20 22:32:03,457|23417|application_1639015019875_1296|INFO|edgesA=854578
2022-03-20 22:32:09,349|29309|application_1639015019875_1296|INFO|edgesB=878852
2022-03-20 22:32:09,361|29321|application_1639015019875_1296|TIME|Read
2022-03-20 22:32:24,324|44284|application_1639015019875_1296|TIME|Saving
./Perf -d Census/S/AR -p 429 -t 1e-3 -n 1
DATASET    = Census/S/AR
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 429
Run 1 ./sdcel2_debug Census/S/AR/P429 /home/acald013/RIDIR/local_path/Census/S/AR/P429/ 1e-3 "429_Census/S/AR_1e-3_1"
2022-03-20 22:32:41,488|13391|application_1639015019875_1297|13636|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AR/P429/edgesA --input2 Census/S/AR/P429/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/AR/P429//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/AR/P429//boundary.wkt --tolerance 1e-3 --qtag 429_Census/S/AR_1e-3_1 --debug --local
2022-03-20 22:32:41,602|13505|application_1639015019875_1297|INFO|scale=1000.0
2022-03-20 22:32:41,710|13613|Saved /tmp/edgesCells_429.wkt in 0.00s [1135 records].
2022-03-20 22:32:41,710|13613|application_1639015019875_1297|INFO|npartitions=1135
2022-03-20 22:32:41,711|13614|application_1639015019875_1297|223|TIME|start|429_Census/S/AR_1e-3_1
2022-03-20 22:32:54,456|26359|application_1639015019875_1297|INFO|nEdgesA=859695
2022-03-20 22:32:57,499|29402|application_1639015019875_1297|INFO|nEdgesB=884111
2022-03-20 22:32:57,499|29402|application_1639015019875_1297|15788|TIME|read|429_Census/S/AR_1e-3_1
2022-03-20 22:33:00,320|32223|application_1639015019875_1297|2821|TIME|layer1S|429_Census/S/AR_1e-3_1
2022-03-20 22:33:02,022|33925|Saved /tmp/edgesFAC.wkt in 0.18s [4244 records].
2022-03-20 22:33:04,083|35986|application_1639015019875_1297|3763|TIME|layer2S|429_Census/S/AR_1e-3_1
2022-03-20 22:33:05,803|37706|Saved /tmp/edgesFBC.wkt in 0.27s [4375 records].
2022-03-20 22:33:38,814|70717|Saved /tmp/edgesS.wkt in 0.20s [9568 records].
2022-03-20 22:33:40,838|72741|application_1639015019875_1297|36755|TIME|overlayS|429_Census/S/AR_1e-3_1
2022-03-20 22:33:41,637|73540|Saved /tmp/edgesFE.wkt in 0.21s [912 records].
2022-03-20 22:33:41,637|73540|application_1639015019875_1297|799|TIME|end|429_Census/S/AR_1e-3_1
hdfs dfs -mkdir Census/S/CA/
hdfs dfs -put ~/Datasets/Census/CA/CA2000.wkt Census/S/CA/A.wkt
hdfs dfs -put ~/Datasets/Census/CA/CA2010.wkt Census/S/CA/B.wkt
./QuadPart -d Census/S/CA -p 1432 -t 1e-3
DATASET    = Census/S/CA
TOLERANCE  = 1e-3
PARTITIONS = 1432
./QuadPlusPart 1432 Census/S/CA 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/CA/P1432 ...
2022-03-20 22:34:04,609|2781|local-1647840842981|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/CA/A.wkt --input2 Census/S/CA/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/CA/P1432/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/CA/P1432/boundary.wkt --partitions 1432 --tolerance 1e-3
2022-03-20 22:34:04,610|2782|local-1647840842981|INFO|scale=1000.0
2022-03-20 22:34:04,619|2791|local-1647840842981|TIME|Start
2022-03-20 22:34:15,357|13529|local-1647840842981|INFO|edgesA=2711639
2022-03-20 22:34:23,239|21411|local-1647840842981|INFO|edgesB=2917450
2022-03-20 22:34:23,634|21806|local-1647840842981|TIME|Read
2022-03-20 22:34:23,634|21806|Partition by number (1432)
2022-03-20 22:34:23,639|21811|Fraction: 0.010182382072833876
2022-03-20 22:34:24,274|22446|local-1647840842981|INFO|partitions=3649
2022-03-20 22:34:24,275|22447|local-1647840842981|TIME|Partition
2022-03-20 22:34:24,278|22450|Saved /home/acald013/RIDIR/local_path/Census/S/CA/P1432/boundary.wkt in 0.00s [1 records].
2022-03-20 22:34:24,455|22627|Saved /home/acald013/RIDIR/local_path/Census/S/CA/P1432/quadtree.wkt in 0.01s [3649 records].
2022-03-20 22:34:24,681|22853|local-1647840842981|TIME|Close
Partitioning edges...
rm -f -r Census/S/CA/P1432/edgesA/
rm -f -r Census/S/CA/P1432/edgesB/
2022-03-20 22:34:42,349|13706|application_1639015019875_1298|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/CA/A.wkt --input2 Census/S/CA/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/CA/P1432/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/CA/P1432/boundary.wkt --apath Census/S/CA/P1432/edgesA --bpath Census/S/CA/P1432/edgesB --tolerance 1e-3 --save
2022-03-20 22:34:42,350|13707|application_1639015019875_1298|INFO|scale=1000.0
2022-03-20 22:34:42,363|13720|application_1639015019875_1298|TIME|Start
2022-03-20 22:34:52,640|23997|application_1639015019875_1298|INFO|edgesA=2711639
2022-03-20 22:35:00,320|31677|application_1639015019875_1298|INFO|edgesB=2917450
2022-03-20 22:35:00,332|31689|application_1639015019875_1298|TIME|Read
2022-03-20 22:35:35,531|66888|application_1639015019875_1298|TIME|Saving
./Perf -d Census/S/CA -p 1432 -t 1e-3 -n 1
DATASET    = Census/S/CA
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 1432
Run 1 ./sdcel2_debug Census/S/CA/P1432 /home/acald013/RIDIR/local_path/Census/S/CA/P1432/ 1e-3 "1432_Census/S/CA_1e-3_1"
2022-03-20 22:35:53,181|13733|application_1639015019875_1299|13981|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/CA/P1432/edgesA --input2 Census/S/CA/P1432/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/CA/P1432//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/CA/P1432//boundary.wkt --tolerance 1e-3 --qtag 1432_Census/S/CA_1e-3_1 --debug --local
2022-03-20 22:35:53,330|13882|application_1639015019875_1299|INFO|scale=1000.0
2022-03-20 22:35:53,537|14089|Saved /tmp/edgesCells_1432.wkt in 0.01s [3649 records].
2022-03-20 22:35:53,538|14090|application_1639015019875_1299|INFO|npartitions=3649
2022-03-20 22:35:53,538|14090|application_1639015019875_1299|357|TIME|start|1432_Census/S/CA_1e-3_1
2022-03-20 22:36:11,489|32041|application_1639015019875_1299|INFO|nEdgesA=2735505
2022-03-20 22:36:19,979|40531|application_1639015019875_1299|INFO|nEdgesB=2942658
2022-03-20 22:36:19,979|40531|application_1639015019875_1299|26441|TIME|read|1432_Census/S/CA_1e-3_1
2022-03-20 22:36:27,390|47942|application_1639015019875_1299|7411|TIME|layer1S|1432_Census/S/CA_1e-3_1
2022-03-20 22:36:32,919|53471|Saved /tmp/edgesFAC.wkt in 0.60s [22623 records].
2022-03-20 22:36:38,757|59309|application_1639015019875_1299|11367|TIME|layer2S|1432_Census/S/CA_1e-3_1
2022-03-20 22:36:45,102|65654|Saved /tmp/edgesFBC.wkt in 0.63s [24226 records].
2022-03-20 22:37:32,671|113223|Saved /tmp/edgesS.wkt in 0.69s [53956 records].
2022-03-20 22:37:37,473|118025|application_1639015019875_1299|58716|TIME|overlayS|1432_Census/S/CA_1e-3_1
2022-03-20 22:37:39,943|120495|Saved /tmp/edgesFE.wkt in 0.77s [12436 records].
2022-03-20 22:37:39,943|120495|application_1639015019875_1299|2470|TIME|end|1432_Census/S/CA_1e-3_1
hdfs dfs -mkdir Census/S/CO/
hdfs dfs -put ~/Datasets/Census/CO/CO2000.wkt Census/S/CO/A.wkt
hdfs dfs -put ~/Datasets/Census/CO/CO2010.wkt Census/S/CO/B.wkt
./QuadPart -d Census/S/CO -p 367 -t 1e-3
DATASET    = Census/S/CO
TOLERANCE  = 1e-3
PARTITIONS = 367
./QuadPlusPart 367 Census/S/CO 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/CO/P367 ...
2022-03-20 22:38:00,844|2997|local-1647841079050|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/CO/A.wkt --input2 Census/S/CO/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/CO/P367/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/CO/P367/boundary.wkt --partitions 367 --tolerance 1e-3
2022-03-20 22:38:00,844|2997|local-1647841079050|INFO|scale=1000.0
2022-03-20 22:38:00,853|3006|local-1647841079050|TIME|Start
2022-03-20 22:38:08,626|10779|local-1647841079050|INFO|edgesA=713171
2022-03-20 22:38:10,293|12446|local-1647841079050|INFO|edgesB=750511
2022-03-20 22:38:10,520|12673|local-1647841079050|TIME|Read
2022-03-20 22:38:10,521|12674|Partition by number (367)
2022-03-20 22:38:10,525|12678|Fraction: 0.010360533993229948
2022-03-20 22:38:11,036|13189|local-1647841079050|INFO|partitions=988
2022-03-20 22:38:11,037|13190|local-1647841079050|TIME|Partition
2022-03-20 22:38:11,041|13194|Saved /home/acald013/RIDIR/local_path/Census/S/CO/P367/boundary.wkt in 0.00s [1 records].
2022-03-20 22:38:11,135|13288|Saved /home/acald013/RIDIR/local_path/Census/S/CO/P367/quadtree.wkt in 0.00s [988 records].
2022-03-20 22:38:11,329|13482|local-1647841079050|TIME|Close
Partitioning edges...
rm -f -r Census/S/CO/P367/edgesA/
rm -f -r Census/S/CO/P367/edgesB/
2022-03-20 22:38:28,669|14003|application_1639015019875_1300|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/CO/A.wkt --input2 Census/S/CO/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/CO/P367/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/CO/P367/boundary.wkt --apath Census/S/CO/P367/edgesA --bpath Census/S/CO/P367/edgesB --tolerance 1e-3 --save
2022-03-20 22:38:28,669|14003|application_1639015019875_1300|INFO|scale=1000.0
2022-03-20 22:38:28,682|14016|application_1639015019875_1300|TIME|Start
2022-03-20 22:38:38,179|23513|application_1639015019875_1300|INFO|edgesA=713171
2022-03-20 22:38:43,927|29261|application_1639015019875_1300|INFO|edgesB=750511
2022-03-20 22:38:43,936|29270|application_1639015019875_1300|TIME|Read
2022-03-20 22:39:00,177|45511|application_1639015019875_1300|TIME|Saving
./Perf -d Census/S/CO -p 367 -t 1e-3 -n 1
DATASET    = Census/S/CO
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 367
Run 1 ./sdcel2_debug Census/S/CO/P367 /home/acald013/RIDIR/local_path/Census/S/CO/P367/ 1e-3 "367_Census/S/CO_1e-3_1"
2022-03-20 22:39:17,508|13600|application_1639015019875_1301|13851|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/CO/P367/edgesA --input2 Census/S/CO/P367/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/CO/P367//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/CO/P367//boundary.wkt --tolerance 1e-3 --qtag 367_Census/S/CO_1e-3_1 --debug --local
2022-03-20 22:39:17,607|13699|application_1639015019875_1301|INFO|scale=1000.0
2022-03-20 22:39:17,704|13796|Saved /tmp/edgesCells_367.wkt in 0.00s [988 records].
2022-03-20 22:39:17,705|13797|application_1639015019875_1301|INFO|npartitions=988
2022-03-20 22:39:17,705|13797|application_1639015019875_1301|197|TIME|start|367_Census/S/CO_1e-3_1
2022-03-20 22:39:30,472|26564|application_1639015019875_1301|INFO|nEdgesA=718108
2022-03-20 22:39:34,020|30112|application_1639015019875_1301|INFO|nEdgesB=755838
2022-03-20 22:39:34,020|30112|application_1639015019875_1301|16315|TIME|read|367_Census/S/CO_1e-3_1
2022-03-20 22:39:37,368|33460|application_1639015019875_1301|3348|TIME|layer1S|367_Census/S/CO_1e-3_1
2022-03-20 22:39:39,106|35198|Saved /tmp/edgesFAC.wkt in 0.20s [4523 records].
2022-03-20 22:39:40,950|37042|application_1639015019875_1301|3582|TIME|layer2S|367_Census/S/CO_1e-3_1
2022-03-20 22:39:42,756|38848|Saved /tmp/edgesFBC.wkt in 0.19s [4895 records].
2022-03-20 22:40:37,756|93848|Saved /tmp/edgesS.wkt in 0.21s [10618 records].
2022-03-20 22:40:39,864|95956|application_1639015019875_1301|58914|TIME|overlayS|367_Census/S/CO_1e-3_1
2022-03-20 22:40:40,850|96942|Saved /tmp/edgesFE.wkt in 0.17s [1763 records].
2022-03-20 22:40:40,850|96942|application_1639015019875_1301|986|TIME|end|367_Census/S/CO_1e-3_1
hdfs dfs -mkdir Census/S/CT/
hdfs dfs -put ~/Datasets/Census/CT/CT2000.wkt Census/S/CT/A.wkt
hdfs dfs -put ~/Datasets/Census/CT/CT2010.wkt Census/S/CT/B.wkt
./QuadPart -d Census/S/CT -p 127 -t 1e-3
DATASET    = Census/S/CT
TOLERANCE  = 1e-3
PARTITIONS = 127
./QuadPlusPart 127 Census/S/CT 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/CT/P127 ...
2022-03-20 22:41:00,543|2772|local-1647841258922|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/CT/A.wkt --input2 Census/S/CT/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/CT/P127/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/CT/P127/boundary.wkt --partitions 127 --tolerance 1e-3
2022-03-20 22:41:00,544|2773|local-1647841258922|INFO|scale=1000.0
2022-03-20 22:41:00,553|2782|local-1647841258922|TIME|Start
2022-03-20 22:41:07,896|10125|local-1647841258922|INFO|edgesA=258878
2022-03-20 22:41:09,192|11421|local-1647841258922|INFO|edgesB=260279
2022-03-20 22:41:09,394|11623|local-1647841258922|TIME|Read
2022-03-20 22:41:09,394|11623|Partition by number (127)
2022-03-20 22:41:09,398|11627|Fraction: 0.010612541385090114
2022-03-20 22:41:09,688|11917|local-1647841258922|INFO|partitions=328
2022-03-20 22:41:09,689|11918|local-1647841258922|TIME|Partition
2022-03-20 22:41:09,693|11922|Saved /home/acald013/RIDIR/local_path/Census/S/CT/P127/boundary.wkt in 0.00s [1 records].
2022-03-20 22:41:09,743|11972|Saved /home/acald013/RIDIR/local_path/Census/S/CT/P127/quadtree.wkt in 0.00s [328 records].
2022-03-20 22:41:09,900|12129|local-1647841258922|TIME|Close
Partitioning edges...
rm -f -r Census/S/CT/P127/edgesA/
rm -f -r Census/S/CT/P127/edgesB/
2022-03-20 22:41:26,905|13743|application_1639015019875_1302|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/CT/A.wkt --input2 Census/S/CT/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/CT/P127/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/CT/P127/boundary.wkt --apath Census/S/CT/P127/edgesA --bpath Census/S/CT/P127/edgesB --tolerance 1e-3 --save
2022-03-20 22:41:26,906|13744|application_1639015019875_1302|INFO|scale=1000.0
2022-03-20 22:41:26,918|13756|application_1639015019875_1302|TIME|Start
2022-03-20 22:41:36,040|22878|application_1639015019875_1302|INFO|edgesA=258878
2022-03-20 22:41:41,770|28608|application_1639015019875_1302|INFO|edgesB=260279
2022-03-20 22:41:41,779|28617|application_1639015019875_1302|TIME|Read
2022-03-20 22:41:50,818|37656|application_1639015019875_1302|TIME|Saving
./Perf -d Census/S/CT -p 127 -t 1e-3 -n 1
DATASET    = Census/S/CT
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 127
Run 1 ./sdcel2_debug Census/S/CT/P127 /home/acald013/RIDIR/local_path/Census/S/CT/P127/ 1e-3 "127_Census/S/CT_1e-3_1"
2022-03-20 22:42:10,585|16097|application_1639015019875_1303|16362|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/CT/P127/edgesA --input2 Census/S/CT/P127/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/CT/P127//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/CT/P127//boundary.wkt --tolerance 1e-3 --qtag 127_Census/S/CT_1e-3_1 --debug --local
2022-03-20 22:42:10,652|16164|application_1639015019875_1303|INFO|scale=1000.0
2022-03-20 22:42:10,711|16223|Saved /tmp/edgesCells_127.wkt in 0.00s [328 records].
2022-03-20 22:42:10,712|16224|application_1639015019875_1303|INFO|npartitions=328
2022-03-20 22:42:10,712|16224|application_1639015019875_1303|127|TIME|start|127_Census/S/CT_1e-3_1
2022-03-20 22:42:21,789|27301|application_1639015019875_1303|INFO|nEdgesA=261763
2022-03-20 22:42:23,431|28943|application_1639015019875_1303|INFO|nEdgesB=263192
2022-03-20 22:42:23,431|28943|application_1639015019875_1303|12719|TIME|read|127_Census/S/CT_1e-3_1
2022-03-20 22:42:25,105|30617|application_1639015019875_1303|1674|TIME|layer1S|127_Census/S/CT_1e-3_1
2022-03-20 22:42:25,975|31487|Saved /tmp/edgesFAC.wkt in 0.06s [2568 records].
2022-03-20 22:42:27,038|32550|application_1639015019875_1303|1933|TIME|layer2S|127_Census/S/CT_1e-3_1
2022-03-20 22:42:27,906|33418|Saved /tmp/edgesFBC.wkt in 0.06s [2591 records].
2022-03-20 22:42:47,262|52774|Saved /tmp/edgesS.wkt in 0.08s [5778 records].
2022-03-20 22:42:47,932|53444|application_1639015019875_1303|20894|TIME|overlayS|127_Census/S/CT_1e-3_1
2022-03-20 22:42:48,197|53709|Saved /tmp/edgesFE.wkt in 0.06s [1188 records].
2022-03-20 22:42:48,198|53710|application_1639015019875_1303|266|TIME|end|127_Census/S/CT_1e-3_1
hdfs dfs -mkdir Census/S/DE/
hdfs dfs -put ~/Datasets/Census/DE/DE2000.wkt Census/S/DE/A.wkt
hdfs dfs -put ~/Datasets/Census/DE/DE2010.wkt Census/S/DE/B.wkt
./QuadPart -d Census/S/DE -p 49 -t 1e-3
DATASET    = Census/S/DE
TOLERANCE  = 1e-3
PARTITIONS = 49
./QuadPlusPart 49 Census/S/DE 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/DE/P49 ...
2022-03-20 22:43:06,456|2772|local-1647841384850|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/DE/A.wkt --input2 Census/S/DE/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/DE/P49/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/DE/P49/boundary.wkt --partitions 49 --tolerance 1e-3
2022-03-20 22:43:06,456|2772|local-1647841384850|INFO|scale=1000.0
2022-03-20 22:43:06,465|2781|local-1647841384850|TIME|Start
2022-03-20 22:43:13,136|9452|local-1647841384850|INFO|edgesA=89009
2022-03-20 22:43:13,991|10307|local-1647841384850|INFO|edgesB=100357
2022-03-20 22:43:14,120|10436|local-1647841384850|TIME|Read
2022-03-20 22:43:14,120|10436|Partition by number (49)
2022-03-20 22:43:14,125|10441|Fraction: 0.011032462967072674
2022-03-20 22:43:14,273|10589|local-1647841384850|INFO|partitions=133
2022-03-20 22:43:14,274|10590|local-1647841384850|TIME|Partition
2022-03-20 22:43:14,278|10594|Saved /home/acald013/RIDIR/local_path/Census/S/DE/P49/boundary.wkt in 0.00s [1 records].
2022-03-20 22:43:14,308|10624|Saved /home/acald013/RIDIR/local_path/Census/S/DE/P49/quadtree.wkt in 0.00s [133 records].
2022-03-20 22:43:14,455|10771|local-1647841384850|TIME|Close
Partitioning edges...
rm -f -r Census/S/DE/P49/edgesA/
rm -f -r Census/S/DE/P49/edgesB/
2022-03-20 22:43:31,376|13663|application_1639015019875_1304|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/DE/A.wkt --input2 Census/S/DE/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/DE/P49/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/DE/P49/boundary.wkt --apath Census/S/DE/P49/edgesA --bpath Census/S/DE/P49/edgesB --tolerance 1e-3 --save
2022-03-20 22:43:31,377|13664|application_1639015019875_1304|INFO|scale=1000.0
2022-03-20 22:43:31,389|13676|application_1639015019875_1304|TIME|Start
2022-03-20 22:43:40,188|22475|application_1639015019875_1304|INFO|edgesA=89009
2022-03-20 22:43:45,487|27774|application_1639015019875_1304|INFO|edgesB=100357
2022-03-20 22:43:45,497|27784|application_1639015019875_1304|TIME|Read
2022-03-20 22:43:53,645|35932|application_1639015019875_1304|TIME|Saving
./Perf -d Census/S/DE -p 49 -t 1e-3 -n 1
DATASET    = Census/S/DE
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 49
Run 1 ./sdcel2_debug Census/S/DE/P49 /home/acald013/RIDIR/local_path/Census/S/DE/P49/ 1e-3 "49_Census/S/DE_1e-3_1"
2022-03-20 22:44:10,746|13402|application_1639015019875_1305|13641|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/DE/P49/edgesA --input2 Census/S/DE/P49/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/DE/P49//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/DE/P49//boundary.wkt --tolerance 1e-3 --qtag 49_Census/S/DE_1e-3_1 --debug --local
2022-03-20 22:44:10,809|13465|application_1639015019875_1305|INFO|scale=1000.0
2022-03-20 22:44:10,847|13503|Saved /tmp/edgesCells_49.wkt in 0.00s [133 records].
2022-03-20 22:44:10,847|13503|application_1639015019875_1305|INFO|npartitions=133
2022-03-20 22:44:10,847|13503|application_1639015019875_1305|101|TIME|start|49_Census/S/DE_1e-3_1
2022-03-20 22:44:20,907|23563|application_1639015019875_1305|INFO|nEdgesA=89835
2022-03-20 22:44:22,018|24674|application_1639015019875_1305|INFO|nEdgesB=101279
2022-03-20 22:44:22,018|24674|application_1639015019875_1305|11171|TIME|read|49_Census/S/DE_1e-3_1
2022-03-20 22:44:23,310|25966|application_1639015019875_1305|1292|TIME|layer1S|49_Census/S/DE_1e-3_1
2022-03-20 22:44:23,930|26586|Saved /tmp/edgesFAC.wkt in 0.02s [717 records].
2022-03-20 22:44:24,584|27240|application_1639015019875_1305|1274|TIME|layer2S|49_Census/S/DE_1e-3_1
2022-03-20 22:44:25,382|28038|Saved /tmp/edgesFBC.wkt in 0.19s [785 records].
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 18 (count at SDCEL2.scala:158) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867) 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:863) 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:677) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:109) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 	at java.lang.Thread.run(Thread.java:745) 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1348)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1869)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:158)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
hdfs dfs -mkdir Census/S/DC/
hdfs dfs -put ~/Datasets/Census/DC/DC2000.wkt Census/S/DC/A.wkt
hdfs dfs -put ~/Datasets/Census/DC/DC2010.wkt Census/S/DC/B.wkt
./QuadPart -d Census/S/DC -p 20 -t 1e-3
DATASET    = Census/S/DC
TOLERANCE  = 1e-3
PARTITIONS = 20
./QuadPlusPart 20 Census/S/DC 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/DC/P20 ...
2022-03-20 22:44:56,862|2767|local-1647841495245|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/DC/A.wkt --input2 Census/S/DC/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/DC/P20/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/DC/P20/boundary.wkt --partitions 20 --tolerance 1e-3
2022-03-20 22:44:56,863|2768|local-1647841495245|INFO|scale=1000.0
2022-03-20 22:44:56,872|2777|local-1647841495245|TIME|Start
2022-03-20 22:45:03,632|9537|local-1647841495245|INFO|edgesA=41328
2022-03-20 22:45:04,242|10147|local-1647841495245|INFO|edgesB=41150
2022-03-20 22:45:04,431|10336|local-1647841495245|TIME|Read
2022-03-20 22:45:04,431|10336|Partition by number (20)
2022-03-20 22:45:04,436|10341|Fraction: 0.011600132912955533
2022-03-20 22:45:04,564|10469|local-1647841495245|INFO|partitions=55
2022-03-20 22:45:04,564|10469|local-1647841495245|TIME|Partition
2022-03-20 22:45:04,569|10474|Saved /home/acald013/RIDIR/local_path/Census/S/DC/P20/boundary.wkt in 0.00s [1 records].
2022-03-20 22:45:04,587|10492|Saved /home/acald013/RIDIR/local_path/Census/S/DC/P20/quadtree.wkt in 0.00s [55 records].
2022-03-20 22:45:04,728|10633|local-1647841495245|TIME|Close
Partitioning edges...
rm -f -r Census/S/DC/P20/edgesA/
rm -f -r Census/S/DC/P20/edgesB/
2022-03-20 22:45:21,660|13704|application_1639015019875_1306|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/DC/A.wkt --input2 Census/S/DC/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/DC/P20/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/DC/P20/boundary.wkt --apath Census/S/DC/P20/edgesA --bpath Census/S/DC/P20/edgesB --tolerance 1e-3 --save
2022-03-20 22:45:21,661|13705|application_1639015019875_1306|INFO|scale=1000.0
2022-03-20 22:45:21,674|13718|application_1639015019875_1306|TIME|Start
2022-03-20 22:45:30,424|22468|application_1639015019875_1306|INFO|edgesA=41328
2022-03-20 22:45:35,397|27441|application_1639015019875_1306|INFO|edgesB=41150
2022-03-20 22:45:35,406|27450|application_1639015019875_1306|TIME|Read
2022-03-20 22:45:42,778|34822|application_1639015019875_1306|TIME|Saving
./Perf -d Census/S/DC -p 20 -t 1e-3 -n 1
DATASET    = Census/S/DC
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 20
Run 1 ./sdcel2_debug Census/S/DC/P20 /home/acald013/RIDIR/local_path/Census/S/DC/P20/ 1e-3 "20_Census/S/DC_1e-3_1"
2022-03-20 22:46:00,767|14314|application_1639015019875_1307|14570|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/DC/P20/edgesA --input2 Census/S/DC/P20/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/DC/P20//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/DC/P20//boundary.wkt --tolerance 1e-3 --qtag 20_Census/S/DC_1e-3_1 --debug --local
2022-03-20 22:46:00,822|14369|application_1639015019875_1307|INFO|scale=1000.0
2022-03-20 22:46:00,844|14391|Saved /tmp/edgesCells_20.wkt in 0.00s [55 records].
2022-03-20 22:46:00,845|14392|application_1639015019875_1307|INFO|npartitions=55
2022-03-20 22:46:00,845|14392|application_1639015019875_1307|78|TIME|start|20_Census/S/DC_1e-3_1
2022-03-20 22:46:10,313|23860|application_1639015019875_1307|INFO|nEdgesA=41817
2022-03-20 22:46:11,263|24810|application_1639015019875_1307|INFO|nEdgesB=41633
2022-03-20 22:46:11,263|24810|application_1639015019875_1307|10418|TIME|read|20_Census/S/DC_1e-3_1
2022-03-20 22:46:12,468|26015|application_1639015019875_1307|1205|TIME|layer1S|20_Census/S/DC_1e-3_1
2022-03-20 22:46:12,888|26435|Saved /tmp/edgesFAC.wkt in 0.01s [472 records].
2022-03-20 22:46:13,513|27060|application_1639015019875_1307|1045|TIME|layer2S|20_Census/S/DC_1e-3_1
2022-03-20 22:46:13,917|27464|Saved /tmp/edgesFBC.wkt in 0.01s [459 records].
2022-03-20 22:46:16,854|30401|Saved /tmp/edgesS.wkt in 0.01s [938 records].
2022-03-20 22:46:17,277|30824|application_1639015019875_1307|3764|TIME|overlayS|20_Census/S/DC_1e-3_1
2022-03-20 22:46:17,386|30933|Saved /tmp/edgesFE.wkt in 0.01s [200 records].
2022-03-20 22:46:17,386|30933|application_1639015019875_1307|109|TIME|end|20_Census/S/DC_1e-3_1
hdfs dfs -mkdir Census/S/FL/
hdfs dfs -put ~/Datasets/Census/FL/FL2000.wkt Census/S/FL/A.wkt
hdfs dfs -put ~/Datasets/Census/FL/FL2010.wkt Census/S/FL/B.wkt
./QuadPart -d Census/S/FL -p 598 -t 1e-3
DATASET    = Census/S/FL
TOLERANCE  = 1e-3
PARTITIONS = 598
./QuadPlusPart 598 Census/S/FL 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/FL/P598 ...
2022-03-20 22:46:37,894|2888|local-1647841596250|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/FL/A.wkt --input2 Census/S/FL/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/FL/P598/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/FL/P598/boundary.wkt --partitions 598 --tolerance 1e-3
2022-03-20 22:46:37,895|2889|local-1647841596250|INFO|scale=1000.0
2022-03-20 22:46:37,903|2897|local-1647841596250|TIME|Start
2022-03-20 22:46:46,670|11664|local-1647841596250|INFO|edgesA=1086541
2022-03-20 22:46:49,017|14011|local-1647841596250|INFO|edgesB=1216238
2022-03-20 22:46:49,680|14674|local-1647841596250|TIME|Read
2022-03-20 22:46:49,680|14674|Partition by number (598)
2022-03-20 22:46:49,686|14680|Fraction: 0.010286510831452137
2022-03-20 22:46:50,062|15056|local-1647841596250|INFO|partitions=1600
2022-03-20 22:46:50,063|15057|local-1647841596250|TIME|Partition
2022-03-20 22:46:50,067|15061|Saved /home/acald013/RIDIR/local_path/Census/S/FL/P598/boundary.wkt in 0.00s [1 records].
2022-03-20 22:46:50,210|15204|Saved /home/acald013/RIDIR/local_path/Census/S/FL/P598/quadtree.wkt in 0.00s [1600 records].
2022-03-20 22:46:50,514|15508|local-1647841596250|TIME|Close
Partitioning edges...
rm -f -r Census/S/FL/P598/edgesA/
rm -f -r Census/S/FL/P598/edgesB/
2022-03-20 22:47:07,807|13721|application_1639015019875_1308|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/FL/A.wkt --input2 Census/S/FL/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/FL/P598/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/FL/P598/boundary.wkt --apath Census/S/FL/P598/edgesA --bpath Census/S/FL/P598/edgesB --tolerance 1e-3 --save
2022-03-20 22:47:07,807|13721|application_1639015019875_1308|INFO|scale=1000.0
2022-03-20 22:47:07,821|13735|application_1639015019875_1308|TIME|Start
2022-03-20 22:47:17,488|23402|application_1639015019875_1308|INFO|edgesA=1086541
2022-03-20 22:47:23,556|29470|application_1639015019875_1308|INFO|edgesB=1216238
2022-03-20 22:47:23,566|29480|application_1639015019875_1308|TIME|Read
2022-03-20 22:47:41,956|47870|application_1639015019875_1308|TIME|Saving
./Perf -d Census/S/FL -p 598 -t 1e-3 -n 1
DATASET    = Census/S/FL
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 598
Run 1 ./sdcel2_debug Census/S/FL/P598 /home/acald013/RIDIR/local_path/Census/S/FL/P598/ 1e-3 "598_Census/S/FL_1e-3_1"
2022-03-20 22:47:59,245|13484|application_1639015019875_1309|13759|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/FL/P598/edgesA --input2 Census/S/FL/P598/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/FL/P598//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/FL/P598//boundary.wkt --tolerance 1e-3 --qtag 598_Census/S/FL_1e-3_1 --debug --local
2022-03-20 22:47:59,350|13589|application_1639015019875_1309|INFO|scale=1000.0
2022-03-20 22:47:59,493|13732|Saved /tmp/edgesCells_598.wkt in 0.00s [1600 records].
2022-03-20 22:47:59,493|13732|application_1639015019875_1309|INFO|npartitions=1600
2022-03-20 22:47:59,493|13732|application_1639015019875_1309|248|TIME|start|598_Census/S/FL_1e-3_1
2022-03-20 22:48:13,647|27886|application_1639015019875_1309|INFO|nEdgesA=1097692
2022-03-20 22:48:17,417|31656|application_1639015019875_1309|INFO|nEdgesB=1229077
2022-03-20 22:48:17,417|31656|application_1639015019875_1309|17924|TIME|read|598_Census/S/FL_1e-3_1
2022-03-20 22:48:22,151|36390|application_1639015019875_1309|4734|TIME|layer1S|598_Census/S/FL_1e-3_1
2022-03-20 22:48:24,949|39188|Saved /tmp/edgesFAC.wkt in 0.26s [10234 records].
2022-03-20 22:48:27,382|41621|application_1639015019875_1309|5231|TIME|layer2S|598_Census/S/FL_1e-3_1
2022-03-20 22:48:30,018|44257|Saved /tmp/edgesFBC.wkt in 0.27s [12138 records].
2022-03-20 22:49:11,437|85676|Saved /tmp/edgesS.wkt in 0.43s [26857 records].
2022-03-20 22:49:13,852|88091|application_1639015019875_1309|46470|TIME|overlayS|598_Census/S/FL_1e-3_1
2022-03-20 22:49:15,056|89295|Saved /tmp/edgesFE.wkt in 0.39s [6245 records].
2022-03-20 22:49:15,056|89295|application_1639015019875_1309|1204|TIME|end|598_Census/S/FL_1e-3_1
hdfs dfs -mkdir Census/S/GA/
hdfs dfs -put ~/Datasets/Census/GA/GA2000.wkt Census/S/GA/A.wkt
hdfs dfs -put ~/Datasets/Census/GA/GA2010.wkt Census/S/GA/B.wkt
./QuadPart -d Census/S/GA -p 653 -t 1e-3
DATASET    = Census/S/GA
TOLERANCE  = 1e-3
PARTITIONS = 653
./QuadPlusPart 653 Census/S/GA 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/GA/P653 ...
2022-03-20 22:49:35,407|2787|local-1647841773809|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/GA/A.wkt --input2 Census/S/GA/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/GA/P653/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/GA/P653/boundary.wkt --partitions 653 --tolerance 1e-3
2022-03-20 22:49:35,408|2788|local-1647841773809|INFO|scale=1000.0
2022-03-20 22:49:35,417|2797|local-1647841773809|TIME|Start
2022-03-20 22:49:43,998|11378|local-1647841773809|INFO|edgesA=1249819
2022-03-20 22:49:46,698|14078|local-1647841773809|INFO|edgesB=1334311
2022-03-20 22:49:47,073|14453|local-1647841773809|TIME|Read
2022-03-20 22:49:47,074|14454|Partition by number (653)
2022-03-20 22:49:47,077|14457|Fraction: 0.010270460747999996
2022-03-20 22:49:47,407|14787|local-1647841773809|INFO|partitions=1663
2022-03-20 22:49:47,407|14787|local-1647841773809|TIME|Partition
2022-03-20 22:49:47,410|14790|Saved /home/acald013/RIDIR/local_path/Census/S/GA/P653/boundary.wkt in 0.00s [1 records].
2022-03-20 22:49:47,537|14917|Saved /home/acald013/RIDIR/local_path/Census/S/GA/P653/quadtree.wkt in 0.00s [1663 records].
2022-03-20 22:49:47,740|15120|local-1647841773809|TIME|Close
Partitioning edges...
rm -f -r Census/S/GA/P653/edgesA/
rm -f -r Census/S/GA/P653/edgesB/
2022-03-20 22:50:04,969|13621|application_1639015019875_1310|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/GA/A.wkt --input2 Census/S/GA/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/GA/P653/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/GA/P653/boundary.wkt --apath Census/S/GA/P653/edgesA --bpath Census/S/GA/P653/edgesB --tolerance 1e-3 --save
2022-03-20 22:50:04,970|13622|application_1639015019875_1310|INFO|scale=1000.0
2022-03-20 22:50:04,983|13635|application_1639015019875_1310|TIME|Start
2022-03-20 22:50:14,877|23529|application_1639015019875_1310|INFO|edgesA=1249819
2022-03-20 22:50:21,231|29883|application_1639015019875_1310|INFO|edgesB=1334311
2022-03-20 22:50:21,240|29892|application_1639015019875_1310|TIME|Read
2022-03-20 22:50:40,647|49299|application_1639015019875_1310|TIME|Saving
./Perf -d Census/S/GA -p 653 -t 1e-3 -n 1
DATASET    = Census/S/GA
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 653
Run 1 ./sdcel2_debug Census/S/GA/P653 /home/acald013/RIDIR/local_path/Census/S/GA/P653/ 1e-3 "653_Census/S/GA_1e-3_1"
2022-03-20 22:50:57,839|13474|application_1639015019875_1311|13722|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/GA/P653/edgesA --input2 Census/S/GA/P653/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/GA/P653//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/GA/P653//boundary.wkt --tolerance 1e-3 --qtag 653_Census/S/GA_1e-3_1 --debug --local
2022-03-20 22:50:57,961|13596|application_1639015019875_1311|INFO|scale=1000.0
2022-03-20 22:50:58,084|13719|Saved /tmp/edgesCells_653.wkt in 0.00s [1663 records].
2022-03-20 22:50:58,085|13720|application_1639015019875_1311|INFO|npartitions=1663
2022-03-20 22:50:58,085|13720|application_1639015019875_1311|246|TIME|start|653_Census/S/GA_1e-3_1
2022-03-20 22:51:12,156|27791|application_1639015019875_1311|INFO|nEdgesA=1259077
2022-03-20 22:51:16,186|31821|application_1639015019875_1311|INFO|nEdgesB=1344407
2022-03-20 22:51:16,186|31821|application_1639015019875_1311|18101|TIME|read|653_Census/S/GA_1e-3_1
2022-03-20 22:51:19,777|35412|application_1639015019875_1311|3591|TIME|layer1S|653_Census/S/GA_1e-3_1
2022-03-20 22:51:23,233|38868|Saved /tmp/edgesFAC.wkt in 0.34s [7843 records].
2022-03-20 22:51:26,993|42628|application_1639015019875_1311|7216|TIME|layer2S|653_Census/S/GA_1e-3_1
2022-03-20 22:51:29,626|45261|Saved /tmp/edgesFBC.wkt in 0.37s [8596 records].
2022-03-20 22:52:07,328|82963|Saved /tmp/edgesS.wkt in 0.38s [19981 records].
2022-03-20 22:52:09,525|85160|application_1639015019875_1311|42532|TIME|overlayS|653_Census/S/GA_1e-3_1
2022-03-20 22:52:10,622|86257|Saved /tmp/edgesFE.wkt in 0.29s [3424 records].
2022-03-20 22:52:10,623|86258|application_1639015019875_1311|1098|TIME|end|653_Census/S/GA_1e-3_1
hdfs dfs -mkdir Census/S/HI/
hdfs dfs -put ~/Datasets/Census/HI/HI2000.wkt Census/S/HI/A.wkt
hdfs dfs -put ~/Datasets/Census/HI/HI2010.wkt Census/S/HI/B.wkt
./QuadPart -d Census/S/HI -p 70 -t 1e-3
DATASET    = Census/S/HI
TOLERANCE  = 1e-3
PARTITIONS = 70
./QuadPlusPart 70 Census/S/HI 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/HI/P70 ...
2022-03-20 22:52:29,392|2798|local-1647841947781|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/HI/A.wkt --input2 Census/S/HI/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/HI/P70/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/HI/P70/boundary.wkt --partitions 70 --tolerance 1e-3
2022-03-20 22:52:29,393|2799|local-1647841947781|INFO|scale=1000.0
2022-03-20 22:52:29,404|2810|local-1647841947781|TIME|Start
2022-03-20 22:52:36,603|10009|local-1647841947781|INFO|edgesA=125059
2022-03-20 22:52:37,679|11085|local-1647841947781|INFO|edgesB=142917
2022-03-20 22:52:37,851|11257|local-1647841947781|TIME|Read
2022-03-20 22:52:37,852|11258|Partition by number (70)
2022-03-20 22:52:37,855|11261|Fraction: 0.01086122469333264
2022-03-20 22:52:38,048|11454|local-1647841947781|INFO|partitions=232
2022-03-20 22:52:38,049|11455|local-1647841947781|TIME|Partition
2022-03-20 22:52:38,052|11458|Saved /home/acald013/RIDIR/local_path/Census/S/HI/P70/boundary.wkt in 0.00s [1 records].
2022-03-20 22:52:38,094|11500|Saved /home/acald013/RIDIR/local_path/Census/S/HI/P70/quadtree.wkt in 0.00s [232 records].
2022-03-20 22:52:38,429|11835|local-1647841947781|TIME|Close
Partitioning edges...
rm -f -r Census/S/HI/P70/edgesA/
rm -f -r Census/S/HI/P70/edgesB/
2022-03-20 22:52:55,871|14167|application_1639015019875_1312|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/HI/A.wkt --input2 Census/S/HI/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/HI/P70/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/HI/P70/boundary.wkt --apath Census/S/HI/P70/edgesA --bpath Census/S/HI/P70/edgesB --tolerance 1e-3 --save
2022-03-20 22:52:55,871|14167|application_1639015019875_1312|INFO|scale=1000.0
2022-03-20 22:52:55,885|14181|application_1639015019875_1312|TIME|Start
2022-03-20 22:53:08,971|27267|application_1639015019875_1312|INFO|edgesA=125059
2022-03-20 22:53:18,267|36563|application_1639015019875_1312|INFO|edgesB=142917
2022-03-20 22:53:18,275|36571|application_1639015019875_1312|TIME|Read
2022-03-20 22:53:26,915|45211|application_1639015019875_1312|TIME|Saving
./Perf -d Census/S/HI -p 70 -t 1e-3 -n 1
DATASET    = Census/S/HI
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 70
Run 1 ./sdcel2_debug Census/S/HI/P70 /home/acald013/RIDIR/local_path/Census/S/HI/P70/ 1e-3 "70_Census/S/HI_1e-3_1"
2022-03-20 22:53:43,877|13435|application_1639015019875_1313|13684|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/HI/P70/edgesA --input2 Census/S/HI/P70/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/HI/P70//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/HI/P70//boundary.wkt --tolerance 1e-3 --qtag 70_Census/S/HI_1e-3_1 --debug --local
2022-03-20 22:53:43,940|13498|application_1639015019875_1313|INFO|scale=1000.0
2022-03-20 22:53:43,989|13547|Saved /tmp/edgesCells_70.wkt in 0.00s [232 records].
2022-03-20 22:53:43,990|13548|application_1639015019875_1313|INFO|npartitions=232
2022-03-20 22:53:43,990|13548|application_1639015019875_1313|113|TIME|start|70_Census/S/HI_1e-3_1
2022-03-20 22:53:54,472|24030|application_1639015019875_1313|INFO|nEdgesA=126405
2022-03-20 22:53:55,912|25470|application_1639015019875_1313|INFO|nEdgesB=144457
2022-03-20 22:53:55,912|25470|application_1639015019875_1313|11922|TIME|read|70_Census/S/HI_1e-3_1
2022-03-20 22:53:57,318|26876|application_1639015019875_1313|1406|TIME|layer1S|70_Census/S/HI_1e-3_1
2022-03-20 22:53:57,968|27526|Saved /tmp/edgesFAC.wkt in 0.06s [1142 records].
2022-03-20 22:53:58,955|28513|application_1639015019875_1313|1637|TIME|layer2S|70_Census/S/HI_1e-3_1
2022-03-20 22:53:59,525|29083|Saved /tmp/edgesFBC.wkt in 0.05s [1304 records].
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 18 (count at SDCEL2.scala:158) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867) 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:863) 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:677) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:109) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 	at java.lang.Thread.run(Thread.java:745) 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1348)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1869)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:158)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
hdfs dfs -mkdir Census/S/ID/
hdfs dfs -put ~/Datasets/Census/ID/ID2000.wkt Census/S/ID/A.wkt
hdfs dfs -put ~/Datasets/Census/ID/ID2010.wkt Census/S/ID/B.wkt
./QuadPart -d Census/S/ID -p 197 -t 1e-3
DATASET    = Census/S/ID
TOLERANCE  = 1e-3
PARTITIONS = 197
./QuadPlusPart 197 Census/S/ID 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/ID/P197 ...
2022-03-20 22:54:42,365|2886|local-1647842080703|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/ID/A.wkt --input2 Census/S/ID/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/ID/P197/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/ID/P197/boundary.wkt --partitions 197 --tolerance 1e-3
2022-03-20 22:54:42,366|2887|local-1647842080703|INFO|scale=1000.0
2022-03-20 22:54:42,376|2897|local-1647842080703|TIME|Start
2022-03-20 22:54:49,923|10444|local-1647842080703|INFO|edgesA=409049
2022-03-20 22:54:51,324|11845|local-1647842080703|INFO|edgesB=404289
2022-03-20 22:54:51,461|11982|local-1647842080703|TIME|Read
2022-03-20 22:54:51,461|11982|Partition by number (197)
2022-03-20 22:54:51,465|11986|Fraction: 0.010486882264196543
2022-03-20 22:54:51,759|12280|local-1647842080703|INFO|partitions=553
2022-03-20 22:54:51,759|12280|local-1647842080703|TIME|Partition
2022-03-20 22:54:51,763|12284|Saved /home/acald013/RIDIR/local_path/Census/S/ID/P197/boundary.wkt in 0.00s [1 records].
2022-03-20 22:54:51,837|12358|Saved /home/acald013/RIDIR/local_path/Census/S/ID/P197/quadtree.wkt in 0.00s [553 records].
2022-03-20 22:54:51,992|12513|local-1647842080703|TIME|Close
Partitioning edges...
rm -f -r Census/S/ID/P197/edgesA/
rm -f -r Census/S/ID/P197/edgesB/
2022-03-20 22:55:08,779|13493|application_1639015019875_1314|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/ID/A.wkt --input2 Census/S/ID/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/ID/P197/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/ID/P197/boundary.wkt --apath Census/S/ID/P197/edgesA --bpath Census/S/ID/P197/edgesB --tolerance 1e-3 --save
2022-03-20 22:55:08,780|13494|application_1639015019875_1314|INFO|scale=1000.0
2022-03-20 22:55:08,793|13507|application_1639015019875_1314|TIME|Start
2022-03-20 22:55:18,457|23171|application_1639015019875_1314|INFO|edgesA=409049
2022-03-20 22:55:24,007|28721|application_1639015019875_1314|INFO|edgesB=404289
2022-03-20 22:55:24,019|28733|application_1639015019875_1314|TIME|Read
2022-03-20 22:55:34,332|39046|application_1639015019875_1314|TIME|Saving
./Perf -d Census/S/ID -p 197 -t 1e-3 -n 1
DATASET    = Census/S/ID
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 197
Run 1 ./sdcel2_debug Census/S/ID/P197 /home/acald013/RIDIR/local_path/Census/S/ID/P197/ 1e-3 "197_Census/S/ID_1e-3_1"
2022-03-20 22:55:51,672|13597|application_1639015019875_1315|13845|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/ID/P197/edgesA --input2 Census/S/ID/P197/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/ID/P197//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/ID/P197//boundary.wkt --tolerance 1e-3 --qtag 197_Census/S/ID_1e-3_1 --debug --local
2022-03-20 22:55:51,752|13677|application_1639015019875_1315|INFO|scale=1000.0
2022-03-20 22:55:51,823|13748|Saved /tmp/edgesCells_197.wkt in 0.00s [553 records].
2022-03-20 22:55:51,824|13749|application_1639015019875_1315|INFO|npartitions=553
2022-03-20 22:55:51,824|13749|application_1639015019875_1315|152|TIME|start|197_Census/S/ID_1e-3_1
2022-03-20 22:56:02,864|24789|application_1639015019875_1315|INFO|nEdgesA=411041
2022-03-20 22:56:05,155|27080|application_1639015019875_1315|INFO|nEdgesB=406301
2022-03-20 22:56:05,155|27080|application_1639015019875_1315|13331|TIME|read|197_Census/S/ID_1e-3_1
2022-03-20 22:56:07,019|28944|application_1639015019875_1315|1864|TIME|layer1S|197_Census/S/ID_1e-3_1
2022-03-20 22:56:08,113|30038|Saved /tmp/edgesFAC.wkt in 0.08s [1775 records].
2022-03-20 22:56:09,386|31311|application_1639015019875_1315|2367|TIME|layer2S|197_Census/S/ID_1e-3_1
2022-03-20 22:56:10,466|32391|Saved /tmp/edgesFBC.wkt in 0.08s [1803 records].
2022-03-20 22:56:47,068|68993|Saved /tmp/edgesS.wkt in 0.16s [3837 records].
2022-03-20 22:56:48,662|70587|application_1639015019875_1315|39276|TIME|overlayS|197_Census/S/ID_1e-3_1
2022-03-20 22:56:49,212|71137|Saved /tmp/edgesFE.wkt in 0.07s [419 records].
2022-03-20 22:56:49,213|71138|application_1639015019875_1315|551|TIME|end|197_Census/S/ID_1e-3_1
hdfs dfs -mkdir Census/S/IL/
hdfs dfs -put ~/Datasets/Census/IL/IL2000.wkt Census/S/IL/A.wkt
hdfs dfs -put ~/Datasets/Census/IL/IL2010.wkt Census/S/IL/B.wkt
./QuadPart -d Census/S/IL -p 501 -t 1e-3
DATASET    = Census/S/IL
TOLERANCE  = 1e-3
PARTITIONS = 501
./QuadPlusPart 501 Census/S/IL 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/IL/P501 ...
2022-03-20 22:57:10,188|2844|local-1647842228522|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/IL/A.wkt --input2 Census/S/IL/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/IL/P501/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/IL/P501/boundary.wkt --partitions 501 --tolerance 1e-3
2022-03-20 22:57:10,189|2845|local-1647842228522|INFO|scale=1000.0
2022-03-20 22:57:10,199|2855|local-1647842228522|TIME|Start
2022-03-20 22:57:18,429|11085|local-1647842228522|INFO|edgesA=995615
2022-03-20 22:57:21,097|13753|local-1647842228522|INFO|edgesB=1021362
2022-03-20 22:57:21,491|14147|local-1647842228522|TIME|Read
2022-03-20 22:57:21,491|14147|Partition by number (501)
2022-03-20 22:57:21,495|14151|Fraction: 0.010306418879383933
2022-03-20 22:57:21,916|14572|local-1647842228522|INFO|partitions=1282
2022-03-20 22:57:21,916|14572|local-1647842228522|TIME|Partition
2022-03-20 22:57:21,920|14576|Saved /home/acald013/RIDIR/local_path/Census/S/IL/P501/boundary.wkt in 0.00s [1 records].
2022-03-20 22:57:22,025|14681|Saved /home/acald013/RIDIR/local_path/Census/S/IL/P501/quadtree.wkt in 0.00s [1282 records].
2022-03-20 22:57:22,256|14912|local-1647842228522|TIME|Close
Partitioning edges...
rm -f -r Census/S/IL/P501/edgesA/
rm -f -r Census/S/IL/P501/edgesB/
2022-03-20 22:57:39,323|13655|application_1639015019875_1316|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/IL/A.wkt --input2 Census/S/IL/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/IL/P501/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/IL/P501/boundary.wkt --apath Census/S/IL/P501/edgesA --bpath Census/S/IL/P501/edgesB --tolerance 1e-3 --save
2022-03-20 22:57:39,324|13656|application_1639015019875_1316|INFO|scale=1000.0
2022-03-20 22:57:39,336|13668|application_1639015019875_1316|TIME|Start
2022-03-20 22:57:49,202|23534|application_1639015019875_1316|INFO|edgesA=995615
2022-03-20 22:57:55,132|29464|application_1639015019875_1316|INFO|edgesB=1021362
2022-03-20 22:57:55,141|29473|application_1639015019875_1316|TIME|Read
2022-03-20 22:58:11,482|45814|application_1639015019875_1316|TIME|Saving
./Perf -d Census/S/IL -p 501 -t 1e-3 -n 1
DATASET    = Census/S/IL
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 501
Run 1 ./sdcel2_debug Census/S/IL/P501 /home/acald013/RIDIR/local_path/Census/S/IL/P501/ 1e-3 "501_Census/S/IL_1e-3_1"
2022-03-20 22:58:28,447|13323|application_1639015019875_1317|13565|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/IL/P501/edgesA --input2 Census/S/IL/P501/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/IL/P501//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/IL/P501//boundary.wkt --tolerance 1e-3 --qtag 501_Census/S/IL_1e-3_1 --debug --local
2022-03-20 22:58:28,554|13430|application_1639015019875_1317|INFO|scale=1000.0
2022-03-20 22:58:28,662|13538|Saved /tmp/edgesCells_501.wkt in 0.00s [1282 records].
2022-03-20 22:58:28,662|13538|application_1639015019875_1317|INFO|npartitions=1282
2022-03-20 22:58:28,663|13539|application_1639015019875_1317|216|TIME|start|501_Census/S/IL_1e-3_1
2022-03-20 22:58:41,919|26795|application_1639015019875_1317|INFO|nEdgesA=1005784
2022-03-20 22:58:45,467|30343|application_1639015019875_1317|INFO|nEdgesB=1031873
2022-03-20 22:58:45,468|30344|application_1639015019875_1317|16805|TIME|read|501_Census/S/IL_1e-3_1
2022-03-20 22:58:48,715|33591|application_1639015019875_1317|3247|TIME|layer1S|501_Census/S/IL_1e-3_1
2022-03-20 22:58:51,043|35919|Saved /tmp/edgesFAC.wkt in 0.31s [9259 records].
2022-03-20 22:58:52,995|37871|application_1639015019875_1317|4280|TIME|layer2S|501_Census/S/IL_1e-3_1
2022-03-20 22:58:55,265|40141|Saved /tmp/edgesFBC.wkt in 0.24s [9576 records].
2022-03-20 22:59:28,654|73530|Saved /tmp/edgesS.wkt in 0.28s [20723 records].
2022-03-20 22:59:31,182|76058|application_1639015019875_1317|38187|TIME|overlayS|501_Census/S/IL_1e-3_1
2022-03-20 22:59:32,261|77137|Saved /tmp/edgesFE.wkt in 0.23s [4081 records].
2022-03-20 22:59:32,262|77138|application_1639015019875_1317|1080|TIME|end|501_Census/S/IL_1e-3_1
hdfs dfs -mkdir Census/S/IN/
hdfs dfs -put ~/Datasets/Census/IN/IN2000.wkt Census/S/IN/A.wkt
hdfs dfs -put ~/Datasets/Census/IN/IN2010.wkt Census/S/IN/B.wkt
./QuadPart -d Census/S/IN -p 312 -t 1e-3
DATASET    = Census/S/IN
TOLERANCE  = 1e-3
PARTITIONS = 312
./QuadPlusPart 312 Census/S/IN 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/IN/P312 ...
2022-03-20 22:59:51,324|2725|local-1647842389748|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/IN/A.wkt --input2 Census/S/IN/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/IN/P312/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/IN/P312/boundary.wkt --partitions 312 --tolerance 1e-3
2022-03-20 22:59:51,325|2726|local-1647842389748|INFO|scale=1000.0
2022-03-20 22:59:51,333|2734|local-1647842389748|TIME|Start
2022-03-20 22:59:59,100|10501|local-1647842389748|INFO|edgesA=617396
2022-03-20 23:00:00,889|12290|local-1647842389748|INFO|edgesB=636744
2022-03-20 23:00:01,345|12746|local-1647842389748|TIME|Read
2022-03-20 23:00:01,346|12747|Partition by number (312)
2022-03-20 23:00:01,349|12750|Fraction: 0.010390337191220565
2022-03-20 23:00:01,868|13269|local-1647842389748|INFO|partitions=850
2022-03-20 23:00:01,868|13269|local-1647842389748|TIME|Partition
2022-03-20 23:00:01,872|13273|Saved /home/acald013/RIDIR/local_path/Census/S/IN/P312/boundary.wkt in 0.00s [1 records].
2022-03-20 23:00:01,972|13373|Saved /home/acald013/RIDIR/local_path/Census/S/IN/P312/quadtree.wkt in 0.00s [850 records].
2022-03-20 23:00:02,221|13622|local-1647842389748|TIME|Close
Partitioning edges...
rm -f -r Census/S/IN/P312/edgesA/
rm -f -r Census/S/IN/P312/edgesB/
2022-03-20 23:00:18,979|13291|application_1639015019875_1318|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/IN/A.wkt --input2 Census/S/IN/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/IN/P312/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/IN/P312/boundary.wkt --apath Census/S/IN/P312/edgesA --bpath Census/S/IN/P312/edgesB --tolerance 1e-3 --save
2022-03-20 23:00:18,979|13291|application_1639015019875_1318|INFO|scale=1000.0
2022-03-20 23:00:18,992|13304|application_1639015019875_1318|TIME|Start
2022-03-20 23:00:28,768|23080|application_1639015019875_1318|INFO|edgesA=617396
2022-03-20 23:00:34,664|28976|application_1639015019875_1318|INFO|edgesB=636744
2022-03-20 23:00:34,673|28985|application_1639015019875_1318|TIME|Read
2022-03-20 23:00:51,272|45584|application_1639015019875_1318|TIME|Saving
./Perf -d Census/S/IN -p 312 -t 1e-3 -n 1
DATASET    = Census/S/IN
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 312
Run 1 ./sdcel2_debug Census/S/IN/P312 /home/acald013/RIDIR/local_path/Census/S/IN/P312/ 1e-3 "312_Census/S/IN_1e-3_1"
2022-03-20 23:01:08,620|13705|application_1639015019875_1319|13948|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/IN/P312/edgesA --input2 Census/S/IN/P312/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/IN/P312//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/IN/P312//boundary.wkt --tolerance 1e-3 --qtag 312_Census/S/IN_1e-3_1 --debug --local
2022-03-20 23:01:08,717|13802|application_1639015019875_1319|INFO|scale=1000.0
2022-03-20 23:01:08,811|13896|Saved /tmp/edgesCells_312.wkt in 0.00s [850 records].
2022-03-20 23:01:08,812|13897|application_1639015019875_1319|INFO|npartitions=850
2022-03-20 23:01:08,812|13897|application_1639015019875_1319|192|TIME|start|312_Census/S/IN_1e-3_1
2022-03-20 23:01:21,329|26414|application_1639015019875_1319|INFO|nEdgesA=623109
2022-03-20 23:01:24,366|29451|application_1639015019875_1319|INFO|nEdgesB=642651
2022-03-20 23:01:24,366|29451|application_1639015019875_1319|15554|TIME|read|312_Census/S/IN_1e-3_1
2022-03-20 23:01:26,397|31482|application_1639015019875_1319|2031|TIME|layer1S|312_Census/S/IN_1e-3_1
2022-03-20 23:01:28,020|33105|Saved /tmp/edgesFAC.wkt in 0.15s [5050 records].
2022-03-20 23:01:29,517|34602|application_1639015019875_1319|3120|TIME|layer2S|312_Census/S/IN_1e-3_1
2022-03-20 23:01:31,272|36357|Saved /tmp/edgesFBC.wkt in 0.19s [5235 records].
2022-03-20 23:02:07,683|72768|Saved /tmp/edgesS.wkt in 0.18s [11356 records].
2022-03-20 23:02:09,858|74943|application_1639015019875_1319|40341|TIME|overlayS|312_Census/S/IN_1e-3_1
2022-03-20 23:02:10,443|75528|Saved /tmp/edgesFE.wkt in 0.15s [1944 records].
2022-03-20 23:02:10,444|75529|application_1639015019875_1319|586|TIME|end|312_Census/S/IN_1e-3_1
hdfs dfs -mkdir Census/S/IA/
hdfs dfs -put ~/Datasets/Census/IA/IA2000.wkt Census/S/IA/A.wkt
hdfs dfs -put ~/Datasets/Census/IA/IA2010.wkt Census/S/IA/B.wkt
./QuadPart -d Census/S/IA -p 216 -t 1e-3
DATASET    = Census/S/IA
TOLERANCE  = 1e-3
PARTITIONS = 216
./QuadPlusPart 216 Census/S/IA 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/IA/P216 ...
2022-03-20 23:02:30,450|2978|local-1647842548743|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/IA/A.wkt --input2 Census/S/IA/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/IA/P216/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/IA/P216/boundary.wkt --partitions 216 --tolerance 1e-3
2022-03-20 23:02:30,451|2979|local-1647842548743|INFO|scale=1000.0
2022-03-20 23:02:30,460|2988|local-1647842548743|TIME|Start
2022-03-20 23:02:38,100|10628|local-1647842548743|INFO|edgesA=437961
2022-03-20 23:02:39,465|11993|local-1647842548743|INFO|edgesB=440912
2022-03-20 23:02:39,671|12199|local-1647842548743|TIME|Read
2022-03-20 23:02:39,672|12200|Partition by number (216)
2022-03-20 23:02:39,677|12205|Fraction: 0.01046756477321494
2022-03-20 23:02:40,116|12644|local-1647842548743|INFO|partitions=574
2022-03-20 23:02:40,116|12644|local-1647842548743|TIME|Partition
2022-03-20 23:02:40,122|12650|Saved /home/acald013/RIDIR/local_path/Census/S/IA/P216/boundary.wkt in 0.00s [1 records].
2022-03-20 23:02:40,199|12727|Saved /home/acald013/RIDIR/local_path/Census/S/IA/P216/quadtree.wkt in 0.00s [574 records].
2022-03-20 23:02:40,398|12926|local-1647842548743|TIME|Close
Partitioning edges...
rm -f -r Census/S/IA/P216/edgesA/
rm -f -r Census/S/IA/P216/edgesB/
2022-03-20 23:02:57,529|13806|application_1639015019875_1320|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/IA/A.wkt --input2 Census/S/IA/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/IA/P216/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/IA/P216/boundary.wkt --apath Census/S/IA/P216/edgesA --bpath Census/S/IA/P216/edgesB --tolerance 1e-3 --save
2022-03-20 23:02:57,529|13806|application_1639015019875_1320|INFO|scale=1000.0
2022-03-20 23:02:57,542|13819|application_1639015019875_1320|TIME|Start
2022-03-20 23:03:06,754|23031|application_1639015019875_1320|INFO|edgesA=437961
2022-03-20 23:03:12,512|28789|application_1639015019875_1320|INFO|edgesB=440912
2022-03-20 23:03:12,521|28798|application_1639015019875_1320|TIME|Read
2022-03-20 23:03:24,271|40548|application_1639015019875_1320|TIME|Saving
./Perf -d Census/S/IA -p 216 -t 1e-3 -n 1
DATASET    = Census/S/IA
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 216
Run 1 ./sdcel2_debug Census/S/IA/P216 /home/acald013/RIDIR/local_path/Census/S/IA/P216/ 1e-3 "216_Census/S/IA_1e-3_1"
2022-03-20 23:03:42,122|13712|application_1639015019875_1321|13969|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/IA/P216/edgesA --input2 Census/S/IA/P216/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/IA/P216//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/IA/P216//boundary.wkt --tolerance 1e-3 --qtag 216_Census/S/IA_1e-3_1 --debug --local
2022-03-20 23:03:42,205|13795|application_1639015019875_1321|INFO|scale=1000.0
2022-03-20 23:03:42,282|13872|Saved /tmp/edgesCells_216.wkt in 0.00s [574 records].
2022-03-20 23:03:42,283|13873|application_1639015019875_1321|INFO|npartitions=574
2022-03-20 23:03:42,283|13873|application_1639015019875_1321|161|TIME|start|216_Census/S/IA_1e-3_1
2022-03-20 23:03:53,487|25077|application_1639015019875_1321|INFO|nEdgesA=441171
2022-03-20 23:03:55,789|27379|application_1639015019875_1321|INFO|nEdgesB=444146
2022-03-20 23:03:55,789|27379|application_1639015019875_1321|13506|TIME|read|216_Census/S/IA_1e-3_1
2022-03-20 23:03:58,080|29670|application_1639015019875_1321|2290|TIME|layer1S|216_Census/S/IA_1e-3_1
2022-03-20 23:03:59,286|30876|Saved /tmp/edgesFAC.wkt in 0.13s [2891 records].
2022-03-20 23:04:00,698|32288|application_1639015019875_1321|2618|TIME|layer2S|216_Census/S/IA_1e-3_1
2022-03-20 23:04:01,884|33474|Saved /tmp/edgesFBC.wkt in 0.11s [2934 records].
2022-03-20 23:04:45,413|77003|Saved /tmp/edgesS.wkt in 0.11s [6191 records].
2022-03-20 23:04:47,062|78652|application_1639015019875_1321|46365|TIME|overlayS|216_Census/S/IA_1e-3_1
2022-03-20 23:04:47,691|79281|Saved /tmp/edgesFE.wkt in 0.10s [1016 records].
2022-03-20 23:04:47,691|79281|application_1639015019875_1321|629|TIME|end|216_Census/S/IA_1e-3_1
hdfs dfs -mkdir Census/S/KS/
hdfs dfs -put ~/Datasets/Census/KS/KS2000.wkt Census/S/KS/A.wkt
hdfs dfs -put ~/Datasets/Census/KS/KS2010.wkt Census/S/KS/B.wkt
./QuadPart -d Census/S/KS -p 159 -t 1e-3
DATASET    = Census/S/KS
TOLERANCE  = 1e-3
PARTITIONS = 159
./QuadPlusPart 159 Census/S/KS 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/KS/P159 ...
2022-03-20 23:05:06,819|2841|local-1647842705103|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/KS/A.wkt --input2 Census/S/KS/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/KS/P159/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/KS/P159/boundary.wkt --partitions 159 --tolerance 1e-3
2022-03-20 23:05:06,819|2841|local-1647842705103|INFO|scale=1000.0
2022-03-20 23:05:06,829|2851|local-1647842705103|TIME|Start
2022-03-20 23:05:13,861|9883|local-1647842705103|INFO|edgesA=315385
2022-03-20 23:05:14,970|10992|local-1647842705103|INFO|edgesB=324775
2022-03-20 23:05:15,169|11191|local-1647842705103|TIME|Read
2022-03-20 23:05:15,170|11192|Partition by number (159)
2022-03-20 23:05:15,174|11196|Fraction: 0.010550042533088222
2022-03-20 23:05:15,603|11625|local-1647842705103|INFO|partitions=430
2022-03-20 23:05:15,603|11625|local-1647842705103|TIME|Partition
2022-03-20 23:05:15,607|11629|Saved /home/acald013/RIDIR/local_path/Census/S/KS/P159/boundary.wkt in 0.00s [1 records].
2022-03-20 23:05:15,768|11790|Saved /home/acald013/RIDIR/local_path/Census/S/KS/P159/quadtree.wkt in 0.00s [430 records].
2022-03-20 23:05:15,911|11933|local-1647842705103|TIME|Close
Partitioning edges...
rm -f -r Census/S/KS/P159/edgesA/
rm -f -r Census/S/KS/P159/edgesB/
2022-03-20 23:05:33,519|14305|application_1639015019875_1322|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/KS/A.wkt --input2 Census/S/KS/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/KS/P159/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/KS/P159/boundary.wkt --apath Census/S/KS/P159/edgesA --bpath Census/S/KS/P159/edgesB --tolerance 1e-3 --save
2022-03-20 23:05:33,519|14305|application_1639015019875_1322|INFO|scale=1000.0
2022-03-20 23:05:33,532|14318|application_1639015019875_1322|TIME|Start
2022-03-20 23:05:42,910|23696|application_1639015019875_1322|INFO|edgesA=315385
2022-03-20 23:05:52,506|33292|application_1639015019875_1322|INFO|edgesB=324775
2022-03-20 23:05:52,514|33300|application_1639015019875_1322|TIME|Read
2022-03-20 23:06:02,690|43476|application_1639015019875_1322|TIME|Saving
./Perf -d Census/S/KS -p 159 -t 1e-3 -n 1
DATASET    = Census/S/KS
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 159
Run 1 ./sdcel2_debug Census/S/KS/P159 /home/acald013/RIDIR/local_path/Census/S/KS/P159/ 1e-3 "159_Census/S/KS_1e-3_1"
2022-03-20 23:06:20,142|13720|application_1639015019875_1323|13992|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/KS/P159/edgesA --input2 Census/S/KS/P159/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/KS/P159//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/KS/P159//boundary.wkt --tolerance 1e-3 --qtag 159_Census/S/KS_1e-3_1 --debug --local
2022-03-20 23:06:20,235|13813|application_1639015019875_1323|INFO|scale=1000.0
2022-03-20 23:06:20,324|13902|Saved /tmp/edgesCells_159.wkt in 0.00s [430 records].
2022-03-20 23:06:20,325|13903|application_1639015019875_1323|INFO|npartitions=430
2022-03-20 23:06:20,325|13903|application_1639015019875_1323|183|TIME|start|159_Census/S/KS_1e-3_1
2022-03-20 23:06:31,956|25534|application_1639015019875_1323|INFO|nEdgesA=317886
2022-03-20 23:06:33,954|27532|application_1639015019875_1323|INFO|nEdgesB=327330
2022-03-20 23:06:33,954|27532|application_1639015019875_1323|13629|TIME|read|159_Census/S/KS_1e-3_1
2022-03-20 23:06:35,532|29110|application_1639015019875_1323|1578|TIME|layer1S|159_Census/S/KS_1e-3_1
2022-03-20 23:06:36,607|30185|Saved /tmp/edgesFAC.wkt in 0.09s [2372 records].
2022-03-20 23:06:37,493|31071|application_1639015019875_1323|1961|TIME|layer2S|159_Census/S/KS_1e-3_1
2022-03-20 23:06:38,526|32104|Saved /tmp/edgesFBC.wkt in 0.07s [2430 records].
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 18 (count at SDCEL2.scala:158) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867) 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:863) 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:677) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:109) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 	at java.lang.Thread.run(Thread.java:745) 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1348)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1869)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:158)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
hdfs dfs -mkdir Census/S/KY/
hdfs dfs -put ~/Datasets/Census/KY/KY2000.wkt Census/S/KY/A.wkt
hdfs dfs -put ~/Datasets/Census/KY/KY2010.wkt Census/S/KY/B.wkt
./QuadPart -d Census/S/KY -p 573 -t 1e-3
DATASET    = Census/S/KY
TOLERANCE  = 1e-3
PARTITIONS = 573
./QuadPlusPart 573 Census/S/KY 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/KY/P573 ...
2022-03-20 23:07:29,493|2893|local-1647842847860|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/KY/A.wkt --input2 Census/S/KY/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/KY/P573/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/KY/P573/boundary.wkt --partitions 573 --tolerance 1e-3
2022-03-20 23:07:29,493|2893|local-1647842847860|INFO|scale=1000.0
2022-03-20 23:07:29,502|2902|local-1647842847860|TIME|Start
2022-03-20 23:07:37,733|11133|local-1647842847860|INFO|edgesA=1120629
2022-03-20 23:07:39,732|13132|local-1647842847860|INFO|edgesB=1172604
2022-03-20 23:07:40,203|13603|local-1647842847860|TIME|Read
2022-03-20 23:07:40,203|13603|Partition by number (573)
2022-03-20 23:07:40,208|13608|Fraction: 0.010287317687647794
2022-03-20 23:07:40,601|14001|local-1647842847860|INFO|partitions=1552
2022-03-20 23:07:40,602|14002|local-1647842847860|TIME|Partition
2022-03-20 23:07:40,606|14006|Saved /home/acald013/RIDIR/local_path/Census/S/KY/P573/boundary.wkt in 0.00s [1 records].
2022-03-20 23:07:40,713|14113|Saved /home/acald013/RIDIR/local_path/Census/S/KY/P573/quadtree.wkt in 0.00s [1552 records].
2022-03-20 23:07:41,136|14536|local-1647842847860|TIME|Close
Partitioning edges...
rm -f -r Census/S/KY/P573/edgesA/
rm -f -r Census/S/KY/P573/edgesB/
2022-03-20 23:07:58,591|13941|application_1639015019875_1324|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/KY/A.wkt --input2 Census/S/KY/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/KY/P573/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/KY/P573/boundary.wkt --apath Census/S/KY/P573/edgesA --bpath Census/S/KY/P573/edgesB --tolerance 1e-3 --save
2022-03-20 23:07:58,591|13941|application_1639015019875_1324|INFO|scale=1000.0
2022-03-20 23:07:58,604|13954|application_1639015019875_1324|TIME|Start
2022-03-20 23:08:08,528|23878|application_1639015019875_1324|INFO|edgesA=1120629
2022-03-20 23:08:14,583|29933|application_1639015019875_1324|INFO|edgesB=1172604
2022-03-20 23:08:14,593|29943|application_1639015019875_1324|TIME|Read
2022-03-20 23:08:32,489|47839|application_1639015019875_1324|TIME|Saving
./Perf -d Census/S/KY -p 573 -t 1e-3 -n 1
DATASET    = Census/S/KY
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 573
Run 1 ./sdcel2_debug Census/S/KY/P573 /home/acald013/RIDIR/local_path/Census/S/KY/P573/ 1e-3 "573_Census/S/KY_1e-3_1"
2022-03-20 23:08:49,757|13506|application_1639015019875_1325|13783|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/KY/P573/edgesA --input2 Census/S/KY/P573/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/KY/P573//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/KY/P573//boundary.wkt --tolerance 1e-3 --qtag 573_Census/S/KY_1e-3_1 --debug --local
2022-03-20 23:08:49,881|13630|application_1639015019875_1325|INFO|scale=1000.0
2022-03-20 23:08:49,998|13747|Saved /tmp/edgesCells_573.wkt in 0.00s [1552 records].
2022-03-20 23:08:49,998|13747|application_1639015019875_1325|INFO|npartitions=1552
2022-03-20 23:08:49,998|13747|application_1639015019875_1325|241|TIME|start|573_Census/S/KY_1e-3_1
2022-03-20 23:09:03,494|27243|application_1639015019875_1325|INFO|nEdgesA=1128408
2022-03-20 23:09:07,495|31244|application_1639015019875_1325|INFO|nEdgesB=1180665
2022-03-20 23:09:07,495|31244|application_1639015019875_1325|17497|TIME|read|573_Census/S/KY_1e-3_1
2022-03-20 23:09:10,547|34296|application_1639015019875_1325|3052|TIME|layer1S|573_Census/S/KY_1e-3_1
2022-03-20 23:09:12,478|36227|Saved /tmp/edgesFAC.wkt in 0.15s [6319 records].
2022-03-20 23:09:14,617|38366|application_1639015019875_1325|4070|TIME|layer2S|573_Census/S/KY_1e-3_1
2022-03-20 23:09:16,719|40468|Saved /tmp/edgesFBC.wkt in 0.30s [6595 records].
2022-03-20 23:09:56,241|79990|Saved /tmp/edgesS.wkt in 0.28s [15453 records].
2022-03-20 23:09:59,872|83621|application_1639015019875_1325|45255|TIME|overlayS|573_Census/S/KY_1e-3_1
2022-03-20 23:10:01,205|84954|Saved /tmp/edgesFE.wkt in 0.36s [2050 records].
2022-03-20 23:10:01,205|84954|application_1639015019875_1325|1333|TIME|end|573_Census/S/KY_1e-3_1
hdfs dfs -mkdir Census/S/LA/
hdfs dfs -put ~/Datasets/Census/LA/LA2000.wkt Census/S/LA/A.wkt
hdfs dfs -put ~/Datasets/Census/LA/LA2010.wkt Census/S/LA/B.wkt
./QuadPart -d Census/S/LA -p 365 -t 1e-3
DATASET    = Census/S/LA
TOLERANCE  = 1e-3
PARTITIONS = 365
./QuadPlusPart 365 Census/S/LA 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/LA/P365 ...
2022-03-20 23:10:21,641|3069|local-1647843019849|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/LA/A.wkt --input2 Census/S/LA/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/LA/P365/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/LA/P365/boundary.wkt --partitions 365 --tolerance 1e-3
2022-03-20 23:10:21,642|3070|local-1647843019849|INFO|scale=1000.0
2022-03-20 23:10:21,651|3079|local-1647843019849|TIME|Start
2022-03-20 23:10:29,476|10904|local-1647843019849|INFO|edgesA=748520
2022-03-20 23:10:31,209|12637|local-1647843019849|INFO|edgesB=746684
2022-03-20 23:10:31,638|13066|local-1647843019849|TIME|Read
2022-03-20 23:10:31,639|13067|Partition by number (365)
2022-03-20 23:10:31,645|13073|Fraction: 0.010357183109285191
2022-03-20 23:10:32,046|13474|local-1647843019849|INFO|partitions=985
2022-03-20 23:10:32,046|13474|local-1647843019849|TIME|Partition
2022-03-20 23:10:32,050|13478|Saved /home/acald013/RIDIR/local_path/Census/S/LA/P365/boundary.wkt in 0.00s [1 records].
2022-03-20 23:10:32,157|13585|Saved /home/acald013/RIDIR/local_path/Census/S/LA/P365/quadtree.wkt in 0.00s [985 records].
2022-03-20 23:10:32,338|13766|local-1647843019849|TIME|Close
Partitioning edges...
rm -f -r Census/S/LA/P365/edgesA/
rm -f -r Census/S/LA/P365/edgesB/
2022-03-20 23:10:49,304|13592|application_1639015019875_1326|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/LA/A.wkt --input2 Census/S/LA/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/LA/P365/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/LA/P365/boundary.wkt --apath Census/S/LA/P365/edgesA --bpath Census/S/LA/P365/edgesB --tolerance 1e-3 --save
2022-03-20 23:10:49,306|13594|application_1639015019875_1326|INFO|scale=1000.0
2022-03-20 23:10:49,324|13612|application_1639015019875_1326|TIME|Start
2022-03-20 23:10:58,941|23229|application_1639015019875_1326|INFO|edgesA=748520
2022-03-20 23:11:04,842|29130|application_1639015019875_1326|INFO|edgesB=746684
2022-03-20 23:11:04,853|29141|application_1639015019875_1326|TIME|Read
2022-03-20 23:11:21,598|45886|application_1639015019875_1326|TIME|Saving
./Perf -d Census/S/LA -p 365 -t 1e-3 -n 1
DATASET    = Census/S/LA
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 365
Run 1 ./sdcel2_debug Census/S/LA/P365 /home/acald013/RIDIR/local_path/Census/S/LA/P365/ 1e-3 "365_Census/S/LA_1e-3_1"
2022-03-20 23:11:38,912|13316|application_1639015019875_1327|13556|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/LA/P365/edgesA --input2 Census/S/LA/P365/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/LA/P365//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/LA/P365//boundary.wkt --tolerance 1e-3 --qtag 365_Census/S/LA_1e-3_1 --debug --local
2022-03-20 23:11:39,015|13419|application_1639015019875_1327|INFO|scale=1000.0
2022-03-20 23:11:39,111|13515|Saved /tmp/edgesCells_365.wkt in 0.00s [985 records].
2022-03-20 23:11:39,112|13516|application_1639015019875_1327|INFO|npartitions=985
2022-03-20 23:11:39,112|13516|application_1639015019875_1327|200|TIME|start|365_Census/S/LA_1e-3_1
2022-03-20 23:11:51,953|26357|application_1639015019875_1327|INFO|nEdgesA=754141
2022-03-20 23:11:55,682|30086|application_1639015019875_1327|INFO|nEdgesB=752373
2022-03-20 23:11:55,682|30086|application_1639015019875_1327|16570|TIME|read|365_Census/S/LA_1e-3_1
2022-03-20 23:12:00,086|34490|application_1639015019875_1327|4404|TIME|layer1S|365_Census/S/LA_1e-3_1
2022-03-20 23:12:02,116|36520|Saved /tmp/edgesFAC.wkt in 0.19s [4841 records].
2022-03-20 23:12:04,171|38575|application_1639015019875_1327|4085|TIME|layer2S|365_Census/S/LA_1e-3_1
2022-03-20 23:12:06,264|40668|Saved /tmp/edgesFBC.wkt in 0.26s [4916 records].
2022-03-20 23:12:47,434|81838|Saved /tmp/edgesS.wkt in 0.22s [11439 records].
2022-03-20 23:12:49,431|83835|application_1639015019875_1327|45260|TIME|overlayS|365_Census/S/LA_1e-3_1
2022-03-20 23:12:50,250|84654|Saved /tmp/edgesFE.wkt in 0.23s [1958 records].
2022-03-20 23:12:50,251|84655|application_1639015019875_1327|820|TIME|end|365_Census/S/LA_1e-3_1
hdfs dfs -mkdir Census/S/ME/
hdfs dfs -put ~/Datasets/Census/ME/ME2000.wkt Census/S/ME/A.wkt
hdfs dfs -put ~/Datasets/Census/ME/ME2010.wkt Census/S/ME/B.wkt
./QuadPart -d Census/S/ME -p 146 -t 1e-3
DATASET    = Census/S/ME
TOLERANCE  = 1e-3
PARTITIONS = 146
./QuadPlusPart 146 Census/S/ME 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/ME/P146 ...
2022-03-20 23:13:09,026|2798|local-1647843187380|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/ME/A.wkt --input2 Census/S/ME/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/ME/P146/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/ME/P146/boundary.wkt --partitions 146 --tolerance 1e-3
2022-03-20 23:13:09,027|2799|local-1647843187380|INFO|scale=1000.0
2022-03-20 23:13:09,036|2808|local-1647843187380|TIME|Start
2022-03-20 23:13:16,015|9787|local-1647843187380|INFO|edgesA=291660
2022-03-20 23:13:17,109|10881|local-1647843187380|INFO|edgesB=298814
2022-03-20 23:13:17,320|11092|local-1647843187380|TIME|Read
2022-03-20 23:13:17,320|11092|Partition by number (146)
2022-03-20 23:13:17,324|11096|Fraction: 0.010573065403762693
2022-03-20 23:13:17,899|11671|local-1647843187380|INFO|partitions=421
2022-03-20 23:13:17,900|11672|local-1647843187380|TIME|Partition
2022-03-20 23:13:17,903|11675|Saved /home/acald013/RIDIR/local_path/Census/S/ME/P146/boundary.wkt in 0.00s [1 records].
2022-03-20 23:13:17,959|11731|Saved /home/acald013/RIDIR/local_path/Census/S/ME/P146/quadtree.wkt in 0.00s [421 records].
2022-03-20 23:13:18,107|11879|local-1647843187380|TIME|Close
Partitioning edges...
rm -f -r Census/S/ME/P146/edgesA/
rm -f -r Census/S/ME/P146/edgesB/
2022-03-20 23:13:35,402|13801|application_1639015019875_1328|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/ME/A.wkt --input2 Census/S/ME/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/ME/P146/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/ME/P146/boundary.wkt --apath Census/S/ME/P146/edgesA --bpath Census/S/ME/P146/edgesB --tolerance 1e-3 --save
2022-03-20 23:13:35,402|13801|application_1639015019875_1328|INFO|scale=1000.0
2022-03-20 23:13:35,414|13813|application_1639015019875_1328|TIME|Start
2022-03-20 23:13:48,620|27019|application_1639015019875_1328|INFO|edgesA=291660
2022-03-20 23:13:54,082|32481|application_1639015019875_1328|INFO|edgesB=298814
2022-03-20 23:13:54,090|32489|application_1639015019875_1328|TIME|Read
2022-03-20 23:14:04,150|42549|application_1639015019875_1328|TIME|Saving
./Perf -d Census/S/ME -p 146 -t 1e-3 -n 1
DATASET    = Census/S/ME
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 146
Run 1 ./sdcel2_debug Census/S/ME/P146 /home/acald013/RIDIR/local_path/Census/S/ME/P146/ 1e-3 "146_Census/S/ME_1e-3_1"
2022-03-20 23:14:21,896|13759|application_1639015019875_1329|14043|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/ME/P146/edgesA --input2 Census/S/ME/P146/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/ME/P146//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/ME/P146//boundary.wkt --tolerance 1e-3 --qtag 146_Census/S/ME_1e-3_1 --debug --local
2022-03-20 23:14:21,971|13834|application_1639015019875_1329|INFO|scale=1000.0
2022-03-20 23:14:22,033|13896|Saved /tmp/edgesCells_146.wkt in 0.00s [421 records].
2022-03-20 23:14:22,034|13897|application_1639015019875_1329|INFO|npartitions=421
2022-03-20 23:14:22,034|13897|application_1639015019875_1329|138|TIME|start|146_Census/S/ME_1e-3_1
2022-03-20 23:14:33,199|25062|application_1639015019875_1329|INFO|nEdgesA=293724
2022-03-20 23:14:35,061|26924|application_1639015019875_1329|INFO|nEdgesB=301016
2022-03-20 23:14:35,061|26924|application_1639015019875_1329|13027|TIME|read|146_Census/S/ME_1e-3_1
2022-03-20 23:14:36,904|28767|application_1639015019875_1329|1843|TIME|layer1S|146_Census/S/ME_1e-3_1
2022-03-20 23:14:37,862|29725|Saved /tmp/edgesFAC.wkt in 0.07s [1788 records].
2022-03-20 23:14:38,839|30702|application_1639015019875_1329|1935|TIME|layer2S|146_Census/S/ME_1e-3_1
2022-03-20 23:14:39,827|31690|Saved /tmp/edgesFBC.wkt in 0.07s [1857 records].
2022-03-20 23:15:28,353|80216|Saved /tmp/edgesS.wkt in 0.09s [4445 records].
2022-03-20 23:15:29,493|81356|application_1639015019875_1329|50654|TIME|overlayS|146_Census/S/ME_1e-3_1
2022-03-20 23:15:29,927|81790|Saved /tmp/edgesFE.wkt in 0.07s [763 records].
2022-03-20 23:15:29,928|81791|application_1639015019875_1329|435|TIME|end|146_Census/S/ME_1e-3_1
hdfs dfs -mkdir Census/S/MD/
hdfs dfs -put ~/Datasets/Census/MD/MD2000.wkt Census/S/MD/A.wkt
hdfs dfs -put ~/Datasets/Census/MD/MD2010.wkt Census/S/MD/B.wkt
./QuadPart -d Census/S/MD -p 274 -t 1e-3
DATASET    = Census/S/MD
TOLERANCE  = 1e-3
PARTITIONS = 274
./QuadPlusPart 274 Census/S/MD 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/MD/P274 ...
2022-03-20 23:15:49,068|2880|local-1647843347434|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MD/A.wkt --input2 Census/S/MD/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/MD/P274/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/MD/P274/boundary.wkt --partitions 274 --tolerance 1e-3
2022-03-20 23:15:49,069|2881|local-1647843347434|INFO|scale=1000.0
2022-03-20 23:15:49,077|2889|local-1647843347434|TIME|Start
2022-03-20 23:15:57,197|11009|local-1647843347434|INFO|edgesA=535329
2022-03-20 23:15:59,056|12868|local-1647843347434|INFO|edgesB=560134
2022-03-20 23:15:59,255|13067|local-1647843347434|TIME|Read
2022-03-20 23:15:59,256|13068|Partition by number (274)
2022-03-20 23:15:59,260|13072|Fraction: 0.010417973217140577
2022-03-20 23:15:59,755|13567|local-1647843347434|INFO|partitions=697
2022-03-20 23:15:59,755|13567|local-1647843347434|TIME|Partition
2022-03-20 23:15:59,759|13571|Saved /home/acald013/RIDIR/local_path/Census/S/MD/P274/boundary.wkt in 0.00s [1 records].
2022-03-20 23:15:59,834|13646|Saved /home/acald013/RIDIR/local_path/Census/S/MD/P274/quadtree.wkt in 0.00s [697 records].
2022-03-20 23:16:00,172|13984|local-1647843347434|TIME|Close
Partitioning edges...
rm -f -r Census/S/MD/P274/edgesA/
rm -f -r Census/S/MD/P274/edgesB/
2022-03-20 23:16:17,331|13691|application_1639015019875_1330|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MD/A.wkt --input2 Census/S/MD/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/MD/P274/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MD/P274/boundary.wkt --apath Census/S/MD/P274/edgesA --bpath Census/S/MD/P274/edgesB --tolerance 1e-3 --save
2022-03-20 23:16:17,332|13692|application_1639015019875_1330|INFO|scale=1000.0
2022-03-20 23:16:17,344|13704|application_1639015019875_1330|TIME|Start
2022-03-20 23:16:27,113|23473|application_1639015019875_1330|INFO|edgesA=535329
2022-03-20 23:16:32,900|29260|application_1639015019875_1330|INFO|edgesB=560134
2022-03-20 23:16:32,910|29270|application_1639015019875_1330|TIME|Read
2022-03-20 23:16:47,694|44054|application_1639015019875_1330|TIME|Saving
./Perf -d Census/S/MD -p 274 -t 1e-3 -n 1
DATASET    = Census/S/MD
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 274
Run 1 ./sdcel2_debug Census/S/MD/P274 /home/acald013/RIDIR/local_path/Census/S/MD/P274/ 1e-3 "274_Census/S/MD_1e-3_1"
2022-03-20 23:17:04,804|13195|application_1639015019875_1331|13442|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MD/P274/edgesA --input2 Census/S/MD/P274/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/MD/P274//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MD/P274//boundary.wkt --tolerance 1e-3 --qtag 274_Census/S/MD_1e-3_1 --debug --local
2022-03-20 23:17:04,902|13293|application_1639015019875_1331|INFO|scale=1000.0
2022-03-20 23:17:04,987|13378|Saved /tmp/edgesCells_274.wkt in 0.00s [697 records].
2022-03-20 23:17:04,988|13379|application_1639015019875_1331|INFO|npartitions=697
2022-03-20 23:17:04,988|13379|application_1639015019875_1331|184|TIME|start|274_Census/S/MD_1e-3_1
2022-03-20 23:17:16,936|25327|application_1639015019875_1331|INFO|nEdgesA=540365
2022-03-20 23:17:19,511|27902|application_1639015019875_1331|INFO|nEdgesB=565684
2022-03-20 23:17:19,512|27903|application_1639015019875_1331|14524|TIME|read|274_Census/S/MD_1e-3_1
2022-03-20 23:17:22,138|30529|application_1639015019875_1331|2626|TIME|layer1S|274_Census/S/MD_1e-3_1
2022-03-20 23:17:23,692|32083|Saved /tmp/edgesFAC.wkt in 0.23s [4379 records].
2022-03-20 23:17:25,046|33437|application_1639015019875_1331|2908|TIME|layer2S|274_Census/S/MD_1e-3_1
2022-03-20 23:17:26,446|34837|Saved /tmp/edgesFBC.wkt in 0.12s [4799 records].
2022-03-20 23:18:17,493|85884|Saved /tmp/edgesS.wkt in 0.17s [11118 records].
2022-03-20 23:18:19,270|87661|application_1639015019875_1331|54224|TIME|overlayS|274_Census/S/MD_1e-3_1
2022-03-20 23:18:20,119|88510|Saved /tmp/edgesFE.wkt in 0.20s [2189 records].
2022-03-20 23:18:20,119|88510|application_1639015019875_1331|849|TIME|end|274_Census/S/MD_1e-3_1
hdfs dfs -mkdir Census/S/MA/
hdfs dfs -put ~/Datasets/Census/MA/MA2000.wkt Census/S/MA/A.wkt
hdfs dfs -put ~/Datasets/Census/MA/MA2010.wkt Census/S/MA/B.wkt
./QuadPart -d Census/S/MA -p 188 -t 1e-3
DATASET    = Census/S/MA
TOLERANCE  = 1e-3
PARTITIONS = 188
./QuadPlusPart 188 Census/S/MA 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/MA/P188 ...
2022-03-20 23:18:39,052|2831|local-1647843517433|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MA/A.wkt --input2 Census/S/MA/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/MA/P188/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/MA/P188/boundary.wkt --partitions 188 --tolerance 1e-3
2022-03-20 23:18:39,052|2831|local-1647843517433|INFO|scale=1000.0
2022-03-20 23:18:39,061|2840|local-1647843517433|TIME|Start
2022-03-20 23:18:46,122|9901|local-1647843517433|INFO|edgesA=351541
2022-03-20 23:18:47,502|11281|local-1647843517433|INFO|edgesB=383252
2022-03-20 23:18:47,689|11468|local-1647843517433|TIME|Read
2022-03-20 23:18:47,689|11468|Partition by number (188)
2022-03-20 23:18:47,694|11473|Fraction: 0.010512085772682112
2022-03-20 23:18:48,303|12082|local-1647843517433|INFO|partitions=478
2022-03-20 23:18:48,304|12083|local-1647843517433|TIME|Partition
2022-03-20 23:18:48,308|12087|Saved /home/acald013/RIDIR/local_path/Census/S/MA/P188/boundary.wkt in 0.00s [1 records].
2022-03-20 23:18:48,364|12143|Saved /home/acald013/RIDIR/local_path/Census/S/MA/P188/quadtree.wkt in 0.00s [478 records].
2022-03-20 23:18:48,529|12308|local-1647843517433|TIME|Close
Partitioning edges...
rm -f -r Census/S/MA/P188/edgesA/
rm -f -r Census/S/MA/P188/edgesB/
2022-03-20 23:19:23,415|31519|application_1639015019875_1332|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MA/A.wkt --input2 Census/S/MA/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/MA/P188/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MA/P188/boundary.wkt --apath Census/S/MA/P188/edgesA --bpath Census/S/MA/P188/edgesB --tolerance 1e-3 --save
2022-03-20 23:19:23,416|31520|application_1639015019875_1332|INFO|scale=1000.0
2022-03-20 23:19:23,434|31538|application_1639015019875_1332|TIME|Start
2022-03-20 23:19:32,737|40841|application_1639015019875_1332|INFO|edgesA=351541
2022-03-20 23:19:38,527|46631|application_1639015019875_1332|INFO|edgesB=383252
2022-03-20 23:19:38,534|46638|application_1639015019875_1332|TIME|Read
2022-03-20 23:19:49,462|57566|application_1639015019875_1332|TIME|Saving
./Perf -d Census/S/MA -p 188 -t 1e-3 -n 1
DATASET    = Census/S/MA
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 188
Run 1 ./sdcel2_debug Census/S/MA/P188 /home/acald013/RIDIR/local_path/Census/S/MA/P188/ 1e-3 "188_Census/S/MA_1e-3_1"
2022-03-20 23:20:07,036|13759|application_1639015019875_1333|14016|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MA/P188/edgesA --input2 Census/S/MA/P188/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/MA/P188//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MA/P188//boundary.wkt --tolerance 1e-3 --qtag 188_Census/S/MA_1e-3_1 --debug --local
2022-03-20 23:20:07,107|13830|application_1639015019875_1333|INFO|scale=1000.0
2022-03-20 23:20:07,173|13896|Saved /tmp/edgesCells_188.wkt in 0.00s [478 records].
2022-03-20 23:20:07,174|13897|application_1639015019875_1333|INFO|npartitions=478
2022-03-20 23:20:07,174|13897|application_1639015019875_1333|138|TIME|start|188_Census/S/MA_1e-3_1
2022-03-20 23:20:18,192|24915|application_1639015019875_1333|INFO|nEdgesA=356042
2022-03-20 23:20:20,519|27242|application_1639015019875_1333|INFO|nEdgesB=387951
2022-03-20 23:20:20,519|27242|application_1639015019875_1333|13345|TIME|read|188_Census/S/MA_1e-3_1
2022-03-20 23:20:22,158|28881|application_1639015019875_1333|1639|TIME|layer1S|188_Census/S/MA_1e-3_1
2022-03-20 23:20:23,324|30047|Saved /tmp/edgesFAC.wkt in 0.08s [4186 records].
2022-03-20 23:20:24,515|31238|application_1639015019875_1333|2357|TIME|layer2S|188_Census/S/MA_1e-3_1
2022-03-20 23:20:25,735|32458|Saved /tmp/edgesFBC.wkt in 0.09s [4261 records].
2022-03-20 23:21:02,229|68952|Saved /tmp/edgesS.wkt in 0.13s [13956 records].
2022-03-20 23:21:04,037|70760|application_1639015019875_1333|39522|TIME|overlayS|188_Census/S/MA_1e-3_1
2022-03-20 23:21:04,439|71162|Saved /tmp/edgesFE.wkt in 0.10s [5310 records].
2022-03-20 23:21:04,439|71162|application_1639015019875_1333|402|TIME|end|188_Census/S/MA_1e-3_1
hdfs dfs -mkdir Census/S/MI/
hdfs dfs -put ~/Datasets/Census/MI/MI2000.wkt Census/S/MI/A.wkt
hdfs dfs -put ~/Datasets/Census/MI/MI2010.wkt Census/S/MI/B.wkt
./QuadPart -d Census/S/MI -p 262 -t 1e-3
DATASET    = Census/S/MI
TOLERANCE  = 1e-3
PARTITIONS = 262
./QuadPlusPart 262 Census/S/MI 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/MI/P262 ...
2022-03-20 23:21:24,295|3398|local-1647843682422|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MI/A.wkt --input2 Census/S/MI/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/MI/P262/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/MI/P262/boundary.wkt --partitions 262 --tolerance 1e-3
2022-03-20 23:21:24,296|3399|local-1647843682422|INFO|scale=1000.0
2022-03-20 23:21:24,304|3407|local-1647843682422|TIME|Start
2022-03-20 23:21:32,500|11603|local-1647843682422|INFO|edgesA=600592
2022-03-20 23:21:34,001|13104|local-1647843682422|INFO|edgesB=531925
2022-03-20 23:21:34,351|13454|local-1647843682422|TIME|Read
2022-03-20 23:21:34,351|13454|Partition by number (262)
2022-03-20 23:21:34,355|13458|Fraction: 0.010411363573936062
2022-03-20 23:21:34,993|14096|local-1647843682422|INFO|partitions=676
2022-03-20 23:21:34,993|14096|local-1647843682422|TIME|Partition
2022-03-20 23:21:34,998|14101|Saved /home/acald013/RIDIR/local_path/Census/S/MI/P262/boundary.wkt in 0.00s [1 records].
2022-03-20 23:21:35,071|14174|Saved /home/acald013/RIDIR/local_path/Census/S/MI/P262/quadtree.wkt in 0.00s [676 records].
2022-03-20 23:21:35,268|14371|local-1647843682422|TIME|Close
Partitioning edges...
rm -f -r Census/S/MI/P262/edgesA/
rm -f -r Census/S/MI/P262/edgesB/
2022-03-20 23:21:52,111|13531|application_1639015019875_1334|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MI/A.wkt --input2 Census/S/MI/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/MI/P262/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MI/P262/boundary.wkt --apath Census/S/MI/P262/edgesA --bpath Census/S/MI/P262/edgesB --tolerance 1e-3 --save
2022-03-20 23:21:52,111|13531|application_1639015019875_1334|INFO|scale=1000.0
2022-03-20 23:21:52,124|13544|application_1639015019875_1334|TIME|Start
2022-03-20 23:22:01,700|23120|application_1639015019875_1334|INFO|edgesA=600592
2022-03-20 23:22:07,528|28948|application_1639015019875_1334|INFO|edgesB=531925
2022-03-20 23:22:07,536|28956|application_1639015019875_1334|TIME|Read
2022-03-20 23:22:20,735|42155|application_1639015019875_1334|TIME|Saving
./Perf -d Census/S/MI -p 262 -t 1e-3 -n 1
DATASET    = Census/S/MI
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 262
Run 1 ./sdcel2_debug Census/S/MI/P262 /home/acald013/RIDIR/local_path/Census/S/MI/P262/ 1e-3 "262_Census/S/MI_1e-3_1"
2022-03-20 23:22:38,062|13463|application_1639015019875_1335|13702|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MI/P262/edgesA --input2 Census/S/MI/P262/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/MI/P262//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MI/P262//boundary.wkt --tolerance 1e-3 --qtag 262_Census/S/MI_1e-3_1 --debug --local
2022-03-20 23:22:38,150|13551|application_1639015019875_1335|INFO|scale=1000.0
2022-03-20 23:22:38,245|13646|Saved /tmp/edgesCells_262.wkt in 0.00s [676 records].
2022-03-20 23:22:38,245|13646|application_1639015019875_1335|INFO|npartitions=676
2022-03-20 23:22:38,245|13646|application_1639015019875_1335|184|TIME|start|262_Census/S/MI_1e-3_1
2022-03-20 23:22:49,992|25393|application_1639015019875_1335|INFO|nEdgesA=607355
2022-03-20 23:22:52,310|27711|application_1639015019875_1335|INFO|nEdgesB=538722
2022-03-20 23:22:52,310|27711|application_1639015019875_1335|14065|TIME|read|262_Census/S/MI_1e-3_1
2022-03-20 23:22:54,735|30136|application_1639015019875_1335|2425|TIME|layer1S|262_Census/S/MI_1e-3_1
2022-03-20 23:22:56,789|32190|Saved /tmp/edgesFAC.wkt in 0.25s [6878 records].
2022-03-20 23:22:58,008|33409|application_1639015019875_1335|3273|TIME|layer2S|262_Census/S/MI_1e-3_1
2022-03-20 23:22:59,643|35044|Saved /tmp/edgesFBC.wkt in 0.12s [6851 records].
2022-03-20 23:23:45,787|81188|Saved /tmp/edgesS.wkt in 0.17s [15097 records].
2022-03-20 23:23:47,865|83266|application_1639015019875_1335|49857|TIME|overlayS|262_Census/S/MI_1e-3_1
2022-03-20 23:23:48,492|83893|Saved /tmp/edgesFE.wkt in 0.16s [4225 records].
2022-03-20 23:23:48,493|83894|application_1639015019875_1335|628|TIME|end|262_Census/S/MI_1e-3_1
hdfs dfs -mkdir Census/S/MN/
hdfs dfs -put ~/Datasets/Census/MN/MN2000.wkt Census/S/MN/A.wkt
hdfs dfs -put ~/Datasets/Census/MN/MN2010.wkt Census/S/MN/B.wkt
./QuadPart -d Census/S/MN -p 353 -t 1e-3
DATASET    = Census/S/MN
TOLERANCE  = 1e-3
PARTITIONS = 353
./QuadPlusPart 353 Census/S/MN 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/MN/P353 ...
2022-03-20 23:24:07,700|2797|local-1647843846101|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MN/A.wkt --input2 Census/S/MN/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/MN/P353/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/MN/P353/boundary.wkt --partitions 353 --tolerance 1e-3
2022-03-20 23:24:07,701|2798|local-1647843846101|INFO|scale=1000.0
2022-03-20 23:24:07,709|2806|local-1647843846101|TIME|Start
2022-03-20 23:24:15,678|10775|local-1647843846101|INFO|edgesA=701956
2022-03-20 23:24:17,303|12400|local-1647843846101|INFO|edgesB=720544
2022-03-20 23:24:17,940|13037|local-1647843846101|TIME|Read
2022-03-20 23:24:17,940|13037|Partition by number (353)
2022-03-20 23:24:17,945|13042|Fraction: 0.010366387303587698
2022-03-20 23:24:18,263|13360|local-1647843846101|INFO|partitions=943
2022-03-20 23:24:18,264|13361|local-1647843846101|TIME|Partition
2022-03-20 23:24:18,268|13365|Saved /home/acald013/RIDIR/local_path/Census/S/MN/P353/boundary.wkt in 0.00s [1 records].
2022-03-20 23:24:18,353|13450|Saved /home/acald013/RIDIR/local_path/Census/S/MN/P353/quadtree.wkt in 0.00s [943 records].
2022-03-20 23:24:18,567|13664|local-1647843846101|TIME|Close
Partitioning edges...
rm -f -r Census/S/MN/P353/edgesA/
rm -f -r Census/S/MN/P353/edgesB/
2022-03-20 23:24:36,392|13972|application_1639015019875_1336|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MN/A.wkt --input2 Census/S/MN/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/MN/P353/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MN/P353/boundary.wkt --apath Census/S/MN/P353/edgesA --bpath Census/S/MN/P353/edgesB --tolerance 1e-3 --save
2022-03-20 23:24:36,393|13973|application_1639015019875_1336|INFO|scale=1000.0
2022-03-20 23:24:36,406|13986|application_1639015019875_1336|TIME|Start
2022-03-20 23:24:45,830|23410|application_1639015019875_1336|INFO|edgesA=701956
2022-03-20 23:24:51,698|29278|application_1639015019875_1336|INFO|edgesB=720544
2022-03-20 23:24:51,706|29286|application_1639015019875_1336|TIME|Read
2022-03-20 23:25:07,651|45231|application_1639015019875_1336|TIME|Saving
./Perf -d Census/S/MN -p 353 -t 1e-3 -n 1
DATASET    = Census/S/MN
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 353
Run 1 ./sdcel2_debug Census/S/MN/P353 /home/acald013/RIDIR/local_path/Census/S/MN/P353/ 1e-3 "353_Census/S/MN_1e-3_1"
2022-03-20 23:25:24,888|13509|application_1639015019875_1337|13754|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MN/P353/edgesA --input2 Census/S/MN/P353/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/MN/P353//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MN/P353//boundary.wkt --tolerance 1e-3 --qtag 353_Census/S/MN_1e-3_1 --debug --local
2022-03-20 23:25:24,983|13604|application_1639015019875_1337|INFO|scale=1000.0
2022-03-20 23:25:25,075|13696|Saved /tmp/edgesCells_353.wkt in 0.00s [943 records].
2022-03-20 23:25:25,075|13696|application_1639015019875_1337|INFO|npartitions=943
2022-03-20 23:25:25,075|13696|application_1639015019875_1337|187|TIME|start|353_Census/S/MN_1e-3_1
2022-03-20 23:25:37,823|26444|application_1639015019875_1337|INFO|nEdgesA=707424
2022-03-20 23:25:40,872|29493|application_1639015019875_1337|INFO|nEdgesB=726090
2022-03-20 23:25:40,872|29493|application_1639015019875_1337|15797|TIME|read|353_Census/S/MN_1e-3_1
2022-03-20 23:25:43,097|31718|application_1639015019875_1337|2225|TIME|layer1S|353_Census/S/MN_1e-3_1
2022-03-20 23:25:44,610|33231|Saved /tmp/edgesFAC.wkt in 0.11s [4892 records].
2022-03-20 23:25:46,247|34868|application_1639015019875_1337|3150|TIME|layer2S|353_Census/S/MN_1e-3_1
2022-03-20 23:25:48,058|36679|Saved /tmp/edgesFBC.wkt in 0.17s [4947 records].
2022-03-20 23:26:44,390|93011|Saved /tmp/edgesS.wkt in 0.18s [11135 records].
2022-03-20 23:26:46,888|95509|application_1639015019875_1337|60641|TIME|overlayS|353_Census/S/MN_1e-3_1
2022-03-20 23:26:47,591|96212|Saved /tmp/edgesFE.wkt in 0.16s [2088 records].
2022-03-20 23:26:47,592|96213|application_1639015019875_1337|704|TIME|end|353_Census/S/MN_1e-3_1
hdfs dfs -mkdir Census/S/MS/
hdfs dfs -put ~/Datasets/Census/MS/MS2000.wkt Census/S/MS/A.wkt
hdfs dfs -put ~/Datasets/Census/MS/MS2010.wkt Census/S/MS/B.wkt
./QuadPart -d Census/S/MS -p 394 -t 1e-3
DATASET    = Census/S/MS
TOLERANCE  = 1e-3
PARTITIONS = 394
./QuadPlusPart 394 Census/S/MS 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/MS/P394 ...
2022-03-20 23:27:07,558|2726|local-1647844025962|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MS/A.wkt --input2 Census/S/MS/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/MS/P394/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/MS/P394/boundary.wkt --partitions 394 --tolerance 1e-3
2022-03-20 23:27:07,559|2727|local-1647844025962|INFO|scale=1000.0
2022-03-20 23:27:07,567|2735|local-1647844025962|TIME|Start
2022-03-20 23:27:15,240|10408|local-1647844025962|INFO|edgesA=773123
2022-03-20 23:27:16,628|11796|local-1647844025962|INFO|edgesB=807269
2022-03-20 23:27:16,776|11944|local-1647844025962|TIME|Read
2022-03-20 23:27:16,777|11945|Partition by number (394)
2022-03-20 23:27:16,781|11949|Fraction: 0.010346690983489613
2022-03-20 23:27:17,157|12325|local-1647844025962|INFO|partitions=1126
2022-03-20 23:27:17,157|12325|local-1647844025962|TIME|Partition
2022-03-20 23:27:17,161|12329|Saved /home/acald013/RIDIR/local_path/Census/S/MS/P394/boundary.wkt in 0.00s [1 records].
2022-03-20 23:27:17,262|12430|Saved /home/acald013/RIDIR/local_path/Census/S/MS/P394/quadtree.wkt in 0.00s [1126 records].
2022-03-20 23:27:17,565|12733|local-1647844025962|TIME|Close
Partitioning edges...
rm -f -r Census/S/MS/P394/edgesA/
rm -f -r Census/S/MS/P394/edgesB/
2022-03-20 23:27:34,893|13651|application_1639015019875_1338|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MS/A.wkt --input2 Census/S/MS/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/MS/P394/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MS/P394/boundary.wkt --apath Census/S/MS/P394/edgesA --bpath Census/S/MS/P394/edgesB --tolerance 1e-3 --save
2022-03-20 23:27:34,894|13652|application_1639015019875_1338|INFO|scale=1000.0
2022-03-20 23:27:34,907|13665|application_1639015019875_1338|TIME|Start
2022-03-20 23:27:44,446|23204|application_1639015019875_1338|INFO|edgesA=773123
2022-03-20 23:27:50,192|28950|application_1639015019875_1338|INFO|edgesB=807269
2022-03-20 23:27:50,201|28959|application_1639015019875_1338|TIME|Read
2022-03-20 23:28:04,260|43018|application_1639015019875_1338|TIME|Saving
./Perf -d Census/S/MS -p 394 -t 1e-3 -n 1
DATASET    = Census/S/MS
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 394
Run 1 ./sdcel2_debug Census/S/MS/P394 /home/acald013/RIDIR/local_path/Census/S/MS/P394/ 1e-3 "394_Census/S/MS_1e-3_1"
2022-03-20 23:28:21,947|13956|application_1639015019875_1339|14215|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MS/P394/edgesA --input2 Census/S/MS/P394/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/MS/P394//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MS/P394//boundary.wkt --tolerance 1e-3 --qtag 394_Census/S/MS_1e-3_1 --debug --local
2022-03-20 23:28:22,056|14065|application_1639015019875_1339|INFO|scale=1000.0
2022-03-20 23:28:22,166|14175|Saved /tmp/edgesCells_394.wkt in 0.00s [1126 records].
2022-03-20 23:28:22,166|14175|application_1639015019875_1339|INFO|npartitions=1126
2022-03-20 23:28:22,166|14175|application_1639015019875_1339|219|TIME|start|394_Census/S/MS_1e-3_1
2022-03-20 23:28:34,930|26939|application_1639015019875_1339|INFO|nEdgesA=777899
2022-03-20 23:28:37,828|29837|application_1639015019875_1339|INFO|nEdgesB=812259
2022-03-20 23:28:37,829|29838|application_1639015019875_1339|15663|TIME|read|394_Census/S/MS_1e-3_1
2022-03-20 23:28:40,868|32877|application_1639015019875_1339|3039|TIME|layer1S|394_Census/S/MS_1e-3_1
2022-03-20 23:28:42,555|34564|Saved /tmp/edgesFAC.wkt in 0.17s [4052 records].
2022-03-20 23:28:44,704|36713|application_1639015019875_1339|3836|TIME|layer2S|394_Census/S/MS_1e-3_1
2022-03-20 23:28:46,549|38558|Saved /tmp/edgesFBC.wkt in 0.23s [4219 records].
2022-03-20 23:29:12,314|64323|Saved /tmp/edgesS.wkt in 0.19s [9671 records].
2022-03-20 23:29:14,189|66198|application_1639015019875_1339|29484|TIME|overlayS|394_Census/S/MS_1e-3_1
2022-03-20 23:29:14,959|66968|Saved /tmp/edgesFE.wkt in 0.18s [1222 records].
2022-03-20 23:29:14,959|66968|application_1639015019875_1339|771|TIME|end|394_Census/S/MS_1e-3_1
hdfs dfs -mkdir Census/S/MO/
hdfs dfs -put ~/Datasets/Census/MO/MO2000.wkt Census/S/MO/A.wkt
hdfs dfs -put ~/Datasets/Census/MO/MO2010.wkt Census/S/MO/B.wkt
./QuadPart -d Census/S/MO -p 485 -t 1e-3
DATASET    = Census/S/MO
TOLERANCE  = 1e-3
PARTITIONS = 485
./QuadPlusPart 485 Census/S/MO 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/MO/P485 ...
2022-03-20 23:29:35,276|2841|local-1647844173674|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MO/A.wkt --input2 Census/S/MO/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/MO/P485/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/MO/P485/boundary.wkt --partitions 485 --tolerance 1e-3
2022-03-20 23:29:35,277|2842|local-1647844173674|INFO|scale=1000.0
2022-03-20 23:29:35,286|2851|local-1647844173674|TIME|Start
2022-03-20 23:29:43,153|10718|local-1647844173674|INFO|edgesA=961153
2022-03-20 23:29:45,384|12949|local-1647844173674|INFO|edgesB=991572
2022-03-20 23:29:45,605|13170|local-1647844173674|TIME|Read
2022-03-20 23:29:45,605|13170|Partition by number (485)
2022-03-20 23:29:45,610|13175|Fraction: 0.010311759993398653
2022-03-20 23:29:46,459|14024|local-1647844173674|INFO|partitions=1270
2022-03-20 23:29:46,459|14024|local-1647844173674|TIME|Partition
2022-03-20 23:29:46,464|14029|Saved /home/acald013/RIDIR/local_path/Census/S/MO/P485/boundary.wkt in 0.00s [1 records].
2022-03-20 23:29:46,592|14157|Saved /home/acald013/RIDIR/local_path/Census/S/MO/P485/quadtree.wkt in 0.00s [1270 records].
2022-03-20 23:29:46,753|14318|local-1647844173674|TIME|Close
Partitioning edges...
rm -f -r Census/S/MO/P485/edgesA/
rm -f -r Census/S/MO/P485/edgesB/
2022-03-20 23:30:03,757|13518|application_1639015019875_1340|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MO/A.wkt --input2 Census/S/MO/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/MO/P485/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MO/P485/boundary.wkt --apath Census/S/MO/P485/edgesA --bpath Census/S/MO/P485/edgesB --tolerance 1e-3 --save
2022-03-20 23:30:03,757|13518|application_1639015019875_1340|INFO|scale=1000.0
2022-03-20 23:30:03,770|13531|application_1639015019875_1340|TIME|Start
2022-03-20 23:30:13,353|23114|application_1639015019875_1340|INFO|edgesA=961153
2022-03-20 23:30:19,248|29009|application_1639015019875_1340|INFO|edgesB=991572
2022-03-20 23:30:19,264|29025|application_1639015019875_1340|TIME|Read
2022-03-20 23:30:35,551|45312|application_1639015019875_1340|TIME|Saving
./Perf -d Census/S/MO -p 485 -t 1e-3 -n 1
DATASET    = Census/S/MO
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 485
Run 1 ./sdcel2_debug Census/S/MO/P485 /home/acald013/RIDIR/local_path/Census/S/MO/P485/ 1e-3 "485_Census/S/MO_1e-3_1"
2022-03-20 23:30:52,897|13567|application_1639015019875_1341|13826|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MO/P485/edgesA --input2 Census/S/MO/P485/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/MO/P485//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MO/P485//boundary.wkt --tolerance 1e-3 --qtag 485_Census/S/MO_1e-3_1 --debug --local
2022-03-20 23:30:52,999|13669|application_1639015019875_1341|INFO|scale=1000.0
2022-03-20 23:30:53,114|13784|Saved /tmp/edgesCells_485.wkt in 0.01s [1270 records].
2022-03-20 23:30:53,114|13784|application_1639015019875_1341|INFO|npartitions=1270
2022-03-20 23:30:53,115|13785|application_1639015019875_1341|218|TIME|start|485_Census/S/MO_1e-3_1
2022-03-20 23:31:06,247|26917|application_1639015019875_1341|INFO|nEdgesA=967864
2022-03-20 23:31:09,689|30359|application_1639015019875_1341|INFO|nEdgesB=998479
2022-03-20 23:31:09,690|30360|application_1639015019875_1341|16575|TIME|read|485_Census/S/MO_1e-3_1
2022-03-20 23:31:12,470|33140|application_1639015019875_1341|2780|TIME|layer1S|485_Census/S/MO_1e-3_1
2022-03-20 23:31:14,311|34981|Saved /tmp/edgesFAC.wkt in 0.32s [5824 records].
2022-03-20 23:31:16,215|36885|application_1639015019875_1341|3745|TIME|layer2S|485_Census/S/MO_1e-3_1
2022-03-20 23:31:18,134|38804|Saved /tmp/edgesFBC.wkt in 0.25s [5992 records].
2022-03-20 23:31:52,171|72841|Saved /tmp/edgesS.wkt in 0.36s [13363 records].
2022-03-20 23:31:53,964|74634|application_1639015019875_1341|37749|TIME|overlayS|485_Census/S/MO_1e-3_1
2022-03-20 23:31:54,864|75534|Saved /tmp/edgesFE.wkt in 0.24s [2040 records].
2022-03-20 23:31:54,864|75534|application_1639015019875_1341|900|TIME|end|485_Census/S/MO_1e-3_1
hdfs dfs -mkdir Census/S/MT/
hdfs dfs -put ~/Datasets/Census/MT/MT2000.wkt Census/S/MT/A.wkt
hdfs dfs -put ~/Datasets/Census/MT/MT2010.wkt Census/S/MT/B.wkt
./QuadPart -d Census/S/MT -p 303 -t 1e-3
DATASET    = Census/S/MT
TOLERANCE  = 1e-3
PARTITIONS = 303
./QuadPlusPart 303 Census/S/MT 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/MT/P303 ...
2022-03-20 23:32:14,819|2806|local-1647844333180|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MT/A.wkt --input2 Census/S/MT/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/MT/P303/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/MT/P303/boundary.wkt --partitions 303 --tolerance 1e-3
2022-03-20 23:32:14,819|2806|local-1647844333180|INFO|scale=1000.0
2022-03-20 23:32:14,828|2815|local-1647844333180|TIME|Start
2022-03-20 23:32:22,870|10857|local-1647844333180|INFO|edgesA=657284
2022-03-20 23:32:24,441|12428|local-1647844333180|INFO|edgesB=621702
2022-03-20 23:32:24,649|12636|local-1647844333180|TIME|Read
2022-03-20 23:32:24,649|12636|Partition by number (303)
2022-03-20 23:32:24,656|12643|Fraction: 0.010386091568256869
2022-03-20 23:32:25,115|13102|local-1647844333180|INFO|partitions=907
2022-03-20 23:32:25,115|13102|local-1647844333180|TIME|Partition
2022-03-20 23:32:25,118|13105|Saved /home/acald013/RIDIR/local_path/Census/S/MT/P303/boundary.wkt in 0.00s [1 records].
2022-03-20 23:32:25,203|13190|Saved /home/acald013/RIDIR/local_path/Census/S/MT/P303/quadtree.wkt in 0.00s [907 records].
2022-03-20 23:32:25,439|13426|local-1647844333180|TIME|Close
Partitioning edges...
rm -f -r Census/S/MT/P303/edgesA/
rm -f -r Census/S/MT/P303/edgesB/
2022-03-20 23:32:42,863|13955|application_1639015019875_1342|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MT/A.wkt --input2 Census/S/MT/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/MT/P303/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MT/P303/boundary.wkt --apath Census/S/MT/P303/edgesA --bpath Census/S/MT/P303/edgesB --tolerance 1e-3 --save
2022-03-20 23:32:42,863|13955|application_1639015019875_1342|INFO|scale=1000.0
2022-03-20 23:32:42,877|13969|application_1639015019875_1342|TIME|Start
2022-03-20 23:32:52,492|23584|application_1639015019875_1342|INFO|edgesA=657284
2022-03-20 23:32:58,032|29124|application_1639015019875_1342|INFO|edgesB=621702
2022-03-20 23:32:58,043|29135|application_1639015019875_1342|TIME|Read
2022-03-20 23:33:11,550|42642|application_1639015019875_1342|TIME|Saving
./Perf -d Census/S/MT -p 303 -t 1e-3 -n 1
DATASET    = Census/S/MT
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 303
Run 1 ./sdcel2_debug Census/S/MT/P303 /home/acald013/RIDIR/local_path/Census/S/MT/P303/ 1e-3 "303_Census/S/MT_1e-3_1"
2022-03-20 23:33:29,241|13996|application_1639015019875_1343|14243|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MT/P303/edgesA --input2 Census/S/MT/P303/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/MT/P303//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MT/P303//boundary.wkt --tolerance 1e-3 --qtag 303_Census/S/MT_1e-3_1 --debug --local
2022-03-20 23:33:29,334|14089|application_1639015019875_1343|INFO|scale=1000.0
2022-03-20 23:33:29,431|14186|Saved /tmp/edgesCells_303.wkt in 0.00s [907 records].
2022-03-20 23:33:29,432|14187|application_1639015019875_1343|INFO|npartitions=907
2022-03-20 23:33:29,432|14187|application_1639015019875_1343|191|TIME|start|303_Census/S/MT_1e-3_1
2022-03-20 23:33:41,964|26719|application_1639015019875_1343|INFO|nEdgesA=660492
2022-03-20 23:33:44,767|29522|application_1639015019875_1343|INFO|nEdgesB=624860
2022-03-20 23:33:44,767|29522|application_1639015019875_1343|15335|TIME|read|303_Census/S/MT_1e-3_1
2022-03-20 23:33:47,555|32310|application_1639015019875_1343|2788|TIME|layer1S|303_Census/S/MT_1e-3_1
2022-03-20 23:33:49,118|33873|Saved /tmp/edgesFAC.wkt in 0.17s [2724 records].
2022-03-20 23:33:50,960|35715|application_1639015019875_1343|3405|TIME|layer2S|303_Census/S/MT_1e-3_1
2022-03-20 23:33:52,652|37407|Saved /tmp/edgesFBC.wkt in 0.18s [2694 records].
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 18 (count at SDCEL2.scala:158) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867) 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:863) 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:677) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:109) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 	at java.lang.Thread.run(Thread.java:745) 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1348)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1869)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:158)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
hdfs dfs -mkdir Census/S/NE/
hdfs dfs -put ~/Datasets/Census/NE/NE2000.wkt Census/S/NE/A.wkt
hdfs dfs -put ~/Datasets/Census/NE/NE2010.wkt Census/S/NE/B.wkt
./QuadPart -d Census/S/NE -p 123 -t 1e-3
DATASET    = Census/S/NE
TOLERANCE  = 1e-3
PARTITIONS = 123
./QuadPlusPart 123 Census/S/NE 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/NE/P123 ...
2022-03-20 23:34:50,581|2803|local-1647844488940|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NE/A.wkt --input2 Census/S/NE/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/NE/P123/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/NE/P123/boundary.wkt --partitions 123 --tolerance 1e-3
2022-03-20 23:34:50,581|2803|local-1647844488940|INFO|scale=1000.0
2022-03-20 23:34:50,590|2812|local-1647844488940|TIME|Start
2022-03-20 23:34:57,611|9833|local-1647844488940|INFO|edgesA=255904
2022-03-20 23:34:58,673|10895|local-1647844488940|INFO|edgesB=251765
2022-03-20 23:34:58,812|11034|local-1647844488940|TIME|Read
2022-03-20 23:34:58,812|11034|Partition by number (123)
2022-03-20 23:34:58,816|11038|Fraction: 0.01061938435348341
2022-03-20 23:34:59,284|11506|local-1647844488940|INFO|partitions=316
2022-03-20 23:34:59,284|11506|local-1647844488940|TIME|Partition
2022-03-20 23:34:59,288|11510|Saved /home/acald013/RIDIR/local_path/Census/S/NE/P123/boundary.wkt in 0.00s [1 records].
2022-03-20 23:34:59,337|11559|Saved /home/acald013/RIDIR/local_path/Census/S/NE/P123/quadtree.wkt in 0.00s [316 records].
2022-03-20 23:34:59,491|11713|local-1647844488940|TIME|Close
Partitioning edges...
rm -f -r Census/S/NE/P123/edgesA/
rm -f -r Census/S/NE/P123/edgesB/
2022-03-20 23:35:16,154|13513|application_1639015019875_1344|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NE/A.wkt --input2 Census/S/NE/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/NE/P123/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NE/P123/boundary.wkt --apath Census/S/NE/P123/edgesA --bpath Census/S/NE/P123/edgesB --tolerance 1e-3 --save
2022-03-20 23:35:16,154|13513|application_1639015019875_1344|INFO|scale=1000.0
2022-03-20 23:35:16,167|13526|application_1639015019875_1344|TIME|Start
2022-03-20 23:35:25,683|23042|application_1639015019875_1344|INFO|edgesA=255904
2022-03-20 23:35:31,210|28569|application_1639015019875_1344|INFO|edgesB=251765
2022-03-20 23:35:31,217|28576|application_1639015019875_1344|TIME|Read
2022-03-20 23:35:40,465|37824|application_1639015019875_1344|TIME|Saving
./Perf -d Census/S/NE -p 123 -t 1e-3 -n 1
DATASET    = Census/S/NE
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 123
Run 1 ./sdcel2_debug Census/S/NE/P123 /home/acald013/RIDIR/local_path/Census/S/NE/P123/ 1e-3 "123_Census/S/NE_1e-3_1"
2022-03-20 23:35:57,858|13756|application_1639015019875_1345|14005|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NE/P123/edgesA --input2 Census/S/NE/P123/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/NE/P123//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NE/P123//boundary.wkt --tolerance 1e-3 --qtag 123_Census/S/NE_1e-3_1 --debug --local
2022-03-20 23:35:57,922|13820|application_1639015019875_1345|INFO|scale=1000.0
2022-03-20 23:35:57,974|13872|Saved /tmp/edgesCells_123.wkt in 0.00s [316 records].
2022-03-20 23:35:57,974|13872|application_1639015019875_1345|INFO|npartitions=316
2022-03-20 23:35:57,975|13873|application_1639015019875_1345|117|TIME|start|123_Census/S/NE_1e-3_1
2022-03-20 23:36:08,897|24795|application_1639015019875_1345|INFO|nEdgesA=257608
2022-03-20 23:36:10,599|26497|application_1639015019875_1345|INFO|nEdgesB=253489
2022-03-20 23:36:10,599|26497|application_1639015019875_1345|12624|TIME|read|123_Census/S/NE_1e-3_1
2022-03-20 23:36:12,406|28304|application_1639015019875_1345|1807|TIME|layer1S|123_Census/S/NE_1e-3_1
2022-03-20 23:36:13,220|29118|Saved /tmp/edgesFAC.wkt in 0.06s [1628 records].
2022-03-20 23:36:14,101|29999|application_1639015019875_1345|1695|TIME|layer2S|123_Census/S/NE_1e-3_1
2022-03-20 23:36:14,879|30777|Saved /tmp/edgesFBC.wkt in 0.05s [1663 records].
2022-03-20 23:36:34,912|50810|Saved /tmp/edgesS.wkt in 0.06s [3514 records].
2022-03-20 23:36:35,568|51466|application_1639015019875_1345|21467|TIME|overlayS|123_Census/S/NE_1e-3_1
2022-03-20 23:36:35,832|51730|Saved /tmp/edgesFE.wkt in 0.06s [680 records].
2022-03-20 23:36:35,832|51730|application_1639015019875_1345|264|TIME|end|123_Census/S/NE_1e-3_1
hdfs dfs -mkdir Census/S/NV/
hdfs dfs -put ~/Datasets/Census/NV/NV2000.wkt Census/S/NV/A.wkt
hdfs dfs -put ~/Datasets/Census/NV/NV2010.wkt Census/S/NV/B.wkt
./QuadPart -d Census/S/NV -p 148 -t 1e-3
DATASET    = Census/S/NV
TOLERANCE  = 1e-3
PARTITIONS = 148
./QuadPlusPart 148 Census/S/NV 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/NV/P148 ...
2022-03-20 23:36:54,814|2963|local-1647844613131|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NV/A.wkt --input2 Census/S/NV/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/NV/P148/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/NV/P148/boundary.wkt --partitions 148 --tolerance 1e-3
2022-03-20 23:36:54,815|2964|local-1647844613131|INFO|scale=1000.0
2022-03-20 23:36:54,823|2972|local-1647844613131|TIME|Start
2022-03-20 23:37:02,770|10919|local-1647844613131|INFO|edgesA=277559
2022-03-20 23:37:04,006|12155|local-1647844613131|INFO|edgesB=302008
2022-03-20 23:37:04,167|12316|local-1647844613131|TIME|Read
2022-03-20 23:37:04,168|12317|Partition by number (148)
2022-03-20 23:37:04,172|12321|Fraction: 0.010578695856879655
2022-03-20 23:37:04,623|12772|local-1647844613131|INFO|partitions=472
2022-03-20 23:37:04,623|12772|local-1647844613131|TIME|Partition
2022-03-20 23:37:04,627|12776|Saved /home/acald013/RIDIR/local_path/Census/S/NV/P148/boundary.wkt in 0.00s [1 records].
2022-03-20 23:37:04,691|12840|Saved /home/acald013/RIDIR/local_path/Census/S/NV/P148/quadtree.wkt in 0.00s [472 records].
2022-03-20 23:37:04,881|13030|local-1647844613131|TIME|Close
Partitioning edges...
rm -f -r Census/S/NV/P148/edgesA/
rm -f -r Census/S/NV/P148/edgesB/
2022-03-20 23:37:21,827|13608|application_1639015019875_1346|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NV/A.wkt --input2 Census/S/NV/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/NV/P148/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NV/P148/boundary.wkt --apath Census/S/NV/P148/edgesA --bpath Census/S/NV/P148/edgesB --tolerance 1e-3 --save
2022-03-20 23:37:21,827|13608|application_1639015019875_1346|INFO|scale=1000.0
2022-03-20 23:37:21,841|13622|application_1639015019875_1346|TIME|Start
2022-03-20 23:37:34,996|26777|application_1639015019875_1346|INFO|edgesA=277559
2022-03-20 23:37:40,697|32478|application_1639015019875_1346|INFO|edgesB=302008
2022-03-20 23:37:40,706|32487|application_1639015019875_1346|TIME|Read
2022-03-20 23:37:50,723|42504|application_1639015019875_1346|TIME|Saving
./Perf -d Census/S/NV -p 148 -t 1e-3 -n 1
DATASET    = Census/S/NV
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 148
Run 1 ./sdcel2_debug Census/S/NV/P148 /home/acald013/RIDIR/local_path/Census/S/NV/P148/ 1e-3 "148_Census/S/NV_1e-3_1"
2022-03-20 23:38:08,376|14050|application_1639015019875_1347|14300|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NV/P148/edgesA --input2 Census/S/NV/P148/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/NV/P148//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NV/P148//boundary.wkt --tolerance 1e-3 --qtag 148_Census/S/NV_1e-3_1 --debug --local
2022-03-20 23:38:08,452|14126|application_1639015019875_1347|INFO|scale=1000.0
2022-03-20 23:38:08,521|14195|Saved /tmp/edgesCells_148.wkt in 0.00s [472 records].
2022-03-20 23:38:08,521|14195|application_1639015019875_1347|INFO|npartitions=472
2022-03-20 23:38:08,521|14195|application_1639015019875_1347|145|TIME|start|148_Census/S/NV_1e-3_1
2022-03-20 23:38:19,518|25192|application_1639015019875_1347|INFO|nEdgesA=279508
2022-03-20 23:38:21,574|27248|application_1639015019875_1347|INFO|nEdgesB=304191
2022-03-20 23:38:21,574|27248|application_1639015019875_1347|13053|TIME|read|148_Census/S/NV_1e-3_1
2022-03-20 23:38:23,251|28925|application_1639015019875_1347|1677|TIME|layer1S|148_Census/S/NV_1e-3_1
2022-03-20 23:38:24,156|29830|Saved /tmp/edgesFAC.wkt in 0.06s [1897 records].
2022-03-20 23:38:25,163|30837|application_1639015019875_1347|1912|TIME|layer2S|148_Census/S/NV_1e-3_1
2022-03-20 23:38:26,248|31922|Saved /tmp/edgesFBC.wkt in 0.06s [2206 records].
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 18 (count at SDCEL2.scala:158) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867) 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:863) 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:677) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:109) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 	at java.lang.Thread.run(Thread.java:745) 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1348)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1869)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:158)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
hdfs dfs -mkdir Census/S/NH/
hdfs dfs -put ~/Datasets/Census/NH/NH2000.wkt Census/S/NH/A.wkt
hdfs dfs -put ~/Datasets/Census/NH/NH2010.wkt Census/S/NH/B.wkt
./QuadPart -d Census/S/NH -p 41 -t 1e-3
DATASET    = Census/S/NH
TOLERANCE  = 1e-3
PARTITIONS = 41
./QuadPlusPart 41 Census/S/NH 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/NH/P41 ...
2022-03-20 23:39:31,427|2839|local-1647844769784|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NH/A.wkt --input2 Census/S/NH/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/NH/P41/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/NH/P41/boundary.wkt --partitions 41 --tolerance 1e-3
2022-03-20 23:39:31,427|2839|local-1647844769784|INFO|scale=1000.0
2022-03-20 23:39:31,435|2847|local-1647844769784|TIME|Start
2022-03-20 23:39:38,051|9463|local-1647844769784|INFO|edgesA=78189
2022-03-20 23:39:38,786|10198|local-1647844769784|INFO|edgesB=83553
2022-03-20 23:39:38,932|10344|local-1647844769784|TIME|Read
2022-03-20 23:39:38,933|10345|Partition by number (41)
2022-03-20 23:39:38,937|10349|Fraction: 0.011122916959152889
2022-03-20 23:39:39,086|10498|local-1647844769784|INFO|partitions=115
2022-03-20 23:39:39,086|10498|local-1647844769784|TIME|Partition
2022-03-20 23:39:39,091|10503|Saved /home/acald013/RIDIR/local_path/Census/S/NH/P41/boundary.wkt in 0.00s [1 records].
2022-03-20 23:39:39,120|10532|Saved /home/acald013/RIDIR/local_path/Census/S/NH/P41/quadtree.wkt in 0.00s [115 records].
2022-03-20 23:39:39,274|10686|local-1647844769784|TIME|Close
Partitioning edges...
rm -f -r Census/S/NH/P41/edgesA/
rm -f -r Census/S/NH/P41/edgesB/
2022-03-20 23:39:55,986|13583|application_1639015019875_1348|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NH/A.wkt --input2 Census/S/NH/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/NH/P41/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NH/P41/boundary.wkt --apath Census/S/NH/P41/edgesA --bpath Census/S/NH/P41/edgesB --tolerance 1e-3 --save
2022-03-20 23:39:55,987|13584|application_1639015019875_1348|INFO|scale=1000.0
2022-03-20 23:39:56,000|13597|application_1639015019875_1348|TIME|Start
2022-03-20 23:40:04,753|22350|application_1639015019875_1348|INFO|edgesA=78189
2022-03-20 23:40:09,953|27550|application_1639015019875_1348|INFO|edgesB=83553
2022-03-20 23:40:09,961|27558|application_1639015019875_1348|TIME|Read
2022-03-20 23:40:17,821|35418|application_1639015019875_1348|TIME|Saving
./Perf -d Census/S/NH -p 41 -t 1e-3 -n 1
DATASET    = Census/S/NH
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 41
Run 1 ./sdcel2_debug Census/S/NH/P41 /home/acald013/RIDIR/local_path/Census/S/NH/P41/ 1e-3 "41_Census/S/NH_1e-3_1"
2022-03-20 23:40:35,288|13663|application_1639015019875_1349|13914|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NH/P41/edgesA --input2 Census/S/NH/P41/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/NH/P41//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NH/P41//boundary.wkt --tolerance 1e-3 --qtag 41_Census/S/NH_1e-3_1 --debug --local
2022-03-20 23:40:35,350|13725|application_1639015019875_1349|INFO|scale=1000.0
2022-03-20 23:40:35,387|13762|Saved /tmp/edgesCells_41.wkt in 0.00s [115 records].
2022-03-20 23:40:35,387|13762|application_1639015019875_1349|INFO|npartitions=115
2022-03-20 23:40:35,388|13763|application_1639015019875_1349|100|TIME|start|41_Census/S/NH_1e-3_1
2022-03-20 23:40:45,038|23413|application_1639015019875_1349|INFO|nEdgesA=79097
2022-03-20 23:40:46,079|24454|application_1639015019875_1349|INFO|nEdgesB=84479
2022-03-20 23:40:46,080|24455|application_1639015019875_1349|10692|TIME|read|41_Census/S/NH_1e-3_1
2022-03-20 23:40:47,339|25714|application_1639015019875_1349|1259|TIME|layer1S|41_Census/S/NH_1e-3_1
2022-03-20 23:40:47,823|26198|Saved /tmp/edgesFAC.wkt in 0.02s [811 records].
2022-03-20 23:40:48,573|26948|application_1639015019875_1349|1234|TIME|layer2S|41_Census/S/NH_1e-3_1
2022-03-20 23:40:49,134|27509|Saved /tmp/edgesFBC.wkt in 0.02s [841 records].
2022-03-20 23:41:07,021|45396|Saved /tmp/edgesS.wkt in 0.02s [2016 records].
2022-03-20 23:41:08,403|46778|application_1639015019875_1349|19830|TIME|overlayS|41_Census/S/NH_1e-3_1
2022-03-20 23:41:08,584|46959|Saved /tmp/edgesFE.wkt in 0.02s [569 records].
2022-03-20 23:41:08,584|46959|application_1639015019875_1349|181|TIME|end|41_Census/S/NH_1e-3_1
hdfs dfs -mkdir Census/S/NJ/
hdfs dfs -put ~/Datasets/Census/NJ/NJ2000.wkt Census/S/NJ/A.wkt
hdfs dfs -put ~/Datasets/Census/NJ/NJ2010.wkt Census/S/NJ/B.wkt
./QuadPart -d Census/S/NJ -p 228 -t 1e-3
DATASET    = Census/S/NJ
TOLERANCE  = 1e-3
PARTITIONS = 228
./QuadPlusPart 228 Census/S/NJ 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/NJ/P228 ...
2022-03-20 23:41:27,663|2948|local-1647844885904|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NJ/A.wkt --input2 Census/S/NJ/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/NJ/P228/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/NJ/P228/boundary.wkt --partitions 228 --tolerance 1e-3
2022-03-20 23:41:27,663|2948|local-1647844885904|INFO|scale=1000.0
2022-03-20 23:41:27,672|2957|local-1647844885904|TIME|Start
2022-03-20 23:41:35,297|10582|local-1647844885904|INFO|edgesA=471984
2022-03-20 23:41:36,575|11860|local-1647844885904|INFO|edgesB=464628
2022-03-20 23:41:36,732|12017|local-1647844885904|TIME|Read
2022-03-20 23:41:36,732|12017|Partition by number (228)
2022-03-20 23:41:36,736|12021|Fraction: 0.010453290645930575
2022-03-20 23:41:37,204|12489|local-1647844885904|INFO|partitions=553
2022-03-20 23:41:37,204|12489|local-1647844885904|TIME|Partition
2022-03-20 23:41:37,208|12493|Saved /home/acald013/RIDIR/local_path/Census/S/NJ/P228/boundary.wkt in 0.00s [1 records].
2022-03-20 23:41:37,276|12561|Saved /home/acald013/RIDIR/local_path/Census/S/NJ/P228/quadtree.wkt in 0.00s [553 records].
2022-03-20 23:41:37,454|12739|local-1647844885904|TIME|Close
Partitioning edges...
rm -f -r Census/S/NJ/P228/edgesA/
rm -f -r Census/S/NJ/P228/edgesB/
2022-03-20 23:42:09,111|28306|application_1639015019875_1350|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NJ/A.wkt --input2 Census/S/NJ/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/NJ/P228/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NJ/P228/boundary.wkt --apath Census/S/NJ/P228/edgesA --bpath Census/S/NJ/P228/edgesB --tolerance 1e-3 --save
2022-03-20 23:42:09,111|28306|application_1639015019875_1350|INFO|scale=1000.0
2022-03-20 23:42:09,127|28322|application_1639015019875_1350|TIME|Start
2022-03-20 23:42:18,505|37700|application_1639015019875_1350|INFO|edgesA=471984
2022-03-20 23:42:24,189|43384|application_1639015019875_1350|INFO|edgesB=464628
2022-03-20 23:42:24,201|43396|application_1639015019875_1350|TIME|Read
2022-03-20 23:42:35,771|54966|application_1639015019875_1350|TIME|Saving
./Perf -d Census/S/NJ -p 228 -t 1e-3 -n 1
DATASET    = Census/S/NJ
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 228
Run 1 ./sdcel2_debug Census/S/NJ/P228 /home/acald013/RIDIR/local_path/Census/S/NJ/P228/ 1e-3 "228_Census/S/NJ_1e-3_1"
2022-03-20 23:42:53,372|13784|application_1639015019875_1351|14032|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NJ/P228/edgesA --input2 Census/S/NJ/P228/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/NJ/P228//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NJ/P228//boundary.wkt --tolerance 1e-3 --qtag 228_Census/S/NJ_1e-3_1 --debug --local
2022-03-20 23:42:53,451|13863|application_1639015019875_1351|INFO|scale=1000.0
2022-03-20 23:42:53,526|13938|Saved /tmp/edgesCells_228.wkt in 0.00s [553 records].
2022-03-20 23:42:53,527|13939|application_1639015019875_1351|INFO|npartitions=553
2022-03-20 23:42:53,527|13939|application_1639015019875_1351|155|TIME|start|228_Census/S/NJ_1e-3_1
2022-03-20 23:43:05,158|25570|application_1639015019875_1351|INFO|nEdgesA=477769
2022-03-20 23:43:07,307|27719|application_1639015019875_1351|INFO|nEdgesB=470425
2022-03-20 23:43:07,307|27719|application_1639015019875_1351|13780|TIME|read|228_Census/S/NJ_1e-3_1
2022-03-20 23:43:09,053|29465|application_1639015019875_1351|1746|TIME|layer1S|228_Census/S/NJ_1e-3_1
2022-03-20 23:43:10,489|30901|Saved /tmp/edgesFAC.wkt in 0.11s [5358 records].
2022-03-20 23:43:11,714|32126|application_1639015019875_1351|2661|TIME|layer2S|228_Census/S/NJ_1e-3_1
2022-03-20 23:43:13,055|33467|Saved /tmp/edgesFBC.wkt in 0.12s [5413 records].
2022-03-20 23:43:50,982|71394|Saved /tmp/edgesS.wkt in 0.13s [12466 records].
2022-03-20 23:43:53,149|73561|application_1639015019875_1351|41435|TIME|overlayS|228_Census/S/NJ_1e-3_1
2022-03-20 23:43:53,593|74005|Saved /tmp/edgesFE.wkt in 0.11s [3257 records].
2022-03-20 23:43:53,594|74006|application_1639015019875_1351|445|TIME|end|228_Census/S/NJ_1e-3_1
hdfs dfs -mkdir Census/S/NM/
hdfs dfs -put ~/Datasets/Census/NM/NM2000.wkt Census/S/NM/A.wkt
hdfs dfs -put ~/Datasets/Census/NM/NM2010.wkt Census/S/NM/B.wkt
./QuadPart -d Census/S/NM -p 206 -t 1e-3
DATASET    = Census/S/NM
TOLERANCE  = 1e-3
PARTITIONS = 206
./QuadPlusPart 206 Census/S/NM 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/NM/P206 ...
2022-03-20 23:44:13,784|2988|local-1647845052075|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NM/A.wkt --input2 Census/S/NM/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/NM/P206/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/NM/P206/boundary.wkt --partitions 206 --tolerance 1e-3
2022-03-20 23:44:13,785|2989|local-1647845052075|INFO|scale=1000.0
2022-03-20 23:44:13,793|2997|local-1647845052075|TIME|Start
2022-03-20 23:44:21,508|10712|local-1647845052075|INFO|edgesA=412793
2022-03-20 23:44:22,594|11798|local-1647845052075|INFO|edgesB=421542
2022-03-20 23:44:22,736|11940|local-1647845052075|TIME|Read
2022-03-20 23:44:22,736|11940|Partition by number (206)
2022-03-20 23:44:22,740|11944|Fraction: 0.010480614738152169
2022-03-20 23:44:23,082|12286|local-1647845052075|INFO|partitions=598
2022-03-20 23:44:23,082|12286|local-1647845052075|TIME|Partition
2022-03-20 23:44:23,086|12290|Saved /home/acald013/RIDIR/local_path/Census/S/NM/P206/boundary.wkt in 0.00s [1 records].
2022-03-20 23:44:23,154|12358|Saved /home/acald013/RIDIR/local_path/Census/S/NM/P206/quadtree.wkt in 0.00s [598 records].
2022-03-20 23:44:23,319|12523|local-1647845052075|TIME|Close
Partitioning edges...
rm -f -r Census/S/NM/P206/edgesA/
rm -f -r Census/S/NM/P206/edgesB/
2022-03-20 23:44:40,145|13604|application_1639015019875_1352|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NM/A.wkt --input2 Census/S/NM/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/NM/P206/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NM/P206/boundary.wkt --apath Census/S/NM/P206/edgesA --bpath Census/S/NM/P206/edgesB --tolerance 1e-3 --save
2022-03-20 23:44:40,145|13604|application_1639015019875_1352|INFO|scale=1000.0
2022-03-20 23:44:40,158|13617|application_1639015019875_1352|TIME|Start
2022-03-20 23:44:49,569|23028|application_1639015019875_1352|INFO|edgesA=412793
2022-03-20 23:44:55,240|28699|application_1639015019875_1352|INFO|edgesB=421542
2022-03-20 23:44:55,250|28709|application_1639015019875_1352|TIME|Read
2022-03-20 23:45:06,031|39490|application_1639015019875_1352|TIME|Saving
./Perf -d Census/S/NM -p 206 -t 1e-3 -n 1
DATASET    = Census/S/NM
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 206
Run 1 ./sdcel2_debug Census/S/NM/P206 /home/acald013/RIDIR/local_path/Census/S/NM/P206/ 1e-3 "206_Census/S/NM_1e-3_1"
2022-03-20 23:45:23,217|13460|application_1639015019875_1353|13707|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NM/P206/edgesA --input2 Census/S/NM/P206/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/NM/P206//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NM/P206//boundary.wkt --tolerance 1e-3 --qtag 206_Census/S/NM_1e-3_1 --debug --local
2022-03-20 23:45:23,307|13550|application_1639015019875_1353|INFO|scale=1000.0
2022-03-20 23:45:23,385|13628|Saved /tmp/edgesCells_206.wkt in 0.00s [598 records].
2022-03-20 23:45:23,386|13629|application_1639015019875_1353|INFO|npartitions=598
2022-03-20 23:45:23,386|13629|application_1639015019875_1353|169|TIME|start|206_Census/S/NM_1e-3_1
2022-03-20 23:45:35,364|25607|application_1639015019875_1353|INFO|nEdgesA=415370
2022-03-20 23:45:37,570|27813|application_1639015019875_1353|INFO|nEdgesB=424093
2022-03-20 23:45:37,570|27813|application_1639015019875_1353|14184|TIME|read|206_Census/S/NM_1e-3_1
2022-03-20 23:45:39,258|29501|application_1639015019875_1353|1688|TIME|layer1S|206_Census/S/NM_1e-3_1
2022-03-20 23:45:40,231|30474|Saved /tmp/edgesFAC.wkt in 0.08s [2311 records].
2022-03-20 23:45:41,645|31888|application_1639015019875_1353|2387|TIME|layer2S|206_Census/S/NM_1e-3_1
2022-03-20 23:45:42,693|32936|Saved /tmp/edgesFBC.wkt in 0.10s [2332 records].
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 18 (count at SDCEL2.scala:158) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867) 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:863) 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:677) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:109) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 	at java.lang.Thread.run(Thread.java:745) 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1348)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1869)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:158)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
hdfs dfs -mkdir Census/S/NY/
hdfs dfs -put ~/Datasets/Census/NY/NY2000.wkt Census/S/NY/A.wkt
hdfs dfs -put ~/Datasets/Census/NY/NY2010.wkt Census/S/NY/B.wkt
./QuadPart -d Census/S/NY -p 365 -t 1e-3
DATASET    = Census/S/NY
TOLERANCE  = 1e-3
PARTITIONS = 365
./QuadPlusPart 365 Census/S/NY 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/NY/P365 ...
2022-03-20 23:46:41,169|2855|local-1647845199471|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NY/A.wkt --input2 Census/S/NY/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/NY/P365/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/NY/P365/boundary.wkt --partitions 365 --tolerance 1e-3
2022-03-20 23:46:41,170|2856|local-1647845199471|INFO|scale=1000.0
2022-03-20 23:46:41,179|2865|local-1647845199471|TIME|Start
2022-03-20 23:46:48,788|10474|local-1647845199471|INFO|edgesA=746251
2022-03-20 23:46:50,356|12042|local-1647845199471|INFO|edgesB=738924
2022-03-20 23:46:50,724|12410|local-1647845199471|TIME|Read
2022-03-20 23:46:50,724|12410|Partition by number (365)
2022-03-20 23:46:50,728|12414|Fraction: 0.01035792169309604
2022-03-20 23:46:51,048|12734|local-1647845199471|INFO|partitions=997
2022-03-20 23:46:51,048|12734|local-1647845199471|TIME|Partition
2022-03-20 23:46:51,052|12738|Saved /home/acald013/RIDIR/local_path/Census/S/NY/P365/boundary.wkt in 0.00s [1 records].
2022-03-20 23:46:51,138|12824|Saved /home/acald013/RIDIR/local_path/Census/S/NY/P365/quadtree.wkt in 0.00s [997 records].
2022-03-20 23:46:51,282|12968|local-1647845199471|TIME|Close
Partitioning edges...
rm -f -r Census/S/NY/P365/edgesA/
rm -f -r Census/S/NY/P365/edgesB/
2022-03-20 23:47:08,791|14177|application_1639015019875_1354|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NY/A.wkt --input2 Census/S/NY/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/NY/P365/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NY/P365/boundary.wkt --apath Census/S/NY/P365/edgesA --bpath Census/S/NY/P365/edgesB --tolerance 1e-3 --save
2022-03-20 23:47:08,791|14177|application_1639015019875_1354|INFO|scale=1000.0
2022-03-20 23:47:08,804|14190|application_1639015019875_1354|TIME|Start
2022-03-20 23:47:18,507|23893|application_1639015019875_1354|INFO|edgesA=746251
2022-03-20 23:47:24,335|29721|application_1639015019875_1354|INFO|edgesB=738924
2022-03-20 23:47:24,343|29729|application_1639015019875_1354|TIME|Read
2022-03-20 23:47:40,198|45584|application_1639015019875_1354|TIME|Saving
./Perf -d Census/S/NY -p 365 -t 1e-3 -n 1
DATASET    = Census/S/NY
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 365
Run 1 ./sdcel2_debug Census/S/NY/P365 /home/acald013/RIDIR/local_path/Census/S/NY/P365/ 1e-3 "365_Census/S/NY_1e-3_1"
2022-03-20 23:47:57,630|13776|application_1639015019875_1355|14041|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NY/P365/edgesA --input2 Census/S/NY/P365/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/NY/P365//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NY/P365//boundary.wkt --tolerance 1e-3 --qtag 365_Census/S/NY_1e-3_1 --debug --local
2022-03-20 23:47:57,731|13877|application_1639015019875_1355|INFO|scale=1000.0
2022-03-20 23:47:57,829|13975|Saved /tmp/edgesCells_365.wkt in 0.00s [997 records].
2022-03-20 23:47:57,829|13975|application_1639015019875_1355|INFO|npartitions=997
2022-03-20 23:47:57,829|13975|application_1639015019875_1355|199|TIME|start|365_Census/S/NY_1e-3_1
2022-03-20 23:48:10,305|26451|application_1639015019875_1355|INFO|nEdgesA=756336
2022-03-20 23:48:13,208|29354|application_1639015019875_1355|INFO|nEdgesB=749117
2022-03-20 23:48:13,209|29355|application_1639015019875_1355|15380|TIME|read|365_Census/S/NY_1e-3_1
2022-03-20 23:48:15,604|31750|application_1639015019875_1355|2395|TIME|layer1S|365_Census/S/NY_1e-3_1
2022-03-20 23:48:18,604|34750|Saved /tmp/edgesFAC.wkt in 0.20s [10886 records].
2022-03-20 23:48:20,764|36910|application_1639015019875_1355|5160|TIME|layer2S|365_Census/S/NY_1e-3_1
2022-03-20 23:48:23,709|39855|Saved /tmp/edgesFBC.wkt in 0.23s [10938 records].
2022-03-20 23:49:25,748|101894|Saved /tmp/edgesS.wkt in 0.29s [23788 records].
2022-03-20 23:49:27,565|103711|application_1639015019875_1355|66801|TIME|overlayS|365_Census/S/NY_1e-3_1
2022-03-20 23:49:28,342|104488|Saved /tmp/edgesFE.wkt in 0.18s [7845 records].
2022-03-20 23:49:28,342|104488|application_1639015019875_1355|777|TIME|end|365_Census/S/NY_1e-3_1
hdfs dfs -mkdir Census/S/NC/
hdfs dfs -put ~/Datasets/Census/NC/NC2000.wkt Census/S/NC/A.wkt
hdfs dfs -put ~/Datasets/Census/NC/NC2010.wkt Census/S/NC/B.wkt
./QuadPart -d Census/S/NC -p 764 -t 1e-3
DATASET    = Census/S/NC
TOLERANCE  = 1e-3
PARTITIONS = 764
./QuadPlusPart 764 Census/S/NC 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/NC/P764 ...
2022-03-20 23:49:50,056|2919|local-1647845388359|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NC/A.wkt --input2 Census/S/NC/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/NC/P764/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/NC/P764/boundary.wkt --partitions 764 --tolerance 1e-3
2022-03-20 23:49:50,057|2920|local-1647845388359|INFO|scale=1000.0
2022-03-20 23:49:50,065|2928|local-1647845388359|TIME|Start
2022-03-20 23:49:58,762|11625|local-1647845388359|INFO|edgesA=1357236
2022-03-20 23:50:01,797|14660|local-1647845388359|INFO|edgesB=1561176
2022-03-20 23:50:02,226|15089|local-1647845388359|TIME|Read
2022-03-20 23:50:02,226|15089|Partition by number (764)
2022-03-20 23:50:02,230|15093|Fraction: 0.01025436877903789
2022-03-20 23:50:02,683|15546|local-1647845388359|INFO|partitions=1987
2022-03-20 23:50:02,683|15546|local-1647845388359|TIME|Partition
2022-03-20 23:50:02,687|15550|Saved /home/acald013/RIDIR/local_path/Census/S/NC/P764/boundary.wkt in 0.00s [1 records].
2022-03-20 23:50:02,814|15677|Saved /home/acald013/RIDIR/local_path/Census/S/NC/P764/quadtree.wkt in 0.00s [1987 records].
2022-03-20 23:50:03,170|16033|local-1647845388359|TIME|Close
Partitioning edges...
rm -f -r Census/S/NC/P764/edgesA/
rm -f -r Census/S/NC/P764/edgesB/
2022-03-20 23:50:20,656|13859|application_1639015019875_1356|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NC/A.wkt --input2 Census/S/NC/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/NC/P764/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NC/P764/boundary.wkt --apath Census/S/NC/P764/edgesA --bpath Census/S/NC/P764/edgesB --tolerance 1e-3 --save
2022-03-20 23:50:20,657|13860|application_1639015019875_1356|INFO|scale=1000.0
2022-03-20 23:50:20,670|13873|application_1639015019875_1356|TIME|Start
2022-03-20 23:50:30,637|23840|application_1639015019875_1356|INFO|edgesA=1357236
2022-03-20 23:50:36,864|30067|application_1639015019875_1356|INFO|edgesB=1561176
2022-03-20 23:50:36,876|30079|application_1639015019875_1356|TIME|Read
2022-03-20 23:50:58,522|51725|application_1639015019875_1356|TIME|Saving
./Perf -d Census/S/NC -p 764 -t 1e-3 -n 1
DATASET    = Census/S/NC
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 764
Run 1 ./sdcel2_debug Census/S/NC/P764 /home/acald013/RIDIR/local_path/Census/S/NC/P764/ 1e-3 "764_Census/S/NC_1e-3_1"
2022-03-20 23:51:15,886|13598|application_1639015019875_1357|13843|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/NC/P764/edgesA --input2 Census/S/NC/P764/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/NC/P764//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/NC/P764//boundary.wkt --tolerance 1e-3 --qtag 764_Census/S/NC_1e-3_1 --debug --local
2022-03-20 23:51:16,003|13715|application_1639015019875_1357|INFO|scale=1000.0
2022-03-20 23:51:16,127|13839|Saved /tmp/edgesCells_764.wkt in 0.00s [1987 records].
2022-03-20 23:51:16,127|13839|application_1639015019875_1357|INFO|npartitions=1987
2022-03-20 23:51:16,127|13839|application_1639015019875_1357|241|TIME|start|764_Census/S/NC_1e-3_1
2022-03-20 23:51:31,370|29082|application_1639015019875_1357|INFO|nEdgesA=1367933
2022-03-20 23:51:36,127|33839|application_1639015019875_1357|INFO|nEdgesB=1573367
2022-03-20 23:51:36,127|33839|application_1639015019875_1357|20000|TIME|read|764_Census/S/NC_1e-3_1
2022-03-20 23:51:40,245|37957|application_1639015019875_1357|4118|TIME|layer1S|764_Census/S/NC_1e-3_1
2022-03-20 23:51:43,238|40950|Saved /tmp/edgesFAC.wkt in 0.26s [8776 records].
2022-03-20 23:51:46,368|44080|application_1639015019875_1357|6123|TIME|layer2S|764_Census/S/NC_1e-3_1
2022-03-20 23:51:49,097|46809|Saved /tmp/edgesFBC.wkt in 0.28s [10147 records].
2022-03-20 23:52:26,861|84573|Saved /tmp/edgesS.wkt in 0.35s [23676 records].
2022-03-20 23:52:30,633|88345|application_1639015019875_1357|44265|TIME|overlayS|764_Census/S/NC_1e-3_1
2022-03-20 23:52:32,083|89795|Saved /tmp/edgesFE.wkt in 0.49s [3571 records].
2022-03-20 23:52:32,084|89796|application_1639015019875_1357|1450|TIME|end|764_Census/S/NC_1e-3_1
hdfs dfs -mkdir Census/S/ND/
hdfs dfs -put ~/Datasets/Census/ND/ND2000.wkt Census/S/ND/A.wkt
hdfs dfs -put ~/Datasets/Census/ND/ND2010.wkt Census/S/ND/B.wkt
./QuadPart -d Census/S/ND -p 90 -t 1e-3
DATASET    = Census/S/ND
TOLERANCE  = 1e-3
PARTITIONS = 90
./QuadPlusPart 90 Census/S/ND 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/ND/P90 ...
2022-03-20 23:52:51,174|2925|local-1647845569517|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/ND/A.wkt --input2 Census/S/ND/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/ND/P90/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/ND/P90/boundary.wkt --partitions 90 --tolerance 1e-3
2022-03-20 23:52:51,174|2925|local-1647845569517|INFO|scale=1000.0
2022-03-20 23:52:51,183|2934|local-1647845569517|TIME|Start
2022-03-20 23:52:58,332|10083|local-1647845569517|INFO|edgesA=200759
2022-03-20 23:52:59,498|11249|local-1647845569517|INFO|edgesB=185037
2022-03-20 23:52:59,624|11375|local-1647845569517|TIME|Read
2022-03-20 23:52:59,624|11375|Partition by number (90)
2022-03-20 23:52:59,628|11379|Fraction: 0.010712705128956012
2022-03-20 23:52:59,864|11615|local-1647845569517|INFO|partitions=262
2022-03-20 23:52:59,864|11615|local-1647845569517|TIME|Partition
2022-03-20 23:52:59,868|11619|Saved /home/acald013/RIDIR/local_path/Census/S/ND/P90/boundary.wkt in 0.00s [1 records].
2022-03-20 23:52:59,916|11667|Saved /home/acald013/RIDIR/local_path/Census/S/ND/P90/quadtree.wkt in 0.00s [262 records].
2022-03-20 23:53:00,087|11838|local-1647845569517|TIME|Close
Partitioning edges...
rm -f -r Census/S/ND/P90/edgesA/
rm -f -r Census/S/ND/P90/edgesB/
2022-03-20 23:53:16,851|13510|application_1639015019875_1358|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/ND/A.wkt --input2 Census/S/ND/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/ND/P90/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/ND/P90/boundary.wkt --apath Census/S/ND/P90/edgesA --bpath Census/S/ND/P90/edgesB --tolerance 1e-3 --save
2022-03-20 23:53:16,852|13511|application_1639015019875_1358|INFO|scale=1000.0
2022-03-20 23:53:16,864|13523|application_1639015019875_1358|TIME|Start
2022-03-20 23:53:26,301|22960|application_1639015019875_1358|INFO|edgesA=200759
2022-03-20 23:53:35,920|32579|application_1639015019875_1358|INFO|edgesB=185037
2022-03-20 23:53:35,929|32588|application_1639015019875_1358|TIME|Read
2022-03-20 23:53:44,914|41573|application_1639015019875_1358|TIME|Saving
./Perf -d Census/S/ND -p 90 -t 1e-3 -n 1
DATASET    = Census/S/ND
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 90
Run 1 ./sdcel2_debug Census/S/ND/P90 /home/acald013/RIDIR/local_path/Census/S/ND/P90/ 1e-3 "90_Census/S/ND_1e-3_1"
2022-03-20 23:54:02,101|13590|application_1639015019875_1359|13839|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/ND/P90/edgesA --input2 Census/S/ND/P90/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/ND/P90//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/ND/P90//boundary.wkt --tolerance 1e-3 --qtag 90_Census/S/ND_1e-3_1 --debug --local
2022-03-20 23:54:02,168|13657|application_1639015019875_1359|INFO|scale=1000.0
2022-03-20 23:54:02,221|13710|Saved /tmp/edgesCells_90.wkt in 0.00s [262 records].
2022-03-20 23:54:02,221|13710|application_1639015019875_1359|INFO|npartitions=262
2022-03-20 23:54:02,222|13711|application_1639015019875_1359|121|TIME|start|90_Census/S/ND_1e-3_1
2022-03-20 23:54:12,596|24085|application_1639015019875_1359|INFO|nEdgesA=201897
2022-03-20 23:54:14,341|25830|application_1639015019875_1359|INFO|nEdgesB=186089
2022-03-20 23:54:14,342|25831|application_1639015019875_1359|12120|TIME|read|90_Census/S/ND_1e-3_1
2022-03-20 23:54:16,186|27675|application_1639015019875_1359|1844|TIME|layer1S|90_Census/S/ND_1e-3_1
2022-03-20 23:54:17,007|28496|Saved /tmp/edgesFAC.wkt in 0.04s [1030 records].
2022-03-20 23:54:18,082|29571|application_1639015019875_1359|1896|TIME|layer2S|90_Census/S/ND_1e-3_1
2022-03-20 23:54:18,805|30294|Saved /tmp/edgesFBC.wkt in 0.05s [953 records].
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 18 (count at SDCEL2.scala:158) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867) 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:863) 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:677) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:109) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 	at java.lang.Thread.run(Thread.java:745) 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1348)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1869)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:158)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
hdfs dfs -mkdir Census/S/OH/
hdfs dfs -put ~/Datasets/Census/OH/OH2000.wkt Census/S/OH/A.wkt
hdfs dfs -put ~/Datasets/Census/OH/OH2010.wkt Census/S/OH/B.wkt
./QuadPart -d Census/S/OH -p 439 -t 1e-3
DATASET    = Census/S/OH
TOLERANCE  = 1e-3
PARTITIONS = 439
./QuadPlusPart 439 Census/S/OH 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/OH/P439 ...
2022-03-20 23:55:04,112|2923|local-1647845702428|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/OH/A.wkt --input2 Census/S/OH/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/OH/P439/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/OH/P439/boundary.wkt --partitions 439 --tolerance 1e-3
2022-03-20 23:55:04,113|2924|local-1647845702428|INFO|scale=1000.0
2022-03-20 23:55:04,121|2932|local-1647845702428|TIME|Start
2022-03-20 23:55:12,477|11288|local-1647845702428|INFO|edgesA=897345
2022-03-20 23:55:14,159|12970|local-1647845702428|INFO|edgesB=893336
2022-03-20 23:55:14,366|13177|local-1647845702428|TIME|Read
2022-03-20 23:55:14,367|13178|Partition by number (439)
2022-03-20 23:55:14,370|13181|Fraction: 0.010325458187169501
2022-03-20 23:55:15,066|13877|local-1647845702428|INFO|partitions=1138
2022-03-20 23:55:15,066|13877|local-1647845702428|TIME|Partition
2022-03-20 23:55:15,071|13882|Saved /home/acald013/RIDIR/local_path/Census/S/OH/P439/boundary.wkt in 0.00s [1 records].
2022-03-20 23:55:15,165|13976|Saved /home/acald013/RIDIR/local_path/Census/S/OH/P439/quadtree.wkt in 0.00s [1138 records].
2022-03-20 23:55:15,331|14142|local-1647845702428|TIME|Close
Partitioning edges...
rm -f -r Census/S/OH/P439/edgesA/
rm -f -r Census/S/OH/P439/edgesB/
2022-03-20 23:55:32,669|13942|application_1639015019875_1360|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/OH/A.wkt --input2 Census/S/OH/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/OH/P439/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/OH/P439/boundary.wkt --apath Census/S/OH/P439/edgesA --bpath Census/S/OH/P439/edgesB --tolerance 1e-3 --save
2022-03-20 23:55:32,670|13943|application_1639015019875_1360|INFO|scale=1000.0
2022-03-20 23:55:32,684|13957|application_1639015019875_1360|TIME|Start
2022-03-20 23:55:42,407|23680|application_1639015019875_1360|INFO|edgesA=897345
2022-03-20 23:55:48,442|29715|application_1639015019875_1360|INFO|edgesB=893336
2022-03-20 23:55:48,450|29723|application_1639015019875_1360|TIME|Read
2022-03-20 23:56:03,525|44798|application_1639015019875_1360|TIME|Saving
./Perf -d Census/S/OH -p 439 -t 1e-3 -n 1
DATASET    = Census/S/OH
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 439
Run 1 ./sdcel2_debug Census/S/OH/P439 /home/acald013/RIDIR/local_path/Census/S/OH/P439/ 1e-3 "439_Census/S/OH_1e-3_1"
2022-03-20 23:56:20,687|13575|application_1639015019875_1361|13815|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/OH/P439/edgesA --input2 Census/S/OH/P439/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/OH/P439//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/OH/P439//boundary.wkt --tolerance 1e-3 --qtag 439_Census/S/OH_1e-3_1 --debug --local
2022-03-20 23:56:20,791|13679|application_1639015019875_1361|INFO|scale=1000.0
2022-03-20 23:56:20,907|13795|Saved /tmp/edgesCells_439.wkt in 0.01s [1138 records].
2022-03-20 23:56:20,907|13795|application_1639015019875_1361|INFO|npartitions=1138
2022-03-20 23:56:20,907|13795|application_1639015019875_1361|221|TIME|start|439_Census/S/OH_1e-3_1
2022-03-20 23:56:34,554|27442|application_1639015019875_1361|INFO|nEdgesA=906482
2022-03-20 23:56:38,066|30954|application_1639015019875_1361|INFO|nEdgesB=902531
2022-03-20 23:56:38,066|30954|application_1639015019875_1361|17159|TIME|read|439_Census/S/OH_1e-3_1
2022-03-20 23:56:41,088|33976|application_1639015019875_1361|3022|TIME|layer1S|439_Census/S/OH_1e-3_1
2022-03-20 23:56:43,048|35936|Saved /tmp/edgesFAC.wkt in 0.22s [8577 records].
2022-03-20 23:56:44,997|37885|application_1639015019875_1361|3909|TIME|layer2S|439_Census/S/OH_1e-3_1
2022-03-20 23:56:46,883|39771|Saved /tmp/edgesFBC.wkt in 0.26s [8602 records].
2022-03-20 23:57:20,638|73526|Saved /tmp/edgesS.wkt in 0.35s [19279 records].
2022-03-20 23:57:22,589|75477|application_1639015019875_1361|37592|TIME|overlayS|439_Census/S/OH_1e-3_1
2022-03-20 23:57:23,690|76578|Saved /tmp/edgesFE.wkt in 0.26s [4553 records].
2022-03-20 23:57:23,690|76578|application_1639015019875_1361|1101|TIME|end|439_Census/S/OH_1e-3_1
hdfs dfs -mkdir Census/S/OK/
hdfs dfs -put ~/Datasets/Census/OK/OK2000.wkt Census/S/OK/A.wkt
hdfs dfs -put ~/Datasets/Census/OK/OK2010.wkt Census/S/OK/B.wkt
./QuadPart -d Census/S/OK -p 345 -t 1e-3
DATASET    = Census/S/OK
TOLERANCE  = 1e-3
PARTITIONS = 345
./QuadPlusPart 345 Census/S/OK 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/OK/P345 ...
2022-03-20 23:57:42,944|2735|local-1647845861349|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/OK/A.wkt --input2 Census/S/OK/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/OK/P345/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/OK/P345/boundary.wkt --partitions 345 --tolerance 1e-3
2022-03-20 23:57:42,945|2736|local-1647845861349|INFO|scale=1000.0
2022-03-20 23:57:42,956|2747|local-1647845861349|TIME|Start
2022-03-20 23:57:50,676|10467|local-1647845861349|INFO|edgesA=687250
2022-03-20 23:57:52,223|12014|local-1647845861349|INFO|edgesB=705778
2022-03-20 23:57:52,449|12240|local-1647845861349|TIME|Read
2022-03-20 23:57:52,449|12240|Partition by number (345)
2022-03-20 23:57:52,454|12245|Fraction: 0.01037010824844236
2022-03-20 23:57:53,009|12800|local-1647845861349|INFO|partitions=907
2022-03-20 23:57:53,010|12801|local-1647845861349|TIME|Partition
2022-03-20 23:57:53,014|12805|Saved /home/acald013/RIDIR/local_path/Census/S/OK/P345/boundary.wkt in 0.00s [1 records].
2022-03-20 23:57:53,103|12894|Saved /home/acald013/RIDIR/local_path/Census/S/OK/P345/quadtree.wkt in 0.00s [907 records].
2022-03-20 23:57:53,281|13072|local-1647845861349|TIME|Close
Partitioning edges...
rm -f -r Census/S/OK/P345/edgesA/
rm -f -r Census/S/OK/P345/edgesB/
2022-03-20 23:58:10,802|14165|application_1639015019875_1362|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/OK/A.wkt --input2 Census/S/OK/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/OK/P345/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/OK/P345/boundary.wkt --apath Census/S/OK/P345/edgesA --bpath Census/S/OK/P345/edgesB --tolerance 1e-3 --save
2022-03-20 23:58:10,803|14166|application_1639015019875_1362|INFO|scale=1000.0
2022-03-20 23:58:10,815|14178|application_1639015019875_1362|TIME|Start
2022-03-20 23:58:20,483|23846|application_1639015019875_1362|INFO|edgesA=687250
2022-03-20 23:58:26,136|29499|application_1639015019875_1362|INFO|edgesB=705778
2022-03-20 23:58:26,145|29508|application_1639015019875_1362|TIME|Read
2022-03-20 23:58:41,806|45169|application_1639015019875_1362|TIME|Saving
./Perf -d Census/S/OK -p 345 -t 1e-3 -n 1
DATASET    = Census/S/OK
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 345
Run 1 ./sdcel2_debug Census/S/OK/P345 /home/acald013/RIDIR/local_path/Census/S/OK/P345/ 1e-3 "345_Census/S/OK_1e-3_1"
2022-03-20 23:58:59,685|14180|application_1639015019875_1363|14441|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/OK/P345/edgesA --input2 Census/S/OK/P345/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/OK/P345//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/OK/P345//boundary.wkt --tolerance 1e-3 --qtag 345_Census/S/OK_1e-3_1 --debug --local
2022-03-20 23:58:59,783|14278|application_1639015019875_1363|INFO|scale=1000.0
2022-03-20 23:58:59,886|14381|Saved /tmp/edgesCells_345.wkt in 0.00s [907 records].
2022-03-20 23:58:59,887|14382|application_1639015019875_1363|INFO|npartitions=907
2022-03-20 23:58:59,887|14382|application_1639015019875_1363|202|TIME|start|345_Census/S/OK_1e-3_1
2022-03-20 23:59:12,673|27168|application_1639015019875_1363|INFO|nEdgesA=692222
2022-03-20 23:59:15,476|29971|application_1639015019875_1363|INFO|nEdgesB=710898
2022-03-20 23:59:15,477|29972|application_1639015019875_1363|15590|TIME|read|345_Census/S/OK_1e-3_1
2022-03-20 23:59:18,206|32701|application_1639015019875_1363|2729|TIME|layer1S|345_Census/S/OK_1e-3_1
2022-03-20 23:59:19,941|34436|Saved /tmp/edgesFAC.wkt in 0.17s [4305 records].
2022-03-20 23:59:21,583|36078|application_1639015019875_1363|3377|TIME|layer2S|345_Census/S/OK_1e-3_1
2022-03-20 23:59:23,082|37577|Saved /tmp/edgesFBC.wkt in 0.11s [4435 records].
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 18 (count at SDCEL2.scala:158) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867) 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:863) 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:677) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:109) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 	at java.lang.Thread.run(Thread.java:745) 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1348)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1869)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:158)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
hdfs dfs -mkdir Census/S/OR/
hdfs dfs -put ~/Datasets/Census/OR/OR2000.wkt Census/S/OR/A.wkt
hdfs dfs -put ~/Datasets/Census/OR/OR2010.wkt Census/S/OR/B.wkt
./QuadPart -d Census/S/OR -p 464 -t 1e-3
DATASET    = Census/S/OR
TOLERANCE  = 1e-3
PARTITIONS = 464
./QuadPlusPart 464 Census/S/OR 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/OR/P464 ...
2022-03-21 00:00:21,711|3286|local-1647846019655|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/OR/A.wkt --input2 Census/S/OR/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/OR/P464/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/OR/P464/boundary.wkt --partitions 464 --tolerance 1e-3
2022-03-21 00:00:21,713|3288|local-1647846019655|INFO|scale=1000.0
2022-03-21 00:00:21,721|3296|local-1647846019655|TIME|Start
2022-03-21 00:00:30,167|11742|local-1647846019655|INFO|edgesA=923902
2022-03-21 00:00:32,440|14015|local-1647846019655|INFO|edgesB=949224
2022-03-21 00:00:32,629|14204|local-1647846019655|TIME|Read
2022-03-21 00:00:32,629|14204|Partition by number (464)
2022-03-21 00:00:32,633|14208|Fraction: 0.010318409814691926
2022-03-21 00:00:32,954|14529|local-1647846019655|INFO|partitions=1285
2022-03-21 00:00:32,954|14529|local-1647846019655|TIME|Partition
2022-03-21 00:00:32,958|14533|Saved /home/acald013/RIDIR/local_path/Census/S/OR/P464/boundary.wkt in 0.00s [1 records].
2022-03-21 00:00:33,103|14678|Saved /home/acald013/RIDIR/local_path/Census/S/OR/P464/quadtree.wkt in 0.00s [1285 records].
2022-03-21 00:00:33,519|15094|local-1647846019655|TIME|Close
Partitioning edges...
rm -f -r Census/S/OR/P464/edgesA/
rm -f -r Census/S/OR/P464/edgesB/
2022-03-21 00:00:50,749|13744|application_1639015019875_1364|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/OR/A.wkt --input2 Census/S/OR/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/OR/P464/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/OR/P464/boundary.wkt --apath Census/S/OR/P464/edgesA --bpath Census/S/OR/P464/edgesB --tolerance 1e-3 --save
2022-03-21 00:00:50,749|13744|application_1639015019875_1364|INFO|scale=1000.0
2022-03-21 00:00:50,762|13757|application_1639015019875_1364|TIME|Start
2022-03-21 00:01:00,314|23309|application_1639015019875_1364|INFO|edgesA=923902
2022-03-21 00:01:06,051|29046|application_1639015019875_1364|INFO|edgesB=949224
2022-03-21 00:01:06,060|29055|application_1639015019875_1364|TIME|Read
2022-03-21 00:01:21,471|44466|application_1639015019875_1364|TIME|Saving
./Perf -d Census/S/OR -p 464 -t 1e-3 -n 1
DATASET    = Census/S/OR
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 464
Run 1 ./sdcel2_debug Census/S/OR/P464 /home/acald013/RIDIR/local_path/Census/S/OR/P464/ 1e-3 "464_Census/S/OR_1e-3_1"
2022-03-21 00:01:38,935|13493|application_1639015019875_1365|13735|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/OR/P464/edgesA --input2 Census/S/OR/P464/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/OR/P464//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/OR/P464//boundary.wkt --tolerance 1e-3 --qtag 464_Census/S/OR_1e-3_1 --debug --local
2022-03-21 00:01:39,048|13606|application_1639015019875_1365|INFO|scale=1000.0
2022-03-21 00:01:39,161|13719|Saved /tmp/edgesCells_464.wkt in 0.00s [1285 records].
2022-03-21 00:01:39,161|13719|application_1639015019875_1365|INFO|npartitions=1285
2022-03-21 00:01:39,162|13720|application_1639015019875_1365|227|TIME|start|464_Census/S/OR_1e-3_1
2022-03-21 00:01:52,159|26717|application_1639015019875_1365|INFO|nEdgesA=929006
2022-03-21 00:01:55,352|29910|application_1639015019875_1365|INFO|nEdgesB=954536
2022-03-21 00:01:55,353|29911|application_1639015019875_1365|16191|TIME|read|464_Census/S/OR_1e-3_1
2022-03-21 00:01:59,657|34215|application_1639015019875_1365|4304|TIME|layer1S|464_Census/S/OR_1e-3_1
2022-03-21 00:02:01,775|36333|Saved /tmp/edgesFAC.wkt in 0.35s [4508 records].
2022-03-21 00:02:04,611|39169|application_1639015019875_1365|4954|TIME|layer2S|464_Census/S/OR_1e-3_1
2022-03-21 00:02:06,499|41057|Saved /tmp/edgesFBC.wkt in 0.19s [4703 records].
2022-03-21 00:02:41,727|76285|Saved /tmp/edgesS.wkt in 0.25s [10015 records].
2022-03-21 00:02:43,497|78055|application_1639015019875_1365|38885|TIME|overlayS|464_Census/S/OR_1e-3_1
2022-03-21 00:02:44,443|79001|Saved /tmp/edgesFE.wkt in 0.19s [1147 records].
2022-03-21 00:02:44,444|79002|application_1639015019875_1365|948|TIME|end|464_Census/S/OR_1e-3_1
hdfs dfs -mkdir Census/S/PA/
hdfs dfs -put ~/Datasets/Census/PA/PA2000.wkt Census/S/PA/A.wkt
hdfs dfs -put ~/Datasets/Census/PA/PA2010.wkt Census/S/PA/B.wkt
./QuadPart -d Census/S/PA -p 585 -t 1e-3
DATASET    = Census/S/PA
TOLERANCE  = 1e-3
PARTITIONS = 585
./QuadPlusPart 585 Census/S/PA 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/PA/P585 ...
2022-03-21 00:03:05,496|2917|local-1647846183815|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/PA/A.wkt --input2 Census/S/PA/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/PA/P585/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/PA/P585/boundary.wkt --partitions 585 --tolerance 1e-3
2022-03-21 00:03:05,497|2918|local-1647846183815|INFO|scale=1000.0
2022-03-21 00:03:05,506|2927|local-1647846183815|TIME|Start
2022-03-21 00:03:14,400|11821|local-1647846183815|INFO|edgesA=1209640
2022-03-21 00:03:16,392|13813|local-1647846183815|INFO|edgesB=1193333
2022-03-21 00:03:16,976|14397|local-1647846183815|TIME|Read
2022-03-21 00:03:16,978|14399|Partition by number (585)
2022-03-21 00:03:16,983|14404|Fraction: 0.01028042301596336
2022-03-21 00:03:17,330|14751|local-1647846183815|INFO|partitions=1513
2022-03-21 00:03:17,331|14752|local-1647846183815|TIME|Partition
2022-03-21 00:03:17,335|14756|Saved /home/acald013/RIDIR/local_path/Census/S/PA/P585/boundary.wkt in 0.00s [1 records].
2022-03-21 00:03:17,468|14889|Saved /home/acald013/RIDIR/local_path/Census/S/PA/P585/quadtree.wkt in 0.00s [1513 records].
2022-03-21 00:03:17,685|15106|local-1647846183815|TIME|Close
Partitioning edges...
rm -f -r Census/S/PA/P585/edgesA/
rm -f -r Census/S/PA/P585/edgesB/
2022-03-21 00:03:35,812|14386|application_1639015019875_1366|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/PA/A.wkt --input2 Census/S/PA/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/PA/P585/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/PA/P585/boundary.wkt --apath Census/S/PA/P585/edgesA --bpath Census/S/PA/P585/edgesB --tolerance 1e-3 --save
2022-03-21 00:03:35,813|14387|application_1639015019875_1366|INFO|scale=1000.0
2022-03-21 00:03:35,825|14399|application_1639015019875_1366|TIME|Start
2022-03-21 00:03:45,691|24265|application_1639015019875_1366|INFO|edgesA=1209640
2022-03-21 00:03:51,819|30393|application_1639015019875_1366|INFO|edgesB=1193333
2022-03-21 00:03:51,828|30402|application_1639015019875_1366|TIME|Read
2022-03-21 00:04:09,418|47992|application_1639015019875_1366|TIME|Saving
./Perf -d Census/S/PA -p 585 -t 1e-3 -n 1
DATASET    = Census/S/PA
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 585
Run 1 ./sdcel2_debug Census/S/PA/P585 /home/acald013/RIDIR/local_path/Census/S/PA/P585/ 1e-3 "585_Census/S/PA_1e-3_1"
2022-03-21 00:04:26,807|13704|application_1639015019875_1367|13951|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/PA/P585/edgesA --input2 Census/S/PA/P585/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/PA/P585//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/PA/P585//boundary.wkt --tolerance 1e-3 --qtag 585_Census/S/PA_1e-3_1 --debug --local
2022-03-21 00:04:26,932|13829|application_1639015019875_1367|INFO|scale=1000.0
2022-03-21 00:04:27,058|13955|Saved /tmp/edgesCells_585.wkt in 0.00s [1513 records].
2022-03-21 00:04:27,059|13956|application_1639015019875_1367|INFO|npartitions=1513
2022-03-21 00:04:27,059|13956|application_1639015019875_1367|252|TIME|start|585_Census/S/PA_1e-3_1
2022-03-21 00:04:41,297|28194|application_1639015019875_1367|INFO|nEdgesA=1221797
2022-03-21 00:04:44,988|31885|application_1639015019875_1367|INFO|nEdgesB=1205634
2022-03-21 00:04:44,988|31885|application_1639015019875_1367|17929|TIME|read|585_Census/S/PA_1e-3_1
2022-03-21 00:04:47,856|34753|application_1639015019875_1367|2868|TIME|layer1S|585_Census/S/PA_1e-3_1
2022-03-21 00:04:50,315|37212|Saved /tmp/edgesFAC.wkt in 0.26s [10655 records].
2022-03-21 00:04:52,596|39493|application_1639015019875_1367|4740|TIME|layer2S|585_Census/S/PA_1e-3_1
2022-03-21 00:04:55,016|41913|Saved /tmp/edgesFBC.wkt in 0.18s [10790 records].
2022-03-21 00:05:30,151|77048|Saved /tmp/edgesS.wkt in 0.44s [37107 records].
2022-03-21 00:05:32,627|79524|application_1639015019875_1367|40031|TIME|overlayS|585_Census/S/PA_1e-3_1
2022-03-21 00:05:33,906|80803|Saved /tmp/edgesFE.wkt in 0.40s [14670 records].
2022-03-21 00:05:33,906|80803|application_1639015019875_1367|1279|TIME|end|585_Census/S/PA_1e-3_1
hdfs dfs -mkdir Census/S/RI/
hdfs dfs -put ~/Datasets/Census/RI/RI2000.wkt Census/S/RI/A.wkt
hdfs dfs -put ~/Datasets/Census/RI/RI2010.wkt Census/S/RI/B.wkt
./QuadPart -d Census/S/RI -p 39 -t 1e-3
DATASET    = Census/S/RI
TOLERANCE  = 1e-3
PARTITIONS = 39
./QuadPlusPart 39 Census/S/RI 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/RI/P39 ...
2022-03-21 00:05:52,424|2908|local-1647846350781|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/RI/A.wkt --input2 Census/S/RI/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/RI/P39/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/RI/P39/boundary.wkt --partitions 39 --tolerance 1e-3
2022-03-21 00:05:52,424|2908|local-1647846350781|INFO|scale=1000.0
2022-03-21 00:05:52,433|2917|local-1647846350781|TIME|Start
2022-03-21 00:05:59,683|10167|local-1647846350781|INFO|edgesA=84055
2022-03-21 00:06:00,503|10987|local-1647846350781|INFO|edgesB=80613
2022-03-21 00:06:00,649|11133|local-1647846350781|TIME|Read
2022-03-21 00:06:00,649|11133|Partition by number (39)
2022-03-21 00:06:00,654|11138|Fraction: 0.011110728330502632
2022-03-21 00:06:00,813|11297|local-1647846350781|INFO|partitions=103
2022-03-21 00:06:00,814|11298|local-1647846350781|TIME|Partition
2022-03-21 00:06:00,818|11302|Saved /home/acald013/RIDIR/local_path/Census/S/RI/P39/boundary.wkt in 0.00s [1 records].
2022-03-21 00:06:00,848|11332|Saved /home/acald013/RIDIR/local_path/Census/S/RI/P39/quadtree.wkt in 0.00s [103 records].
2022-03-21 00:06:01,004|11488|local-1647846350781|TIME|Close
Partitioning edges...
rm -f -r Census/S/RI/P39/edgesA/
rm -f -r Census/S/RI/P39/edgesB/
2022-03-21 00:06:18,383|14090|application_1639015019875_1368|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/RI/A.wkt --input2 Census/S/RI/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/RI/P39/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/RI/P39/boundary.wkt --apath Census/S/RI/P39/edgesA --bpath Census/S/RI/P39/edgesB --tolerance 1e-3 --save
2022-03-21 00:06:18,383|14090|application_1639015019875_1368|INFO|scale=1000.0
2022-03-21 00:06:18,396|14103|application_1639015019875_1368|TIME|Start
2022-03-21 00:06:27,582|23289|application_1639015019875_1368|INFO|edgesA=84055
2022-03-21 00:06:32,764|28471|application_1639015019875_1368|INFO|edgesB=80613
2022-03-21 00:06:32,772|28479|application_1639015019875_1368|TIME|Read
2022-03-21 00:06:40,692|36399|application_1639015019875_1368|TIME|Saving
./Perf -d Census/S/RI -p 39 -t 1e-3 -n 1
DATASET    = Census/S/RI
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 39
Run 1 ./sdcel2_debug Census/S/RI/P39 /home/acald013/RIDIR/local_path/Census/S/RI/P39/ 1e-3 "39_Census/S/RI_1e-3_1"
2022-03-21 00:06:58,122|13857|application_1639015019875_1369|14107|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/RI/P39/edgesA --input2 Census/S/RI/P39/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/RI/P39//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/RI/P39//boundary.wkt --tolerance 1e-3 --qtag 39_Census/S/RI_1e-3_1 --debug --local
2022-03-21 00:06:58,186|13921|application_1639015019875_1369|INFO|scale=1000.0
2022-03-21 00:06:58,224|13959|Saved /tmp/edgesCells_39.wkt in 0.00s [103 records].
2022-03-21 00:06:58,224|13959|application_1639015019875_1369|INFO|npartitions=103
2022-03-21 00:06:58,224|13959|application_1639015019875_1369|102|TIME|start|39_Census/S/RI_1e-3_1
2022-03-21 00:07:07,979|23714|application_1639015019875_1369|INFO|nEdgesA=84871
2022-03-21 00:07:09,072|24807|application_1639015019875_1369|INFO|nEdgesB=81491
2022-03-21 00:07:09,072|24807|application_1639015019875_1369|10848|TIME|read|39_Census/S/RI_1e-3_1
2022-03-21 00:07:10,278|26013|application_1639015019875_1369|1206|TIME|layer1S|39_Census/S/RI_1e-3_1
2022-03-21 00:07:10,895|26630|Saved /tmp/edgesFAC.wkt in 0.03s [725 records].
2022-03-21 00:07:11,574|27309|application_1639015019875_1369|1296|TIME|layer2S|39_Census/S/RI_1e-3_1
2022-03-21 00:07:12,171|27906|Saved /tmp/edgesFBC.wkt in 0.03s [772 records].
2022-03-21 00:07:39,222|54957|Saved /tmp/edgesS.wkt in 0.03s [1862 records].
2022-03-21 00:07:39,689|55424|application_1639015019875_1369|28115|TIME|overlayS|39_Census/S/RI_1e-3_1
2022-03-21 00:07:39,848|55583|Saved /tmp/edgesFE.wkt in 0.03s [442 records].
2022-03-21 00:07:39,848|55583|application_1639015019875_1369|159|TIME|end|39_Census/S/RI_1e-3_1
hdfs dfs -mkdir Census/S/SC/
hdfs dfs -put ~/Datasets/Census/SC/SC2000.wkt Census/S/SC/A.wkt
hdfs dfs -put ~/Datasets/Census/SC/SC2010.wkt Census/S/SC/B.wkt
./QuadPart -d Census/S/SC -p 421 -t 1e-3
DATASET    = Census/S/SC
TOLERANCE  = 1e-3
PARTITIONS = 421
./QuadPlusPart 421 Census/S/SC 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/SC/P421 ...
2022-03-21 00:08:00,015|2988|local-1647846478377|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/SC/A.wkt --input2 Census/S/SC/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/SC/P421/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/SC/P421/boundary.wkt --partitions 421 --tolerance 1e-3
2022-03-21 00:08:00,016|2989|local-1647846478377|INFO|scale=1000.0
2022-03-21 00:08:00,026|2999|local-1647846478377|TIME|Start
2022-03-21 00:08:07,824|10797|local-1647846478377|INFO|edgesA=779022
2022-03-21 00:08:09,501|12474|local-1647846478377|INFO|edgesB=861767
2022-03-21 00:08:09,887|12860|local-1647846478377|TIME|Read
2022-03-21 00:08:09,887|12860|Partition by number (421)
2022-03-21 00:08:09,892|12865|Fraction: 0.010340171867878679
2022-03-21 00:08:10,263|13236|local-1647846478377|INFO|partitions=1063
2022-03-21 00:08:10,263|13236|local-1647846478377|TIME|Partition
2022-03-21 00:08:10,267|13240|Saved /home/acald013/RIDIR/local_path/Census/S/SC/P421/boundary.wkt in 0.00s [1 records].
2022-03-21 00:08:10,359|13332|Saved /home/acald013/RIDIR/local_path/Census/S/SC/P421/quadtree.wkt in 0.00s [1063 records].
2022-03-21 00:08:10,581|13554|local-1647846478377|TIME|Close
Partitioning edges...
rm -f -r Census/S/SC/P421/edgesA/
rm -f -r Census/S/SC/P421/edgesB/
2022-03-21 00:08:28,038|14055|application_1639015019875_1370|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/SC/A.wkt --input2 Census/S/SC/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/SC/P421/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/SC/P421/boundary.wkt --apath Census/S/SC/P421/edgesA --bpath Census/S/SC/P421/edgesB --tolerance 1e-3 --save
2022-03-21 00:08:28,039|14056|application_1639015019875_1370|INFO|scale=1000.0
2022-03-21 00:08:28,052|14069|application_1639015019875_1370|TIME|Start
2022-03-21 00:08:37,645|23662|application_1639015019875_1370|INFO|edgesA=779022
2022-03-21 00:08:43,589|29606|application_1639015019875_1370|INFO|edgesB=861767
2022-03-21 00:08:43,598|29615|application_1639015019875_1370|TIME|Read
2022-03-21 00:08:57,307|43324|application_1639015019875_1370|TIME|Saving
./Perf -d Census/S/SC -p 421 -t 1e-3 -n 1
DATASET    = Census/S/SC
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 421
Run 1 ./sdcel2_debug Census/S/SC/P421 /home/acald013/RIDIR/local_path/Census/S/SC/P421/ 1e-3 "421_Census/S/SC_1e-3_1"
2022-03-21 00:09:14,874|13613|application_1639015019875_1371|13858|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/SC/P421/edgesA --input2 Census/S/SC/P421/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/SC/P421//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/SC/P421//boundary.wkt --tolerance 1e-3 --qtag 421_Census/S/SC_1e-3_1 --debug --local
2022-03-21 00:09:14,972|13711|application_1639015019875_1371|INFO|scale=1000.0
2022-03-21 00:09:15,079|13818|Saved /tmp/edgesCells_421.wkt in 0.00s [1063 records].
2022-03-21 00:09:15,079|13818|application_1639015019875_1371|INFO|npartitions=1063
2022-03-21 00:09:15,079|13818|application_1639015019875_1371|206|TIME|start|421_Census/S/SC_1e-3_1
2022-03-21 00:09:28,184|26923|application_1639015019875_1371|INFO|nEdgesA=784762
2022-03-21 00:09:31,295|30034|application_1639015019875_1371|INFO|nEdgesB=868105
2022-03-21 00:09:31,296|30035|application_1639015019875_1371|16217|TIME|read|421_Census/S/SC_1e-3_1
2022-03-21 00:09:34,003|32742|application_1639015019875_1371|2707|TIME|layer1S|421_Census/S/SC_1e-3_1
2022-03-21 00:09:35,531|34270|Saved /tmp/edgesFAC.wkt in 0.18s [4729 records].
2022-03-21 00:09:37,624|36363|application_1639015019875_1371|3621|TIME|layer2S|421_Census/S/SC_1e-3_1
2022-03-21 00:09:39,336|38075|Saved /tmp/edgesFBC.wkt in 0.19s [5277 records].
2022-03-21 00:10:17,032|75771|Saved /tmp/edgesS.wkt in 0.24s [12195 records].
2022-03-21 00:10:18,521|77260|application_1639015019875_1371|40897|TIME|overlayS|421_Census/S/SC_1e-3_1
2022-03-21 00:10:19,269|78008|Saved /tmp/edgesFE.wkt in 0.22s [1726 records].
2022-03-21 00:10:19,269|78008|application_1639015019875_1371|748|TIME|end|421_Census/S/SC_1e-3_1
hdfs dfs -mkdir Census/S/SD/
hdfs dfs -put ~/Datasets/Census/SD/SD2000.wkt Census/S/SD/A.wkt
hdfs dfs -put ~/Datasets/Census/SD/SD2010.wkt Census/S/SD/B.wkt
./QuadPart -d Census/S/SD -p 164 -t 1e-3
DATASET    = Census/S/SD
TOLERANCE  = 1e-3
PARTITIONS = 164
./QuadPlusPart 164 Census/S/SD 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/SD/P164 ...
2022-03-21 00:10:44,306|2903|local-1647846642597|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/SD/A.wkt --input2 Census/S/SD/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/SD/P164/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/SD/P164/boundary.wkt --partitions 164 --tolerance 1e-3
2022-03-21 00:10:44,307|2904|local-1647846642597|INFO|scale=1000.0
2022-03-21 00:10:44,316|2913|local-1647846642597|TIME|Start
2022-03-21 00:10:51,845|10442|local-1647846642597|INFO|edgesA=372477
2022-03-21 00:10:53,165|11762|local-1647846642597|INFO|edgesB=336728
2022-03-21 00:10:53,405|12002|local-1647846642597|TIME|Read
2022-03-21 00:10:53,405|12002|Partition by number (164)
2022-03-21 00:10:53,409|12006|Fraction: 0.01052272402712279
2022-03-21 00:10:53,757|12354|local-1647846642597|INFO|partitions=499
2022-03-21 00:10:53,757|12354|local-1647846642597|TIME|Partition
2022-03-21 00:10:53,761|12358|Saved /home/acald013/RIDIR/local_path/Census/S/SD/P164/boundary.wkt in 0.00s [1 records].
2022-03-21 00:10:53,824|12421|Saved /home/acald013/RIDIR/local_path/Census/S/SD/P164/quadtree.wkt in 0.00s [499 records].
2022-03-21 00:10:54,031|12628|local-1647846642597|TIME|Close
Partitioning edges...
rm -f -r Census/S/SD/P164/edgesA/
rm -f -r Census/S/SD/P164/edgesB/
2022-03-21 00:11:10,673|13390|application_1639015019875_1372|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/SD/A.wkt --input2 Census/S/SD/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/SD/P164/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/SD/P164/boundary.wkt --apath Census/S/SD/P164/edgesA --bpath Census/S/SD/P164/edgesB --tolerance 1e-3 --save
2022-03-21 00:11:10,673|13390|application_1639015019875_1372|INFO|scale=1000.0
2022-03-21 00:11:10,685|13402|application_1639015019875_1372|TIME|Start
2022-03-21 00:11:20,092|22809|application_1639015019875_1372|INFO|edgesA=372477
2022-03-21 00:11:29,993|32710|application_1639015019875_1372|INFO|edgesB=336728
2022-03-21 00:11:30,006|32723|application_1639015019875_1372|TIME|Read
2022-03-21 00:11:39,499|42216|application_1639015019875_1372|TIME|Saving
./Perf -d Census/S/SD -p 164 -t 1e-3 -n 1
DATASET    = Census/S/SD
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 164
Run 1 ./sdcel2_debug Census/S/SD/P164 /home/acald013/RIDIR/local_path/Census/S/SD/P164/ 1e-3 "164_Census/S/SD_1e-3_1"
2022-03-21 00:11:56,703|13590|application_1639015019875_1373|13830|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/SD/P164/edgesA --input2 Census/S/SD/P164/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/SD/P164//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/SD/P164//boundary.wkt --tolerance 1e-3 --qtag 164_Census/S/SD_1e-3_1 --debug --local
2022-03-21 00:11:56,784|13671|application_1639015019875_1373|INFO|scale=1000.0
2022-03-21 00:11:56,857|13744|Saved /tmp/edgesCells_164.wkt in 0.00s [499 records].
2022-03-21 00:11:56,857|13744|application_1639015019875_1373|INFO|npartitions=499
2022-03-21 00:11:56,857|13744|application_1639015019875_1373|154|TIME|start|164_Census/S/SD_1e-3_1
2022-03-21 00:12:08,592|25479|application_1639015019875_1373|INFO|nEdgesA=374206
2022-03-21 00:12:10,197|27084|application_1639015019875_1373|INFO|nEdgesB=338269
2022-03-21 00:12:10,197|27084|application_1639015019875_1373|13340|TIME|read|164_Census/S/SD_1e-3_1
2022-03-21 00:12:12,125|29012|application_1639015019875_1373|1928|TIME|layer1S|164_Census/S/SD_1e-3_1
2022-03-21 00:12:13,123|30010|Saved /tmp/edgesFAC.wkt in 0.09s [1544 records].
2022-03-21 00:12:14,493|31380|application_1639015019875_1373|2368|TIME|layer2S|164_Census/S/SD_1e-3_1
2022-03-21 00:12:15,633|32520|Saved /tmp/edgesFBC.wkt in 0.08s [1436 records].
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 18 (count at SDCEL2.scala:158) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 0 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867) 	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:863) 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:677) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337) 	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094) 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020) 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085) 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811) 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:109) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 	at java.lang.Thread.run(Thread.java:745) 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1348)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1869)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:158)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
hdfs dfs -mkdir Census/S/TN/
hdfs dfs -put ~/Datasets/Census/TN/TN2000.wkt Census/S/TN/A.wkt
hdfs dfs -put ~/Datasets/Census/TN/TN2010.wkt Census/S/TN/B.wkt
./QuadPart -d Census/S/TN -p 693 -t 1e-3
DATASET    = Census/S/TN
TOLERANCE  = 1e-3
PARTITIONS = 693
./QuadPlusPart 693 Census/S/TN 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/TN/P693 ...
2022-03-21 00:13:25,511|2837|local-1647846803916|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/TN/A.wkt --input2 Census/S/TN/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/TN/P693/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/TN/P693/boundary.wkt --partitions 693 --tolerance 1e-3
2022-03-21 00:13:25,512|2838|local-1647846803916|INFO|scale=1000.0
2022-03-21 00:13:25,520|2846|local-1647846803916|TIME|Start
2022-03-21 00:13:34,198|11524|local-1647846803916|INFO|edgesA=1317952
2022-03-21 00:13:36,570|13896|local-1647846803916|INFO|edgesB=1417981
2022-03-21 00:13:37,016|14342|local-1647846803916|TIME|Read
2022-03-21 00:13:37,017|14343|Partition by number (693)
2022-03-21 00:13:37,021|14347|Fraction: 0.010262743831508409
2022-03-21 00:13:37,413|14739|local-1647846803916|INFO|partitions=1777
2022-03-21 00:13:37,413|14739|local-1647846803916|TIME|Partition
2022-03-21 00:13:37,417|14743|Saved /home/acald013/RIDIR/local_path/Census/S/TN/P693/boundary.wkt in 0.00s [1 records].
2022-03-21 00:13:37,545|14871|Saved /home/acald013/RIDIR/local_path/Census/S/TN/P693/quadtree.wkt in 0.00s [1777 records].
2022-03-21 00:13:37,710|15036|local-1647846803916|TIME|Close
Partitioning edges...
rm -f -r Census/S/TN/P693/edgesA/
rm -f -r Census/S/TN/P693/edgesB/
2022-03-21 00:13:55,441|14077|application_1639015019875_1374|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/TN/A.wkt --input2 Census/S/TN/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/TN/P693/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/TN/P693/boundary.wkt --apath Census/S/TN/P693/edgesA --bpath Census/S/TN/P693/edgesB --tolerance 1e-3 --save
2022-03-21 00:13:55,441|14077|application_1639015019875_1374|INFO|scale=1000.0
2022-03-21 00:13:55,454|14090|application_1639015019875_1374|TIME|Start
2022-03-21 00:14:05,476|24112|application_1639015019875_1374|INFO|edgesA=1317952
2022-03-21 00:14:11,499|30135|application_1639015019875_1374|INFO|edgesB=1417981
2022-03-21 00:14:11,509|30145|application_1639015019875_1374|TIME|Read
2022-03-21 00:14:33,308|51944|application_1639015019875_1374|TIME|Saving
./Perf -d Census/S/TN -p 693 -t 1e-3 -n 1
DATASET    = Census/S/TN
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 693
Run 1 ./sdcel2_debug Census/S/TN/P693 /home/acald013/RIDIR/local_path/Census/S/TN/P693/ 1e-3 "693_Census/S/TN_1e-3_1"
2022-03-21 00:14:51,337|13819|application_1639015019875_1375|14082|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/TN/P693/edgesA --input2 Census/S/TN/P693/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/TN/P693//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/TN/P693//boundary.wkt --tolerance 1e-3 --qtag 693_Census/S/TN_1e-3_1 --debug --local
2022-03-21 00:14:51,451|13933|application_1639015019875_1375|INFO|scale=1000.0
2022-03-21 00:14:51,574|14056|Saved /tmp/edgesCells_693.wkt in 0.00s [1777 records].
2022-03-21 00:14:51,574|14056|application_1639015019875_1375|INFO|npartitions=1777
2022-03-21 00:14:51,575|14057|application_1639015019875_1375|238|TIME|start|693_Census/S/TN_1e-3_1
2022-03-21 00:15:06,096|28578|application_1639015019875_1375|INFO|nEdgesA=1327280
2022-03-21 00:15:10,208|32690|application_1639015019875_1375|INFO|nEdgesB=1427991
2022-03-21 00:15:10,209|32691|application_1639015019875_1375|18634|TIME|read|693_Census/S/TN_1e-3_1
2022-03-21 00:15:14,093|36575|application_1639015019875_1375|3884|TIME|layer1S|693_Census/S/TN_1e-3_1
2022-03-21 00:15:16,816|39298|Saved /tmp/edgesFAC.wkt in 0.36s [7595 records].
2022-03-21 00:15:19,560|42042|application_1639015019875_1375|5467|TIME|layer2S|693_Census/S/TN_1e-3_1
2022-03-21 00:15:22,603|45085|Saved /tmp/edgesFBC.wkt in 0.35s [8167 records].
2022-03-21 00:15:47,239|69721|Saved /tmp/edgesS.wkt in 0.34s [19209 records].
2022-03-21 00:15:50,116|72598|application_1639015019875_1375|30556|TIME|overlayS|693_Census/S/TN_1e-3_1
2022-03-21 00:15:51,306|73788|Saved /tmp/edgesFE.wkt in 0.32s [2444 records].
2022-03-21 00:15:51,306|73788|application_1639015019875_1375|1190|TIME|end|693_Census/S/TN_1e-3_1
hdfs dfs -mkdir Census/S/TX/
hdfs dfs -put ~/Datasets/Census/TX/TX2000.wkt Census/S/TX/A.wkt
hdfs dfs -put ~/Datasets/Census/TX/TX2010.wkt Census/S/TX/B.wkt
./QuadPart -d Census/S/TX -p 1417 -t 1e-3
DATASET    = Census/S/TX
TOLERANCE  = 1e-3
PARTITIONS = 1417
./QuadPlusPart 1417 Census/S/TX 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/TX/P1417 ...
2022-03-21 00:16:13,361|2851|local-1647846971728|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/TX/A.wkt --input2 Census/S/TX/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/TX/P1417/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/TX/P1417/boundary.wkt --partitions 1417 --tolerance 1e-3
2022-03-21 00:16:13,362|2852|local-1647846971728|INFO|scale=1000.0
2022-03-21 00:16:13,370|2860|local-1647846971728|TIME|Start
2022-03-21 00:16:24,152|13642|local-1647846971728|INFO|edgesA=2848707
2022-03-21 00:16:29,313|18803|local-1647846971728|INFO|edgesB=2891977
2022-03-21 00:16:33,529|23019|local-1647846971728|TIME|Read
2022-03-21 00:16:33,530|23020|Partition by number (1417)
2022-03-21 00:16:33,537|23027|Fraction: 0.010180595058008304
2022-03-21 00:16:34,139|23629|local-1647846971728|INFO|partitions=3871
2022-03-21 00:16:34,139|23629|local-1647846971728|TIME|Partition
2022-03-21 00:16:34,143|23633|Saved /home/acald013/RIDIR/local_path/Census/S/TX/P1417/boundary.wkt in 0.00s [1 records].
2022-03-21 00:16:34,337|23827|Saved /home/acald013/RIDIR/local_path/Census/S/TX/P1417/quadtree.wkt in 0.01s [3871 records].
2022-03-21 00:16:34,484|23974|local-1647846971728|TIME|Close
Partitioning edges...
rm -f -r Census/S/TX/P1417/edgesA/
rm -f -r Census/S/TX/P1417/edgesB/
2022-03-21 00:16:51,778|13383|application_1639015019875_1376|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/TX/A.wkt --input2 Census/S/TX/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/TX/P1417/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/TX/P1417/boundary.wkt --apath Census/S/TX/P1417/edgesA --bpath Census/S/TX/P1417/edgesB --tolerance 1e-3 --save
2022-03-21 00:16:51,778|13383|application_1639015019875_1376|INFO|scale=1000.0
2022-03-21 00:16:51,792|13397|application_1639015019875_1376|TIME|Start
2022-03-21 00:17:02,202|23807|application_1639015019875_1376|INFO|edgesA=2848707
2022-03-21 00:17:08,884|30489|application_1639015019875_1376|INFO|edgesB=2891977
2022-03-21 00:17:08,897|30502|application_1639015019875_1376|TIME|Read
2022-03-21 00:17:44,886|66491|application_1639015019875_1376|TIME|Saving
./Perf -d Census/S/TX -p 1417 -t 1e-3 -n 1
DATASET    = Census/S/TX
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 1417
Run 1 ./sdcel2_debug Census/S/TX/P1417 /home/acald013/RIDIR/local_path/Census/S/TX/P1417/ 1e-3 "1417_Census/S/TX_1e-3_1"
2022-03-21 00:18:03,129|14226|application_1639015019875_1377|14483|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/TX/P1417/edgesA --input2 Census/S/TX/P1417/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/TX/P1417//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/TX/P1417//boundary.wkt --tolerance 1e-3 --qtag 1417_Census/S/TX_1e-3_1 --debug --local
2022-03-21 00:18:03,270|14367|application_1639015019875_1377|INFO|scale=1000.0
2022-03-21 00:18:03,456|14553|Saved /tmp/edgesCells_1417.wkt in 0.01s [3871 records].
2022-03-21 00:18:03,456|14553|application_1639015019875_1377|INFO|npartitions=3871
2022-03-21 00:18:03,456|14553|application_1639015019875_1377|327|TIME|start|1417_Census/S/TX_1e-3_1
2022-03-21 00:18:22,632|33729|application_1639015019875_1377|INFO|nEdgesA=2869512
2022-03-21 00:18:31,443|42540|application_1639015019875_1377|INFO|nEdgesB=2914228
2022-03-21 00:18:31,443|42540|application_1639015019875_1377|27987|TIME|read|1417_Census/S/TX_1e-3_1
2022-03-21 00:18:39,538|50635|application_1639015019875_1377|8095|TIME|layer1S|1417_Census/S/TX_1e-3_1
2022-03-21 00:18:45,250|56347|Saved /tmp/edgesFAC.wkt in 0.68s [18465 records].
2022-03-21 00:18:51,696|62793|application_1639015019875_1377|12158|TIME|layer2S|1417_Census/S/TX_1e-3_1
2022-03-21 00:18:57,959|69056|Saved /tmp/edgesFBC.wkt in 0.73s [20048 records].
2022-03-21 00:19:56,869|127966|Saved /tmp/edgesS.wkt in 1.02s [45483 records].
2022-03-21 00:20:03,679|134776|application_1639015019875_1377|71983|TIME|overlayS|1417_Census/S/TX_1e-3_1
2022-03-21 00:20:06,688|137785|Saved /tmp/edgesFE.wkt in 0.92s [8684 records].
2022-03-21 00:20:06,688|137785|application_1639015019875_1377|3009|TIME|end|1417_Census/S/TX_1e-3_1
hdfs dfs -mkdir Census/S/UT/
hdfs dfs -put ~/Datasets/Census/UT/UT2000.wkt Census/S/UT/A.wkt
hdfs dfs -put ~/Datasets/Census/UT/UT2010.wkt Census/S/UT/B.wkt
./QuadPart -d Census/S/UT -p 237 -t 1e-3
DATASET    = Census/S/UT
TOLERANCE  = 1e-3
PARTITIONS = 237
./QuadPlusPart 237 Census/S/UT 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/UT/P237 ...
2022-03-21 00:20:27,084|2816|local-1647847225452|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/UT/A.wkt --input2 Census/S/UT/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/UT/P237/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/UT/P237/boundary.wkt --partitions 237 --tolerance 1e-3
2022-03-21 00:20:27,085|2817|local-1647847225452|INFO|scale=1000.0
2022-03-21 00:20:27,093|2825|local-1647847225452|TIME|Start
2022-03-21 00:20:34,437|10169|local-1647847225452|INFO|edgesA=481194
2022-03-21 00:20:35,702|11434|local-1647847225452|INFO|edgesB=485153
2022-03-21 00:20:35,896|11628|local-1647847225452|TIME|Read
2022-03-21 00:20:35,897|11629|Partition by number (237)
2022-03-21 00:20:35,901|11633|Fraction: 0.010445740696091667
2022-03-21 00:20:36,504|12236|local-1647847225452|INFO|partitions=679
2022-03-21 00:20:36,504|12236|local-1647847225452|TIME|Partition
2022-03-21 00:20:36,508|12240|Saved /home/acald013/RIDIR/local_path/Census/S/UT/P237/boundary.wkt in 0.00s [1 records].
2022-03-21 00:20:36,588|12320|Saved /home/acald013/RIDIR/local_path/Census/S/UT/P237/quadtree.wkt in 0.00s [679 records].
2022-03-21 00:20:36,731|12463|local-1647847225452|TIME|Close
Partitioning edges...
rm -f -r Census/S/UT/P237/edgesA/
rm -f -r Census/S/UT/P237/edgesB/
2022-03-21 00:20:53,619|13576|application_1639015019875_1378|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/UT/A.wkt --input2 Census/S/UT/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/UT/P237/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/UT/P237/boundary.wkt --apath Census/S/UT/P237/edgesA --bpath Census/S/UT/P237/edgesB --tolerance 1e-3 --save
2022-03-21 00:20:53,619|13576|application_1639015019875_1378|INFO|scale=1000.0
2022-03-21 00:20:53,632|13589|application_1639015019875_1378|TIME|Start
2022-03-21 00:21:03,202|23159|application_1639015019875_1378|INFO|edgesA=481194
2022-03-21 00:21:09,022|28979|application_1639015019875_1378|INFO|edgesB=485153
2022-03-21 00:21:09,031|28988|application_1639015019875_1378|TIME|Read
2022-03-21 00:21:22,365|42322|application_1639015019875_1378|TIME|Saving
./Perf -d Census/S/UT -p 237 -t 1e-3 -n 1
DATASET    = Census/S/UT
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 237
Run 1 ./sdcel2_debug Census/S/UT/P237 /home/acald013/RIDIR/local_path/Census/S/UT/P237/ 1e-3 "237_Census/S/UT_1e-3_1"
2022-03-21 00:21:40,139|13795|application_1639015019875_1379|14046|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/UT/P237/edgesA --input2 Census/S/UT/P237/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/UT/P237//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/UT/P237//boundary.wkt --tolerance 1e-3 --qtag 237_Census/S/UT_1e-3_1 --debug --local
2022-03-21 00:21:40,223|13879|application_1639015019875_1379|INFO|scale=1000.0
2022-03-21 00:21:40,304|13960|Saved /tmp/edgesCells_237.wkt in 0.00s [679 records].
2022-03-21 00:21:40,304|13960|application_1639015019875_1379|INFO|npartitions=679
2022-03-21 00:21:40,304|13960|application_1639015019875_1379|165|TIME|start|237_Census/S/UT_1e-3_1
2022-03-21 00:21:52,474|26130|application_1639015019875_1379|INFO|nEdgesA=483923
2022-03-21 00:21:54,772|28428|application_1639015019875_1379|INFO|nEdgesB=488004
2022-03-21 00:21:54,772|28428|application_1639015019875_1379|14468|TIME|read|237_Census/S/UT_1e-3_1
2022-03-21 00:21:57,382|31038|application_1639015019875_1379|2610|TIME|layer1S|237_Census/S/UT_1e-3_1
2022-03-21 00:21:59,921|33577|Saved /tmp/edgesFAC.wkt in 0.30s [2510 records].
2022-03-21 00:22:01,448|35104|application_1639015019875_1379|4066|TIME|layer2S|237_Census/S/UT_1e-3_1
2022-03-21 00:22:02,590|36246|Saved /tmp/edgesFBC.wkt in 0.15s [2658 records].
2022-03-21 00:22:39,308|72964|Saved /tmp/edgesS.wkt in 0.17s [5818 records].
2022-03-21 00:22:41,193|74849|application_1639015019875_1379|39745|TIME|overlayS|237_Census/S/UT_1e-3_1
2022-03-21 00:22:41,762|75418|Saved /tmp/edgesFE.wkt in 0.14s [905 records].
2022-03-21 00:22:41,762|75418|application_1639015019875_1379|569|TIME|end|237_Census/S/UT_1e-3_1
hdfs dfs -mkdir Census/S/VT/
hdfs dfs -put ~/Datasets/Census/VT/VT2000.wkt Census/S/VT/A.wkt
hdfs dfs -put ~/Datasets/Census/VT/VT2010.wkt Census/S/VT/B.wkt
./QuadPart -d Census/S/VT -p 32 -t 1e-3
DATASET    = Census/S/VT
TOLERANCE  = 1e-3
PARTITIONS = 32
./QuadPlusPart 32 Census/S/VT 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/VT/P32 ...
2022-03-21 00:23:01,079|2859|local-1647847379424|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/VT/A.wkt --input2 Census/S/VT/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/VT/P32/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/VT/P32/boundary.wkt --partitions 32 --tolerance 1e-3
2022-03-21 00:23:01,079|2859|local-1647847379424|INFO|scale=1000.0
2022-03-21 00:23:01,088|2868|local-1647847379424|TIME|Start
2022-03-21 00:23:07,985|9765|local-1647847379424|INFO|edgesA=65415
2022-03-21 00:23:08,699|10479|local-1647847379424|INFO|edgesB=66176
2022-03-21 00:23:08,831|10611|local-1647847379424|TIME|Read
2022-03-21 00:23:08,831|10611|Partition by number (32)
2022-03-21 00:23:08,836|10616|Fraction: 0.011247886655512164
2022-03-21 00:23:08,989|10769|local-1647847379424|INFO|partitions=85
2022-03-21 00:23:08,990|10770|local-1647847379424|TIME|Partition
2022-03-21 00:23:08,994|10774|Saved /home/acald013/RIDIR/local_path/Census/S/VT/P32/boundary.wkt in 0.00s [1 records].
2022-03-21 00:23:09,016|10796|Saved /home/acald013/RIDIR/local_path/Census/S/VT/P32/quadtree.wkt in 0.00s [85 records].
2022-03-21 00:23:09,198|10978|local-1647847379424|TIME|Close
Partitioning edges...
rm -f -r Census/S/VT/P32/edgesA/
rm -f -r Census/S/VT/P32/edgesB/
2022-03-21 00:23:26,131|13633|application_1639015019875_1380|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/VT/A.wkt --input2 Census/S/VT/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/VT/P32/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/VT/P32/boundary.wkt --apath Census/S/VT/P32/edgesA --bpath Census/S/VT/P32/edgesB --tolerance 1e-3 --save
2022-03-21 00:23:26,132|13634|application_1639015019875_1380|INFO|scale=1000.0
2022-03-21 00:23:26,144|13646|application_1639015019875_1380|TIME|Start
2022-03-21 00:23:34,768|22270|application_1639015019875_1380|INFO|edgesA=65415
2022-03-21 00:23:39,755|27257|application_1639015019875_1380|INFO|edgesB=66176
2022-03-21 00:23:39,769|27271|application_1639015019875_1380|TIME|Read
2022-03-21 00:23:47,422|34924|application_1639015019875_1380|TIME|Saving
./Perf -d Census/S/VT -p 32 -t 1e-3 -n 1
DATASET    = Census/S/VT
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 32
Run 1 ./sdcel2_debug Census/S/VT/P32 /home/acald013/RIDIR/local_path/Census/S/VT/P32/ 1e-3 "32_Census/S/VT_1e-3_1"
2022-03-21 00:24:04,723|13704|application_1639015019875_1381|13948|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/VT/P32/edgesA --input2 Census/S/VT/P32/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/VT/P32//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/VT/P32//boundary.wkt --tolerance 1e-3 --qtag 32_Census/S/VT_1e-3_1 --debug --local
2022-03-21 00:24:04,782|13763|application_1639015019875_1381|INFO|scale=1000.0
2022-03-21 00:24:04,812|13793|Saved /tmp/edgesCells_32.wkt in 0.00s [85 records].
2022-03-21 00:24:04,812|13793|application_1639015019875_1381|INFO|npartitions=85
2022-03-21 00:24:04,812|13793|application_1639015019875_1381|89|TIME|start|32_Census/S/VT_1e-3_1
2022-03-21 00:24:14,436|23417|application_1639015019875_1381|INFO|nEdgesA=65996
2022-03-21 00:24:15,983|24964|application_1639015019875_1381|INFO|nEdgesB=66771
2022-03-21 00:24:15,983|24964|application_1639015019875_1381|11171|TIME|read|32_Census/S/VT_1e-3_1
2022-03-21 00:24:17,097|26078|application_1639015019875_1381|1114|TIME|layer1S|32_Census/S/VT_1e-3_1
2022-03-21 00:24:17,639|26620|Saved /tmp/edgesFAC.wkt in 0.03s [536 records].
2022-03-21 00:24:18,171|27152|application_1639015019875_1381|1074|TIME|layer2S|32_Census/S/VT_1e-3_1
2022-03-21 00:24:18,654|27635|Saved /tmp/edgesFBC.wkt in 0.04s [548 records].
2022-03-21 00:24:35,492|44473|Saved /tmp/edgesS.wkt in 0.14s [1479 records].
2022-03-21 00:24:35,904|44885|application_1639015019875_1381|17733|TIME|overlayS|32_Census/S/VT_1e-3_1
2022-03-21 00:24:36,010|44991|Saved /tmp/edgesFE.wkt in 0.02s [496 records].
2022-03-21 00:24:36,011|44992|application_1639015019875_1381|107|TIME|end|32_Census/S/VT_1e-3_1
hdfs dfs -mkdir Census/S/VA/
hdfs dfs -put ~/Datasets/Census/VA/VA2000.wkt Census/S/VA/A.wkt
hdfs dfs -put ~/Datasets/Census/VA/VA2010.wkt Census/S/VA/B.wkt
./QuadPart -d Census/S/VA -p 655 -t 1e-3
DATASET    = Census/S/VA
TOLERANCE  = 1e-3
PARTITIONS = 655
./QuadPlusPart 655 Census/S/VA 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/VA/P655 ...
2022-03-21 00:24:55,591|2771|local-1647847493982|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/VA/A.wkt --input2 Census/S/VA/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/VA/P655/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/VA/P655/boundary.wkt --partitions 655 --tolerance 1e-3
2022-03-21 00:24:55,592|2772|local-1647847493982|INFO|scale=1000.0
2022-03-21 00:24:55,600|2780|local-1647847493982|TIME|Start
2022-03-21 00:25:04,335|11515|local-1647847493982|INFO|edgesA=1249304
2022-03-21 00:25:06,587|13767|local-1647847493982|INFO|edgesB=1337861
2022-03-21 00:25:06,916|14096|local-1647847493982|TIME|Read
2022-03-21 00:25:06,917|14097|Partition by number (655)
2022-03-21 00:25:06,921|14101|Fraction: 0.01027016292692851
2022-03-21 00:25:07,316|14496|local-1647847493982|INFO|partitions=1690
2022-03-21 00:25:07,316|14496|local-1647847493982|TIME|Partition
2022-03-21 00:25:07,320|14500|Saved /home/acald013/RIDIR/local_path/Census/S/VA/P655/boundary.wkt in 0.00s [1 records].
2022-03-21 00:25:07,437|14617|Saved /home/acald013/RIDIR/local_path/Census/S/VA/P655/quadtree.wkt in 0.00s [1690 records].
2022-03-21 00:25:07,631|14811|local-1647847493982|TIME|Close
Partitioning edges...
rm -f -r Census/S/VA/P655/edgesA/
rm -f -r Census/S/VA/P655/edgesB/
2022-03-21 00:25:24,691|13517|application_1639015019875_1382|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/VA/A.wkt --input2 Census/S/VA/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/VA/P655/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/VA/P655/boundary.wkt --apath Census/S/VA/P655/edgesA --bpath Census/S/VA/P655/edgesB --tolerance 1e-3 --save
2022-03-21 00:25:24,691|13517|application_1639015019875_1382|INFO|scale=1000.0
2022-03-21 00:25:24,704|13530|application_1639015019875_1382|TIME|Start
2022-03-21 00:25:34,343|23169|application_1639015019875_1382|INFO|edgesA=1249304
2022-03-21 00:25:40,212|29038|application_1639015019875_1382|INFO|edgesB=1337861
2022-03-21 00:25:40,224|29050|application_1639015019875_1382|TIME|Read
2022-03-21 00:25:59,763|48589|application_1639015019875_1382|TIME|Saving
./Perf -d Census/S/VA -p 655 -t 1e-3 -n 1
DATASET    = Census/S/VA
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 655
Run 1 ./sdcel2_debug Census/S/VA/P655 /home/acald013/RIDIR/local_path/Census/S/VA/P655/ 1e-3 "655_Census/S/VA_1e-3_1"
2022-03-21 00:26:17,192|13631|application_1639015019875_1383|13876|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/VA/P655/edgesA --input2 Census/S/VA/P655/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/VA/P655//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/VA/P655//boundary.wkt --tolerance 1e-3 --qtag 655_Census/S/VA_1e-3_1 --debug --local
2022-03-21 00:26:17,301|13740|application_1639015019875_1383|INFO|scale=1000.0
2022-03-21 00:26:17,423|13862|Saved /tmp/edgesCells_655.wkt in 0.00s [1690 records].
2022-03-21 00:26:17,423|13862|application_1639015019875_1383|INFO|npartitions=1690
2022-03-21 00:26:17,423|13862|application_1639015019875_1383|231|TIME|start|655_Census/S/VA_1e-3_1
2022-03-21 00:26:32,369|28808|application_1639015019875_1383|INFO|nEdgesA=1258554
2022-03-21 00:26:37,073|33512|application_1639015019875_1383|INFO|nEdgesB=1347781
2022-03-21 00:26:37,073|33512|application_1639015019875_1383|19650|TIME|read|655_Census/S/VA_1e-3_1
2022-03-21 00:26:40,877|37316|application_1639015019875_1383|3804|TIME|layer1S|655_Census/S/VA_1e-3_1
2022-03-21 00:26:43,603|40042|Saved /tmp/edgesFAC.wkt in 0.28s [7715 records].
2022-03-21 00:26:46,467|42906|application_1639015019875_1383|5590|TIME|layer2S|655_Census/S/VA_1e-3_1
2022-03-21 00:26:49,062|45501|Saved /tmp/edgesFBC.wkt in 0.31s [8418 records].
2022-03-21 00:27:24,669|81108|Saved /tmp/edgesS.wkt in 0.42s [20196 records].
2022-03-21 00:27:27,292|83731|application_1639015019875_1383|40825|TIME|overlayS|655_Census/S/VA_1e-3_1
2022-03-21 00:27:28,653|85092|Saved /tmp/edgesFE.wkt in 0.52s [3531 records].
2022-03-21 00:27:28,654|85093|application_1639015019875_1383|1362|TIME|end|655_Census/S/VA_1e-3_1
hdfs dfs -mkdir Census/S/WA/
hdfs dfs -put ~/Datasets/Census/WA/WA2000.wkt Census/S/WA/A.wkt
hdfs dfs -put ~/Datasets/Census/WA/WA2010.wkt Census/S/WA/B.wkt
./QuadPart -d Census/S/WA -p 429 -t 1e-3
DATASET    = Census/S/WA
TOLERANCE  = 1e-3
PARTITIONS = 429
./QuadPlusPart 429 Census/S/WA 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/WA/P429 ...
2022-03-21 00:27:50,008|2861|local-1647847668378|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WA/A.wkt --input2 Census/S/WA/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/WA/P429/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/WA/P429/boundary.wkt --partitions 429 --tolerance 1e-3
2022-03-21 00:27:50,009|2862|local-1647847668378|INFO|scale=1000.0
2022-03-21 00:27:50,017|2870|local-1647847668378|TIME|Start
2022-03-21 00:27:58,362|11215|local-1647847668378|INFO|edgesA=813983
2022-03-21 00:28:00,089|12942|local-1647847668378|INFO|edgesB=876539
2022-03-21 00:28:00,584|13437|local-1647847668378|TIME|Read
2022-03-21 00:28:00,584|13437|Partition by number (429)
2022-03-21 00:28:00,589|13442|Fraction: 0.010335458539651284
2022-03-21 00:28:01,137|13990|local-1647847668378|INFO|partitions=1135
2022-03-21 00:28:01,137|13990|local-1647847668378|TIME|Partition
2022-03-21 00:28:01,141|13994|Saved /home/acald013/RIDIR/local_path/Census/S/WA/P429/boundary.wkt in 0.00s [1 records].
2022-03-21 00:28:01,242|14095|Saved /home/acald013/RIDIR/local_path/Census/S/WA/P429/quadtree.wkt in 0.00s [1135 records].
2022-03-21 00:28:01,484|14337|local-1647847668378|TIME|Close
Partitioning edges...
rm -f -r Census/S/WA/P429/edgesA/
rm -f -r Census/S/WA/P429/edgesB/
2022-03-21 00:28:18,558|13590|application_1639015019875_1384|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WA/A.wkt --input2 Census/S/WA/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/WA/P429/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/WA/P429/boundary.wkt --apath Census/S/WA/P429/edgesA --bpath Census/S/WA/P429/edgesB --tolerance 1e-3 --save
2022-03-21 00:28:18,558|13590|application_1639015019875_1384|INFO|scale=1000.0
2022-03-21 00:28:18,571|13603|application_1639015019875_1384|TIME|Start
2022-03-21 00:28:28,182|23214|application_1639015019875_1384|INFO|edgesA=813983
2022-03-21 00:28:34,020|29052|application_1639015019875_1384|INFO|edgesB=876539
2022-03-21 00:28:34,027|29059|application_1639015019875_1384|TIME|Read
2022-03-21 00:28:48,291|43323|application_1639015019875_1384|TIME|Saving
./Perf -d Census/S/WA -p 429 -t 1e-3 -n 1
DATASET    = Census/S/WA
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 429
Run 1 ./sdcel2_debug Census/S/WA/P429 /home/acald013/RIDIR/local_path/Census/S/WA/P429/ 1e-3 "429_Census/S/WA_1e-3_1"
2022-03-21 00:29:05,896|13934|application_1639015019875_1385|14179|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WA/P429/edgesA --input2 Census/S/WA/P429/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/WA/P429//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/WA/P429//boundary.wkt --tolerance 1e-3 --qtag 429_Census/S/WA_1e-3_1 --debug --local
2022-03-21 00:29:05,995|14033|application_1639015019875_1385|INFO|scale=1000.0
2022-03-21 00:29:06,122|14160|Saved /tmp/edgesCells_429.wkt in 0.00s [1135 records].
2022-03-21 00:29:06,122|14160|application_1639015019875_1385|INFO|npartitions=1135
2022-03-21 00:29:06,122|14160|application_1639015019875_1385|226|TIME|start|429_Census/S/WA_1e-3_1
2022-03-21 00:29:18,644|26682|application_1639015019875_1385|INFO|nEdgesA=820157
2022-03-21 00:29:22,279|30317|application_1639015019875_1385|INFO|nEdgesB=883123
2022-03-21 00:29:22,280|30318|application_1639015019875_1385|16158|TIME|read|429_Census/S/WA_1e-3_1
2022-03-21 00:29:25,444|33482|application_1639015019875_1385|3164|TIME|layer1S|429_Census/S/WA_1e-3_1
2022-03-21 00:29:27,267|35305|Saved /tmp/edgesFAC.wkt in 0.18s [5490 records].
2022-03-21 00:29:29,250|37288|application_1639015019875_1385|3806|TIME|layer2S|429_Census/S/WA_1e-3_1
2022-03-21 00:29:31,033|39071|Saved /tmp/edgesFBC.wkt in 0.25s [5971 records].
2022-03-21 00:30:05,493|73531|Saved /tmp/edgesS.wkt in 0.28s [13015 records].
2022-03-21 00:30:07,052|75090|application_1639015019875_1385|37802|TIME|overlayS|429_Census/S/WA_1e-3_1
2022-03-21 00:30:07,867|75905|Saved /tmp/edgesFE.wkt in 0.24s [2186 records].
2022-03-21 00:30:07,867|75905|application_1639015019875_1385|815|TIME|end|429_Census/S/WA_1e-3_1
hdfs dfs -mkdir Census/S/WV/
hdfs dfs -put ~/Datasets/Census/WV/WV2000.wkt Census/S/WV/A.wkt
hdfs dfs -put ~/Datasets/Census/WV/WV2010.wkt Census/S/WV/B.wkt
./QuadPart -d Census/S/WV -p 365 -t 1e-3
DATASET    = Census/S/WV
TOLERANCE  = 1e-3
PARTITIONS = 365
./QuadPlusPart 365 Census/S/WV 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/WV/P365 ...
2022-03-21 00:30:27,556|3023|local-1647847825844|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WV/A.wkt --input2 Census/S/WV/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/WV/P365/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/WV/P365/boundary.wkt --partitions 365 --tolerance 1e-3
2022-03-21 00:30:27,557|3024|local-1647847825844|INFO|scale=1000.0
2022-03-21 00:30:27,566|3033|local-1647847825844|TIME|Start
2022-03-21 00:30:35,542|11009|local-1647847825844|INFO|edgesA=725479
2022-03-21 00:30:37,427|12894|local-1647847825844|INFO|edgesB=748205
2022-03-21 00:30:37,843|13310|local-1647847825844|TIME|Read
2022-03-21 00:30:37,844|13311|Partition by number (365)
2022-03-21 00:30:37,848|13315|Fraction: 0.010359274883663073
2022-03-21 00:30:38,170|13637|local-1647847825844|INFO|partitions=949
2022-03-21 00:30:38,170|13637|local-1647847825844|TIME|Partition
2022-03-21 00:30:38,174|13641|Saved /home/acald013/RIDIR/local_path/Census/S/WV/P365/boundary.wkt in 0.00s [1 records].
2022-03-21 00:30:38,264|13731|Saved /home/acald013/RIDIR/local_path/Census/S/WV/P365/quadtree.wkt in 0.00s [949 records].
2022-03-21 00:30:38,417|13884|local-1647847825844|TIME|Close
Partitioning edges...
rm -f -r Census/S/WV/P365/edgesA/
rm -f -r Census/S/WV/P365/edgesB/
2022-03-21 00:30:55,759|13838|application_1639015019875_1386|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WV/A.wkt --input2 Census/S/WV/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/WV/P365/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/WV/P365/boundary.wkt --apath Census/S/WV/P365/edgesA --bpath Census/S/WV/P365/edgesB --tolerance 1e-3 --save
2022-03-21 00:30:55,760|13839|application_1639015019875_1386|INFO|scale=1000.0
2022-03-21 00:30:55,772|13851|application_1639015019875_1386|TIME|Start
2022-03-21 00:31:05,265|23344|application_1639015019875_1386|INFO|edgesA=725479
2022-03-21 00:31:11,138|29217|application_1639015019875_1386|INFO|edgesB=748205
2022-03-21 00:31:11,148|29227|application_1639015019875_1386|TIME|Read
2022-03-21 00:31:27,634|45713|application_1639015019875_1386|TIME|Saving
./Perf -d Census/S/WV -p 365 -t 1e-3 -n 1
DATASET    = Census/S/WV
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 365
Run 1 ./sdcel2_debug Census/S/WV/P365 /home/acald013/RIDIR/local_path/Census/S/WV/P365/ 1e-3 "365_Census/S/WV_1e-3_1"
2022-03-21 00:31:44,969|13634|application_1639015019875_1387|13890|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WV/P365/edgesA --input2 Census/S/WV/P365/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/WV/P365//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/WV/P365//boundary.wkt --tolerance 1e-3 --qtag 365_Census/S/WV_1e-3_1 --debug --local
2022-03-21 00:31:45,068|13733|application_1639015019875_1387|INFO|scale=1000.0
2022-03-21 00:31:45,167|13832|Saved /tmp/edgesCells_365.wkt in 0.00s [949 records].
2022-03-21 00:31:45,167|13832|application_1639015019875_1387|INFO|npartitions=949
2022-03-21 00:31:45,167|13832|application_1639015019875_1387|198|TIME|start|365_Census/S/WV_1e-3_1
2022-03-21 00:31:59,823|28488|application_1639015019875_1387|INFO|nEdgesA=729575
2022-03-21 00:32:03,371|32036|application_1639015019875_1387|INFO|nEdgesB=752375
2022-03-21 00:32:03,372|32037|application_1639015019875_1387|18205|TIME|read|365_Census/S/WV_1e-3_1
2022-03-21 00:32:06,105|34770|application_1639015019875_1387|2733|TIME|layer1S|365_Census/S/WV_1e-3_1
2022-03-21 00:32:07,665|36330|Saved /tmp/edgesFAC.wkt in 0.14s [3347 records].
2022-03-21 00:32:09,427|38092|application_1639015019875_1387|3322|TIME|layer2S|365_Census/S/WV_1e-3_1
2022-03-21 00:32:11,095|39760|Saved /tmp/edgesFBC.wkt in 0.18s [3400 records].
2022-03-21 00:32:56,811|85476|Saved /tmp/edgesS.wkt in 0.18s [8359 records].
2022-03-21 00:32:58,624|87289|application_1639015019875_1387|49197|TIME|overlayS|365_Census/S/WV_1e-3_1
2022-03-21 00:32:59,348|88013|Saved /tmp/edgesFE.wkt in 0.17s [1109 records].
2022-03-21 00:32:59,348|88013|application_1639015019875_1387|724|TIME|end|365_Census/S/WV_1e-3_1
hdfs dfs -mkdir Census/S/WI/
hdfs dfs -put ~/Datasets/Census/WI/WI2000.wkt Census/S/WI/A.wkt
hdfs dfs -put ~/Datasets/Census/WI/WI2010.wkt Census/S/WI/B.wkt
./QuadPart -d Census/S/WI -p 362 -t 1e-3
DATASET    = Census/S/WI
TOLERANCE  = 1e-3
PARTITIONS = 362
./QuadPlusPart 362 Census/S/WI 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/WI/P362 ...
2022-03-21 00:33:19,365|2746|local-1647847997772|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WI/A.wkt --input2 Census/S/WI/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/WI/P362/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/WI/P362/boundary.wkt --partitions 362 --tolerance 1e-3
2022-03-21 00:33:19,365|2746|local-1647847997772|INFO|scale=1000.0
2022-03-21 00:33:19,374|2755|local-1647847997772|TIME|Start
2022-03-21 00:33:28,140|11521|local-1647847997772|INFO|edgesA=767573
2022-03-21 00:33:29,505|12886|local-1647847997772|INFO|edgesB=739963
2022-03-21 00:33:29,765|13146|local-1647847997772|TIME|Read
2022-03-21 00:33:29,765|13146|Partition by number (362)
2022-03-21 00:33:29,770|13151|Fraction: 0.010355477741621275
2022-03-21 00:33:30,216|13597|local-1647847997772|INFO|partitions=970
2022-03-21 00:33:30,216|13597|local-1647847997772|TIME|Partition
2022-03-21 00:33:30,220|13601|Saved /home/acald013/RIDIR/local_path/Census/S/WI/P362/boundary.wkt in 0.00s [1 records].
2022-03-21 00:33:30,332|13713|Saved /home/acald013/RIDIR/local_path/Census/S/WI/P362/quadtree.wkt in 0.00s [970 records].
2022-03-21 00:33:30,649|14030|local-1647847997772|TIME|Close
Partitioning edges...
rm -f -r Census/S/WI/P362/edgesA/
rm -f -r Census/S/WI/P362/edgesB/
2022-03-21 00:33:47,652|13556|application_1639015019875_1388|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WI/A.wkt --input2 Census/S/WI/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/WI/P362/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/WI/P362/boundary.wkt --apath Census/S/WI/P362/edgesA --bpath Census/S/WI/P362/edgesB --tolerance 1e-3 --save
2022-03-21 00:33:47,653|13557|application_1639015019875_1388|INFO|scale=1000.0
2022-03-21 00:33:47,664|13568|application_1639015019875_1388|TIME|Start
2022-03-21 00:33:57,047|22951|application_1639015019875_1388|INFO|edgesA=767573
2022-03-21 00:34:02,944|28848|application_1639015019875_1388|INFO|edgesB=739963
2022-03-21 00:34:02,952|28856|application_1639015019875_1388|TIME|Read
2022-03-21 00:34:18,390|44294|application_1639015019875_1388|TIME|Saving
./Perf -d Census/S/WI -p 362 -t 1e-3 -n 1
DATASET    = Census/S/WI
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 362
Run 1 ./sdcel2_debug Census/S/WI/P362 /home/acald013/RIDIR/local_path/Census/S/WI/P362/ 1e-3 "362_Census/S/WI_1e-3_1"
2022-03-21 00:34:36,378|13887|application_1639015019875_1389|14135|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WI/P362/edgesA --input2 Census/S/WI/P362/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/WI/P362//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/WI/P362//boundary.wkt --tolerance 1e-3 --qtag 362_Census/S/WI_1e-3_1 --debug --local
2022-03-21 00:34:36,477|13986|application_1639015019875_1389|INFO|scale=1000.0
2022-03-21 00:34:36,597|14106|Saved /tmp/edgesCells_362.wkt in 0.00s [970 records].
2022-03-21 00:34:36,597|14106|application_1639015019875_1389|INFO|npartitions=970
2022-03-21 00:34:36,597|14106|application_1639015019875_1389|219|TIME|start|362_Census/S/WI_1e-3_1
2022-03-21 00:34:49,347|26856|application_1639015019875_1389|INFO|nEdgesA=773292
2022-03-21 00:34:52,550|30059|application_1639015019875_1389|INFO|nEdgesB=745762
2022-03-21 00:34:52,551|30060|application_1639015019875_1389|15954|TIME|read|362_Census/S/WI_1e-3_1
2022-03-21 00:34:55,128|32637|application_1639015019875_1389|2577|TIME|layer1S|362_Census/S/WI_1e-3_1
2022-03-21 00:34:57,049|34558|Saved /tmp/edgesFAC.wkt in 0.17s [5108 records].
2022-03-21 00:34:58,840|36349|application_1639015019875_1389|3712|TIME|layer2S|362_Census/S/WI_1e-3_1
2022-03-21 00:35:00,720|38229|Saved /tmp/edgesFBC.wkt in 0.15s [5204 records].
2022-03-21 00:35:56,466|93975|Saved /tmp/edgesS.wkt in 0.23s [11508 records].
2022-03-21 00:35:58,569|96078|application_1639015019875_1389|59729|TIME|overlayS|362_Census/S/WI_1e-3_1
2022-03-21 00:35:59,526|97035|Saved /tmp/edgesFE.wkt in 0.27s [1948 records].
2022-03-21 00:35:59,526|97035|application_1639015019875_1389|957|TIME|end|362_Census/S/WI_1e-3_1
hdfs dfs -mkdir Census/S/WY/
hdfs dfs -put ~/Datasets/Census/WY/WY2000.wkt Census/S/WY/A.wkt
hdfs dfs -put ~/Datasets/Census/WY/WY2010.wkt Census/S/WY/B.wkt
./QuadPart -d Census/S/WY -p 109 -t 1e-3
DATASET    = Census/S/WY
TOLERANCE  = 1e-3
PARTITIONS = 109
./QuadPlusPart 109 Census/S/WY 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/WY/P109 ...
2022-03-21 00:36:19,196|2798|local-1647848177598|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WY/A.wkt --input2 Census/S/WY/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/WY/P109/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/WY/P109/boundary.wkt --partitions 109 --tolerance 1e-3
2022-03-21 00:36:19,197|2799|local-1647848177598|INFO|scale=1000.0
2022-03-21 00:36:19,205|2807|local-1647848177598|TIME|Start
2022-03-21 00:36:27,054|10656|local-1647848177598|INFO|edgesA=224092
2022-03-21 00:36:28,244|11846|local-1647848177598|INFO|edgesB=224490
2022-03-21 00:36:28,380|11982|local-1647848177598|TIME|Read
2022-03-21 00:36:28,381|11983|Partition by number (109)
2022-03-21 00:36:28,384|11986|Fraction: 0.010659788334006694
2022-03-21 00:36:28,592|12194|local-1647848177598|INFO|partitions=343
2022-03-21 00:36:28,592|12194|local-1647848177598|TIME|Partition
2022-03-21 00:36:28,596|12198|Saved /home/acald013/RIDIR/local_path/Census/S/WY/P109/boundary.wkt in 0.00s [1 records].
2022-03-21 00:36:28,650|12252|Saved /home/acald013/RIDIR/local_path/Census/S/WY/P109/quadtree.wkt in 0.00s [343 records].
2022-03-21 00:36:28,856|12458|local-1647848177598|TIME|Close
Partitioning edges...
rm -f -r Census/S/WY/P109/edgesA/
rm -f -r Census/S/WY/P109/edgesB/
2022-03-21 00:36:45,832|13732|application_1639015019875_1390|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WY/A.wkt --input2 Census/S/WY/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/WY/P109/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/WY/P109/boundary.wkt --apath Census/S/WY/P109/edgesA --bpath Census/S/WY/P109/edgesB --tolerance 1e-3 --save
2022-03-21 00:36:45,833|13733|application_1639015019875_1390|INFO|scale=1000.0
2022-03-21 00:36:45,845|13745|application_1639015019875_1390|TIME|Start
2022-03-21 00:36:59,184|27084|application_1639015019875_1390|INFO|edgesA=224092
2022-03-21 00:37:04,645|32545|application_1639015019875_1390|INFO|edgesB=224490
2022-03-21 00:37:04,653|32553|application_1639015019875_1390|TIME|Read
2022-03-21 00:37:14,731|42631|application_1639015019875_1390|TIME|Saving
./Perf -d Census/S/WY -p 109 -t 1e-3 -n 1
DATASET    = Census/S/WY
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 109
Run 1 ./sdcel2_debug Census/S/WY/P109 /home/acald013/RIDIR/local_path/Census/S/WY/P109/ 1e-3 "109_Census/S/WY_1e-3_1"
2022-03-21 00:37:32,077|13710|application_1639015019875_1391|13955|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/WY/P109/edgesA --input2 Census/S/WY/P109/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/WY/P109//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/WY/P109//boundary.wkt --tolerance 1e-3 --qtag 109_Census/S/WY_1e-3_1 --debug --local
2022-03-21 00:37:32,146|13779|application_1639015019875_1391|INFO|scale=1000.0
2022-03-21 00:37:32,214|13847|Saved /tmp/edgesCells_109.wkt in 0.01s [343 records].
2022-03-21 00:37:32,214|13847|application_1639015019875_1391|INFO|npartitions=343
2022-03-21 00:37:32,214|13847|application_1639015019875_1391|137|TIME|start|109_Census/S/WY_1e-3_1
2022-03-21 00:37:42,956|24589|application_1639015019875_1391|INFO|nEdgesA=225166
2022-03-21 00:37:44,897|26530|application_1639015019875_1391|INFO|nEdgesB=225574
2022-03-21 00:37:44,897|26530|application_1639015019875_1391|12683|TIME|read|109_Census/S/WY_1e-3_1
2022-03-21 00:37:46,710|28343|application_1639015019875_1391|1813|TIME|layer1S|109_Census/S/WY_1e-3_1
2022-03-21 00:37:47,360|28993|Saved /tmp/edgesFAC.wkt in 0.06s [973 records].
2022-03-21 00:37:48,324|29957|application_1639015019875_1391|1614|TIME|layer2S|109_Census/S/WY_1e-3_1
2022-03-21 00:37:48,942|30575|Saved /tmp/edgesFBC.wkt in 0.05s [982 records].
2022-03-21 00:38:37,260|78893|Saved /tmp/edgesS.wkt in 0.06s [2113 records].
2022-03-21 00:38:38,044|79677|application_1639015019875_1391|49720|TIME|overlayS|109_Census/S/WY_1e-3_1
2022-03-21 00:38:38,358|79991|Saved /tmp/edgesFE.wkt in 0.07s [234 records].
2022-03-21 00:38:38,358|79991|application_1639015019875_1391|314|TIME|end|109_Census/S/WY_1e-3_1
hdfs dfs -mkdir Census/S/AS/
hdfs dfs -put ~/Datasets/Census/AS/AS2000.wkt Census/S/AS/A.wkt
hdfs dfs -put ~/Datasets/Census/AS/AS2010.wkt Census/S/AS/B.wkt
./QuadPart -d Census/S/AS -p 1 -t 1e-3
DATASET    = Census/S/AS
TOLERANCE  = 1e-3
PARTITIONS = 1
./QuadPlusPart 1 Census/S/AS 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/AS/P1 ...
2022-03-21 00:38:56,405|2827|local-1647848334800|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AS/A.wkt --input2 Census/S/AS/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/AS/P1/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/AS/P1/boundary.wkt --partitions 1 --tolerance 1e-3
2022-03-21 00:38:56,406|2828|local-1647848334800|INFO|scale=1000.0
2022-03-21 00:38:56,415|2837|local-1647848334800|TIME|Start
2022-03-21 00:39:02,721|9143|local-1647848334800|INFO|edgesA=4884
2022-03-21 00:39:03,062|9484|local-1647848334800|INFO|edgesB=3306
2022-03-21 00:39:03,174|9596|local-1647848334800|TIME|Read
2022-03-21 00:39:03,174|9596|Partition by number (1)
2022-03-21 00:39:03,178|9600|Fraction: 0.015863322338322605
2022-03-21 00:39:03,286|9708|local-1647848334800|INFO|partitions=1
2022-03-21 00:39:03,287|9709|local-1647848334800|TIME|Partition
2022-03-21 00:39:03,291|9713|Saved /home/acald013/RIDIR/local_path/Census/S/AS/P1/boundary.wkt in 0.00s [1 records].
2022-03-21 00:39:03,292|9714|Saved /home/acald013/RIDIR/local_path/Census/S/AS/P1/quadtree.wkt in 0.00s [1 records].
2022-03-21 00:39:03,517|9939|local-1647848334800|TIME|Close
Partitioning edges...
rm -f -r Census/S/AS/P1/edgesA/
rm -f -r Census/S/AS/P1/edgesB/
2022-03-21 00:39:20,673|13943|application_1639015019875_1392|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AS/A.wkt --input2 Census/S/AS/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/AS/P1/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/AS/P1/boundary.wkt --apath Census/S/AS/P1/edgesA --bpath Census/S/AS/P1/edgesB --tolerance 1e-3 --save
2022-03-21 00:39:20,673|13943|application_1639015019875_1392|INFO|scale=1000.0
2022-03-21 00:39:20,687|13957|application_1639015019875_1392|TIME|Start
2022-03-21 00:39:29,132|22402|application_1639015019875_1392|INFO|edgesA=4884
2022-03-21 00:39:33,891|27161|application_1639015019875_1392|INFO|edgesB=3306
2022-03-21 00:39:33,898|27168|application_1639015019875_1392|TIME|Read
2022-03-21 00:39:36,722|29992|application_1639015019875_1392|TIME|Saving
./Perf -d Census/S/AS -p 1 -t 1e-3 -n 1
DATASET    = Census/S/AS
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 1
Run 1 ./sdcel2_debug Census/S/AS/P1 /home/acald013/RIDIR/local_path/Census/S/AS/P1/ 1e-3 "1_Census/S/AS_1e-3_1"
2022-03-21 00:39:53,994|13752|application_1639015019875_1393|13996|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/AS/P1/edgesA --input2 Census/S/AS/P1/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/AS/P1//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/AS/P1//boundary.wkt --tolerance 1e-3 --qtag 1_Census/S/AS_1e-3_1 --debug --local
2022-03-21 00:39:54,036|13794|application_1639015019875_1393|INFO|scale=1000.0
2022-03-21 00:39:54,042|13800|Saved /tmp/edgesCells_1.wkt in 0.00s [1 records].
2022-03-21 00:39:54,042|13800|application_1639015019875_1393|INFO|npartitions=1
2022-03-21 00:39:54,042|13800|application_1639015019875_1393|48|TIME|start|1_Census/S/AS_1e-3_1
2022-03-21 00:40:02,780|22538|application_1639015019875_1393|INFO|nEdgesA=4884
2022-03-21 00:40:03,472|23230|application_1639015019875_1393|INFO|nEdgesB=3306
2022-03-21 00:40:03,472|23230|application_1639015019875_1393|9430|TIME|read|1_Census/S/AS_1e-3_1
2022-03-21 00:40:04,314|24072|application_1639015019875_1393|842|TIME|layer1S|1_Census/S/AS_1e-3_1
2022-03-21 00:40:05,218|24976|Saved /tmp/edgesFAC.wkt in 0.00s [21 records].
2022-03-21 00:40:05,434|25192|application_1639015019875_1393|1120|TIME|layer2S|1_Census/S/AS_1e-3_1
2022-03-21 00:40:06,011|25769|Saved /tmp/edgesFBC.wkt in 0.00s [19 records].
2022-03-21 00:40:08,670|28428|Saved /tmp/edgesS.wkt in 0.00s [73 records].
2022-03-21 00:40:09,034|28792|application_1639015019875_1393|3600|TIME|overlayS|1_Census/S/AS_1e-3_1
2022-03-21 00:40:09,114|28872|Saved /tmp/edgesFE.wkt in 0.00s [73 records].
2022-03-21 00:40:09,114|28872|application_1639015019875_1393|80|TIME|end|1_Census/S/AS_1e-3_1
hdfs dfs -mkdir Census/S/GU/
hdfs dfs -put ~/Datasets/Census/GU/GU2000.wkt Census/S/GU/A.wkt
hdfs dfs -put ~/Datasets/Census/GU/GU2010.wkt Census/S/GU/B.wkt
./QuadPart -d Census/S/GU -p 26 -t 1e-3
DATASET    = Census/S/GU
TOLERANCE  = 1e-3
PARTITIONS = 26
./QuadPlusPart 26 Census/S/GU 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/GU/P26 ...
2022-03-21 00:40:27,343|2805|local-1647848425698|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/GU/A.wkt --input2 Census/S/GU/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/GU/P26/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/GU/P26/boundary.wkt --partitions 26 --tolerance 1e-3
2022-03-21 00:40:27,344|2806|local-1647848425698|INFO|scale=1000.0
2022-03-21 00:40:27,352|2814|local-1647848425698|TIME|Start
2022-03-21 00:40:33,701|9163|local-1647848425698|INFO|edgesA=16464
2022-03-21 00:40:34,420|9882|local-1647848425698|INFO|edgesB=53488
2022-03-21 00:40:34,603|10065|local-1647848425698|TIME|Read
2022-03-21 00:40:34,604|10066|Partition by number (26)
2022-03-21 00:40:34,607|10069|Fraction: 0.011751718726430329
2022-03-21 00:40:34,735|10197|local-1647848425698|INFO|partitions=76
2022-03-21 00:40:34,736|10198|local-1647848425698|TIME|Partition
2022-03-21 00:40:34,739|10201|Saved /home/acald013/RIDIR/local_path/Census/S/GU/P26/boundary.wkt in 0.00s [1 records].
2022-03-21 00:40:34,762|10224|Saved /home/acald013/RIDIR/local_path/Census/S/GU/P26/quadtree.wkt in 0.00s [76 records].
2022-03-21 00:40:34,900|10362|local-1647848425698|TIME|Close
Partitioning edges...
rm -f -r Census/S/GU/P26/edgesA/
rm -f -r Census/S/GU/P26/edgesB/
2022-03-21 00:40:52,150|13966|application_1639015019875_1394|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/GU/A.wkt --input2 Census/S/GU/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/GU/P26/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/GU/P26/boundary.wkt --apath Census/S/GU/P26/edgesA --bpath Census/S/GU/P26/edgesB --tolerance 1e-3 --save
2022-03-21 00:40:52,150|13966|application_1639015019875_1394|INFO|scale=1000.0
2022-03-21 00:40:52,165|13981|application_1639015019875_1394|TIME|Start
2022-03-21 00:41:00,775|22591|application_1639015019875_1394|INFO|edgesA=16464
2022-03-21 00:41:05,768|27584|application_1639015019875_1394|INFO|edgesB=53488
2022-03-21 00:41:05,779|27595|application_1639015019875_1394|TIME|Read
2022-03-21 00:41:13,010|34826|application_1639015019875_1394|TIME|Saving
./Perf -d Census/S/GU -p 26 -t 1e-3 -n 1
DATASET    = Census/S/GU
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 26
Run 1 ./sdcel2_debug Census/S/GU/P26 /home/acald013/RIDIR/local_path/Census/S/GU/P26/ 1e-3 "26_Census/S/GU_1e-3_1"
2022-03-21 00:41:30,458|13876|application_1639015019875_1395|14119|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/GU/P26/edgesA --input2 Census/S/GU/P26/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/GU/P26//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/GU/P26//boundary.wkt --tolerance 1e-3 --qtag 26_Census/S/GU_1e-3_1 --debug --local
2022-03-21 00:41:30,516|13934|application_1639015019875_1395|INFO|scale=1000.0
2022-03-21 00:41:30,546|13964|Saved /tmp/edgesCells_26.wkt in 0.00s [76 records].
2022-03-21 00:41:30,547|13965|application_1639015019875_1395|INFO|npartitions=76
2022-03-21 00:41:30,547|13965|application_1639015019875_1395|90|TIME|start|26_Census/S/GU_1e-3_1
2022-03-21 00:41:39,819|23237|application_1639015019875_1395|INFO|nEdgesA=16826
2022-03-21 00:41:41,073|24491|application_1639015019875_1395|INFO|nEdgesB=53878
2022-03-21 00:41:41,074|24492|application_1639015019875_1395|10527|TIME|read|26_Census/S/GU_1e-3_1
2022-03-21 00:41:41,868|25286|application_1639015019875_1395|794|TIME|layer1S|26_Census/S/GU_1e-3_1
2022-03-21 00:41:42,168|25586|Saved /tmp/edgesFAC.wkt in 0.01s [301 records].
2022-03-21 00:41:42,938|26356|application_1639015019875_1395|1070|TIME|layer2S|26_Census/S/GU_1e-3_1
2022-03-21 00:41:43,545|26963|Saved /tmp/edgesFBC.wkt in 0.01s [356 records].
2022-03-21 00:42:06,022|49440|Saved /tmp/edgesS.wkt in 0.01s [1133 records].
2022-03-21 00:42:06,417|49835|application_1639015019875_1395|23479|TIME|overlayS|26_Census/S/GU_1e-3_1
2022-03-21 00:42:06,532|49950|Saved /tmp/edgesFE.wkt in 0.01s [260 records].
2022-03-21 00:42:06,532|49950|application_1639015019875_1395|115|TIME|end|26_Census/S/GU_1e-3_1
hdfs dfs -mkdir Census/S/MP/
hdfs dfs -put ~/Datasets/Census/MP/MP2000.wkt Census/S/MP/A.wkt
hdfs dfs -put ~/Datasets/Census/MP/MP2010.wkt Census/S/MP/B.wkt
./QuadPart -d Census/S/MP -p 18 -t 1e-3
DATASET    = Census/S/MP
TOLERANCE  = 1e-3
PARTITIONS = 18
./QuadPlusPart 18 Census/S/MP 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/MP/P18 ...
2022-03-21 00:42:25,526|2946|local-1647848543834|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MP/A.wkt --input2 Census/S/MP/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/MP/P18/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/MP/P18/boundary.wkt --partitions 18 --tolerance 1e-3
2022-03-21 00:42:25,527|2947|local-1647848543834|INFO|scale=1000.0
2022-03-21 00:42:25,537|2957|local-1647848543834|TIME|Start
2022-03-21 00:42:31,950|9370|local-1647848543834|INFO|edgesA=8224
2022-03-21 00:42:32,575|9995|local-1647848543834|INFO|edgesB=36864
2022-03-21 00:42:32,696|10116|local-1647848543834|TIME|Read
2022-03-21 00:42:32,696|10116|Partition by number (18)
2022-03-21 00:42:32,700|10120|Fraction: 0.012214350817337486
2022-03-21 00:42:32,822|10242|local-1647848543834|INFO|partitions=67
2022-03-21 00:42:32,823|10243|local-1647848543834|TIME|Partition
2022-03-21 00:42:32,827|10247|Saved /home/acald013/RIDIR/local_path/Census/S/MP/P18/boundary.wkt in 0.00s [1 records].
2022-03-21 00:42:32,848|10268|Saved /home/acald013/RIDIR/local_path/Census/S/MP/P18/quadtree.wkt in 0.00s [67 records].
2022-03-21 00:42:33,069|10489|local-1647848543834|TIME|Close
Partitioning edges...
rm -f -r Census/S/MP/P18/edgesA/
rm -f -r Census/S/MP/P18/edgesB/
2022-03-21 00:42:50,087|13755|application_1639015019875_1396|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MP/A.wkt --input2 Census/S/MP/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/MP/P18/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MP/P18/boundary.wkt --apath Census/S/MP/P18/edgesA --bpath Census/S/MP/P18/edgesB --tolerance 1e-3 --save
2022-03-21 00:42:50,088|13756|application_1639015019875_1396|INFO|scale=1000.0
2022-03-21 00:42:50,101|13769|application_1639015019875_1396|TIME|Start
2022-03-21 00:42:58,658|22326|application_1639015019875_1396|INFO|edgesA=8224
2022-03-21 00:43:03,551|27219|application_1639015019875_1396|INFO|edgesB=36864
2022-03-21 00:43:03,559|27227|application_1639015019875_1396|TIME|Read
2022-03-21 00:43:09,246|32914|application_1639015019875_1396|TIME|Saving
./Perf -d Census/S/MP -p 18 -t 1e-3 -n 1
DATASET    = Census/S/MP
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 18
Run 1 ./sdcel2_debug Census/S/MP/P18 /home/acald013/RIDIR/local_path/Census/S/MP/P18/ 1e-3 "18_Census/S/MP_1e-3_1"
2022-03-21 00:43:26,263|13438|application_1639015019875_1397|13691|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/MP/P18/edgesA --input2 Census/S/MP/P18/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/MP/P18//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/MP/P18//boundary.wkt --tolerance 1e-3 --qtag 18_Census/S/MP_1e-3_1 --debug --local
2022-03-21 00:43:26,321|13496|application_1639015019875_1397|INFO|scale=1000.0
2022-03-21 00:43:26,348|13523|Saved /tmp/edgesCells_18.wkt in 0.00s [67 records].
2022-03-21 00:43:26,348|13523|application_1639015019875_1397|INFO|npartitions=67
2022-03-21 00:43:26,348|13523|application_1639015019875_1397|86|TIME|start|18_Census/S/MP_1e-3_1
2022-03-21 00:43:35,346|22521|application_1639015019875_1397|INFO|nEdgesA=8362
2022-03-21 00:43:36,426|23601|application_1639015019875_1397|INFO|nEdgesB=37108
2022-03-21 00:43:36,426|23601|application_1639015019875_1397|10078|TIME|read|18_Census/S/MP_1e-3_1
2022-03-21 00:43:37,268|24443|application_1639015019875_1397|842|TIME|layer1S|18_Census/S/MP_1e-3_1
2022-03-21 00:43:37,537|24712|Saved /tmp/edgesFAC.wkt in 0.00s [136 records].
2022-03-21 00:43:38,220|25395|application_1639015019875_1397|952|TIME|layer2S|18_Census/S/MP_1e-3_1
2022-03-21 00:43:38,664|25839|Saved /tmp/edgesFBC.wkt in 0.01s [205 records].
2022-03-21 00:43:50,533|37708|Saved /tmp/edgesS.wkt in 0.01s [544 records].
2022-03-21 00:43:50,963|38138|application_1639015019875_1397|12743|TIME|overlayS|18_Census/S/MP_1e-3_1
2022-03-21 00:43:51,181|38356|Saved /tmp/edgesFE.wkt in 0.09s [84 records].
2022-03-21 00:43:51,181|38356|application_1639015019875_1397|218|TIME|end|18_Census/S/MP_1e-3_1
hdfs dfs -mkdir Census/S/PR/
hdfs dfs -put ~/Datasets/Census/PR/PR2000.wkt Census/S/PR/A.wkt
hdfs dfs -put ~/Datasets/Census/PR/PR2010.wkt Census/S/PR/B.wkt
./QuadPart -d Census/S/PR -p 169 -t 1e-3
DATASET    = Census/S/PR
TOLERANCE  = 1e-3
PARTITIONS = 169
./QuadPlusPart 169 Census/S/PR 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/PR/P169 ...
2022-03-21 00:44:09,943|2843|local-1647848648302|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/PR/A.wkt --input2 Census/S/PR/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/PR/P169/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/PR/P169/boundary.wkt --partitions 169 --tolerance 1e-3
2022-03-21 00:44:09,944|2844|local-1647848648302|INFO|scale=1000.0
2022-03-21 00:44:09,953|2853|local-1647848648302|TIME|Start
2022-03-21 00:44:17,194|10094|local-1647848648302|INFO|edgesA=331129
2022-03-21 00:44:18,305|11205|local-1647848648302|INFO|edgesB=344969
2022-03-21 00:44:18,458|11358|local-1647848648302|TIME|Read
2022-03-21 00:44:18,459|11359|Partition by number (169)
2022-03-21 00:44:18,463|11363|Fraction: 0.010534286182486622
2022-03-21 00:44:18,678|11578|local-1647848648302|INFO|partitions=427
2022-03-21 00:44:18,678|11578|local-1647848648302|TIME|Partition
2022-03-21 00:44:18,682|11582|Saved /home/acald013/RIDIR/local_path/Census/S/PR/P169/boundary.wkt in 0.00s [1 records].
2022-03-21 00:44:18,743|11643|Saved /home/acald013/RIDIR/local_path/Census/S/PR/P169/quadtree.wkt in 0.00s [427 records].
2022-03-21 00:44:18,994|11894|local-1647848648302|TIME|Close
Partitioning edges...
rm -f -r Census/S/PR/P169/edgesA/
rm -f -r Census/S/PR/P169/edgesB/
2022-03-21 00:44:36,464|13897|application_1639015019875_1398|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/PR/A.wkt --input2 Census/S/PR/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/PR/P169/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/PR/P169/boundary.wkt --apath Census/S/PR/P169/edgesA --bpath Census/S/PR/P169/edgesB --tolerance 1e-3 --save
2022-03-21 00:44:36,465|13898|application_1639015019875_1398|INFO|scale=1000.0
2022-03-21 00:44:36,478|13911|application_1639015019875_1398|TIME|Start
2022-03-21 00:44:49,986|27419|application_1639015019875_1398|INFO|edgesA=331129
2022-03-21 00:44:55,645|33078|application_1639015019875_1398|INFO|edgesB=344969
2022-03-21 00:44:55,653|33086|application_1639015019875_1398|TIME|Read
2022-03-21 00:45:04,810|42243|application_1639015019875_1398|TIME|Saving
./Perf -d Census/S/PR -p 169 -t 1e-3 -n 1
DATASET    = Census/S/PR
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 169
Run 1 ./sdcel2_debug Census/S/PR/P169 /home/acald013/RIDIR/local_path/Census/S/PR/P169/ 1e-3 "169_Census/S/PR_1e-3_1"
2022-03-21 00:45:22,212|13764|application_1639015019875_1399|14017|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/PR/P169/edgesA --input2 Census/S/PR/P169/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/PR/P169//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/PR/P169//boundary.wkt --tolerance 1e-3 --qtag 169_Census/S/PR_1e-3_1 --debug --local
2022-03-21 00:45:22,290|13842|application_1639015019875_1399|INFO|scale=1000.0
2022-03-21 00:45:22,358|13910|Saved /tmp/edgesCells_169.wkt in 0.00s [427 records].
2022-03-21 00:45:22,358|13910|application_1639015019875_1399|INFO|npartitions=427
2022-03-21 00:45:22,359|13911|application_1639015019875_1399|147|TIME|start|169_Census/S/PR_1e-3_1
2022-03-21 00:45:34,040|25592|application_1639015019875_1399|INFO|nEdgesA=334657
2022-03-21 00:45:35,752|27304|application_1639015019875_1399|INFO|nEdgesB=348645
2022-03-21 00:45:35,752|27304|application_1639015019875_1399|13393|TIME|read|169_Census/S/PR_1e-3_1
2022-03-21 00:45:37,325|28877|application_1639015019875_1399|1573|TIME|layer1S|169_Census/S/PR_1e-3_1
2022-03-21 00:45:38,253|29805|Saved /tmp/edgesFAC.wkt in 0.07s [3033 records].
2022-03-21 00:45:39,203|30755|application_1639015019875_1399|1878|TIME|layer2S|169_Census/S/PR_1e-3_1
2022-03-21 00:45:40,197|31749|Saved /tmp/edgesFBC.wkt in 0.05s [3188 records].
2022-03-21 00:46:01,123|52675|Saved /tmp/edgesS.wkt in 0.08s [7455 records].
2022-03-21 00:46:02,288|53840|application_1639015019875_1399|23084|TIME|overlayS|169_Census/S/PR_1e-3_1
2022-03-21 00:46:02,829|54381|Saved /tmp/edgesFE.wkt in 0.10s [1635 records].
2022-03-21 00:46:02,830|54382|application_1639015019875_1399|543|TIME|end|169_Census/S/PR_1e-3_1
hdfs dfs -mkdir Census/S/VI/
mkdir: `Census/S/VI': File exists
hdfs dfs -put ~/Datasets/Census/VI/VI2000.wkt Census/S/VI/A.wkt
put: `Census/S/VI/A.wkt': File exists
hdfs dfs -put ~/Datasets/Census/VI/VI2010.wkt Census/S/VI/B.wkt
put: `Census/S/VI/B.wkt': File exists
./QuadPart -d Census/S/VI -p 19 -t 1e-3
DATASET    = Census/S/VI
TOLERANCE  = 1e-3
PARTITIONS = 19
./QuadPlusPart 19 Census/S/VI 1e-3
Making folders...
mkdir: `Census/S/VI/P19': File exists
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/Census/S/VI/P19 ...
2022-03-21 00:46:20,695|2997|local-1647848778868|COMMAND|org.apache.spark.deploy.SparkSubmit --master local[10] --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/VI/A.wkt --input2 Census/S/VI/B.wkt --qpath /home/acald013/RIDIR/local_path/Census/S/VI/P19/quadtree.wkt --epath /home/acald013/RIDIR/local_path/Census/S/VI/P19/boundary.wkt --partitions 19 --tolerance 1e-3
2022-03-21 00:46:20,696|2998|local-1647848778868|INFO|scale=1000.0
2022-03-21 00:46:20,705|3007|local-1647848778868|TIME|Start
2022-03-21 00:46:27,402|9704|local-1647848778868|INFO|edgesA=58356
2022-03-21 00:46:28,002|10304|local-1647848778868|INFO|edgesB=39900
2022-03-21 00:46:28,124|10426|local-1647848778868|TIME|Read
2022-03-21 00:46:28,125|10427|Partition by number (19)
2022-03-21 00:46:28,129|10431|Fraction: 0.011460074625391444
2022-03-21 00:46:28,256|10558|local-1647848778868|INFO|partitions=58
2022-03-21 00:46:28,256|10558|local-1647848778868|TIME|Partition
2022-03-21 00:46:28,260|10562|Saved /home/acald013/RIDIR/local_path/Census/S/VI/P19/boundary.wkt in 0.00s [1 records].
2022-03-21 00:46:28,277|10579|Saved /home/acald013/RIDIR/local_path/Census/S/VI/P19/quadtree.wkt in 0.00s [58 records].
2022-03-21 00:46:28,419|10721|local-1647848778868|TIME|Close
Partitioning edges...
rm -f -r Census/S/VI/P19/edgesA/
rm -f -r Census/S/VI/P19/edgesB/
2022-03-21 00:46:45,620|13958|application_1639015019875_1400|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/VI/A.wkt --input2 Census/S/VI/B.wkt --quadtree /home/acald013/RIDIR/local_path/Census/S/VI/P19/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/VI/P19/boundary.wkt --apath Census/S/VI/P19/edgesA --bpath Census/S/VI/P19/edgesB --tolerance 1e-3 --save
2022-03-21 00:46:45,621|13959|application_1639015019875_1400|INFO|scale=1000.0
2022-03-21 00:46:45,634|13972|application_1639015019875_1400|TIME|Start
2022-03-21 00:46:54,554|22892|application_1639015019875_1400|INFO|edgesA=58356
2022-03-21 00:46:59,688|28026|application_1639015019875_1400|INFO|edgesB=39900
2022-03-21 00:46:59,696|28034|application_1639015019875_1400|TIME|Read
2022-03-21 00:47:07,263|35601|application_1639015019875_1400|TIME|Saving
./Perf -d Census/S/VI -p 19 -t 1e-3 -n 1
DATASET    = Census/S/VI
TOLERANCE  = 1e-3
ITERATIONS = 1
PARTITIONS = 19
Run 1 ./sdcel2_debug Census/S/VI/P19 /home/acald013/RIDIR/local_path/Census/S/VI/P19/ 1e-3 "19_Census/S/VI_1e-3_1"
2022-03-21 00:47:24,297|13552|application_1639015019875_1401|13797|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 Census/S/VI/P19/edgesA --input2 Census/S/VI/P19/edgesB --quadtree /home/acald013/RIDIR/local_path/Census/S/VI/P19//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/Census/S/VI/P19//boundary.wkt --tolerance 1e-3 --qtag 19_Census/S/VI_1e-3_1 --debug --local
2022-03-21 00:47:24,355|13610|application_1639015019875_1401|INFO|scale=1000.0
2022-03-21 00:47:24,380|13635|Saved /tmp/edgesCells_19.wkt in 0.00s [58 records].
2022-03-21 00:47:24,381|13636|application_1639015019875_1401|INFO|npartitions=58
2022-03-21 00:47:24,381|13636|application_1639015019875_1401|84|TIME|start|19_Census/S/VI_1e-3_1
2022-03-21 00:47:33,672|22927|application_1639015019875_1401|INFO|nEdgesA=58638
2022-03-21 00:47:34,849|24104|application_1639015019875_1401|INFO|nEdgesB=40172
2022-03-21 00:47:34,849|24104|application_1639015019875_1401|10468|TIME|read|19_Census/S/VI_1e-3_1
2022-03-21 00:47:36,427|25682|application_1639015019875_1401|1578|TIME|layer1S|19_Census/S/VI_1e-3_1
2022-03-21 00:47:37,237|26492|Saved /tmp/edgesFAC.wkt in 0.02s [265 records].
2022-03-21 00:47:37,746|27001|application_1639015019875_1401|1319|TIME|layer2S|19_Census/S/VI_1e-3_1
2022-03-21 00:47:38,248|27503|Saved /tmp/edgesFBC.wkt in 0.01s [334 records].
2022-03-21 00:47:45,686|34941|Saved /tmp/edgesS.wkt in 0.02s [1075 records].
2022-03-21 00:47:47,068|36323|application_1639015019875_1401|9322|TIME|overlayS|19_Census/S/VI_1e-3_1
2022-03-21 00:47:47,286|36541|Saved /tmp/edgesFE.wkt in 0.02s [348 records].
2022-03-21 00:47:47,286|36541|application_1639015019875_1401|218|TIME|end|19_Census/S/VI_1e-3_1
