DATASET    = gadm/l3vsl2
TOLERANCE  = 1e-3
FIRST      = 22000
INCREMENT  = 2000
LAST       = 30000
ITERATIONS = 5
MASTER     = yarn
Run 1 ./sdcel2_debug gadm/l3vsl2/P22000 /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000/ 1e-3 "22000_gadm/l3vsl2_1e-3_1" yarn 
2022-04-06 12:05:06,900|31698|application_1648870353198_0269|31960|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/P22000/edgesA --input2 gadm/l3vsl2/P22000/edgesB --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000//boundary.wkt --tolerance 1e-3 --qtag 22000_gadm/l3vsl2_1e-3_1 --ooption 0 --level 4
2022-04-06 12:05:06,900|31698|application_1648870353198_0269|INFO|tolerance=0.001
2022-04-06 12:05:06,901|31699|application_1648870353198_0269|INFO|overlay_option=0
2022-04-06 12:05:06,901|31699|application_1648870353198_0269|INFO|overlay_level=4
Exception in thread "main" java.io.FileNotFoundException: /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000/quadtree.wkt (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at scala.io.Source$.fromFile(Source.scala:91)
	at scala.io.Source$.fromFile(Source.scala:76)
	at scala.io.Source$.fromFile(Source.scala:54)
	at edu.ucr.dblab.sdcel.PartitionReader$.readQuadtree(PartitionReader.scala:26)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:56)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Run 1 ./sdcel2_debug gadm/l3vsl2/P24000 /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000/ 1e-3 "24000_gadm/l3vsl2_1e-3_1" yarn 
2022-04-06 12:05:42,695|31495|application_1648870353198_0270|31815|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/P24000/edgesA --input2 gadm/l3vsl2/P24000/edgesB --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000//boundary.wkt --tolerance 1e-3 --qtag 24000_gadm/l3vsl2_1e-3_1 --ooption 0 --level 4
2022-04-06 12:05:42,696|31496|application_1648870353198_0270|INFO|tolerance=0.001
2022-04-06 12:05:42,699|31499|application_1648870353198_0270|INFO|overlay_option=0
2022-04-06 12:05:42,699|31499|application_1648870353198_0270|INFO|overlay_level=4
Exception in thread "main" java.io.FileNotFoundException: /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000/quadtree.wkt (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at scala.io.Source$.fromFile(Source.scala:91)
	at scala.io.Source$.fromFile(Source.scala:76)
	at scala.io.Source$.fromFile(Source.scala:54)
	at edu.ucr.dblab.sdcel.PartitionReader$.readQuadtree(PartitionReader.scala:26)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:56)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Run 1 ./sdcel2_debug gadm/l3vsl2/P26000 /home/acald013/RIDIR/local_path/gadm/l3vsl2/P26000/ 1e-3 "26000_gadm/l3vsl2_1e-3_1" yarn 
2022-04-06 12:06:19,923|31697|application_1648870353198_0271|32038|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/P26000/edgesA --input2 gadm/l3vsl2/P26000/edgesB --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P26000//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P26000//boundary.wkt --tolerance 1e-3 --qtag 26000_gadm/l3vsl2_1e-3_1 --ooption 0 --level 4
2022-04-06 12:06:19,924|31698|application_1648870353198_0271|INFO|tolerance=0.001
2022-04-06 12:06:19,924|31698|application_1648870353198_0271|INFO|overlay_option=0
2022-04-06 12:06:19,925|31699|application_1648870353198_0271|INFO|overlay_level=4
Exception in thread "main" java.io.FileNotFoundException: /home/acald013/RIDIR/local_path/gadm/l3vsl2/P26000/quadtree.wkt (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at scala.io.Source$.fromFile(Source.scala:91)
	at scala.io.Source$.fromFile(Source.scala:76)
	at scala.io.Source$.fromFile(Source.scala:54)
	at edu.ucr.dblab.sdcel.PartitionReader$.readQuadtree(PartitionReader.scala:26)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:56)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Run 1 ./sdcel2_debug gadm/l3vsl2/P28000 /home/acald013/RIDIR/local_path/gadm/l3vsl2/P28000/ 1e-3 "28000_gadm/l3vsl2_1e-3_1" yarn 
2022-04-06 12:06:58,100|31542|application_1648870353198_0272|31836|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/P28000/edgesA --input2 gadm/l3vsl2/P28000/edgesB --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P28000//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P28000//boundary.wkt --tolerance 1e-3 --qtag 28000_gadm/l3vsl2_1e-3_1 --ooption 0 --level 4
2022-04-06 12:06:58,101|31543|application_1648870353198_0272|INFO|tolerance=0.001
2022-04-06 12:06:58,101|31543|application_1648870353198_0272|INFO|overlay_option=0
2022-04-06 12:06:58,101|31543|application_1648870353198_0272|INFO|overlay_level=4
Exception in thread "main" java.io.FileNotFoundException: /home/acald013/RIDIR/local_path/gadm/l3vsl2/P28000/quadtree.wkt (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at scala.io.Source$.fromFile(Source.scala:91)
	at scala.io.Source$.fromFile(Source.scala:76)
	at scala.io.Source$.fromFile(Source.scala:54)
	at edu.ucr.dblab.sdcel.PartitionReader$.readQuadtree(PartitionReader.scala:26)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:56)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Run 1 ./sdcel2_debug gadm/l3vsl2/P30000 /home/acald013/RIDIR/local_path/gadm/l3vsl2/P30000/ 1e-3 "30000_gadm/l3vsl2_1e-3_1" yarn 
2022-04-06 12:07:33,320|31513|application_1648870353198_0273|31776|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/P30000/edgesA --input2 gadm/l3vsl2/P30000/edgesB --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P30000//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P30000//boundary.wkt --tolerance 1e-3 --qtag 30000_gadm/l3vsl2_1e-3_1 --ooption 0 --level 4
2022-04-06 12:07:33,321|31514|application_1648870353198_0273|INFO|tolerance=0.001
2022-04-06 12:07:33,321|31514|application_1648870353198_0273|INFO|overlay_option=0
2022-04-06 12:07:33,321|31514|application_1648870353198_0273|INFO|overlay_level=4
Exception in thread "main" java.io.FileNotFoundException: /home/acald013/RIDIR/local_path/gadm/l3vsl2/P30000/quadtree.wkt (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at scala.io.Source$.fromFile(Source.scala:91)
	at scala.io.Source$.fromFile(Source.scala:76)
	at scala.io.Source$.fromFile(Source.scala:54)
	at edu.ucr.dblab.sdcel.PartitionReader$.readQuadtree(PartitionReader.scala:26)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:56)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Run 2 ./sdcel2_debug gadm/l3vsl2/P22000 /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000/ 1e-3 "22000_gadm/l3vsl2_1e-3_2" yarn 
2022-04-06 12:08:08,582|31319|application_1648870353198_0274|31605|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/P22000/edgesA --input2 gadm/l3vsl2/P22000/edgesB --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000//boundary.wkt --tolerance 1e-3 --qtag 22000_gadm/l3vsl2_1e-3_2 --ooption 0 --level 4
2022-04-06 12:08:08,582|31319|application_1648870353198_0274|INFO|tolerance=0.001
2022-04-06 12:08:08,583|31320|application_1648870353198_0274|INFO|overlay_option=0
2022-04-06 12:08:08,583|31320|application_1648870353198_0274|INFO|overlay_level=4
Exception in thread "main" java.io.FileNotFoundException: /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000/quadtree.wkt (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at scala.io.Source$.fromFile(Source.scala:91)
	at scala.io.Source$.fromFile(Source.scala:76)
	at scala.io.Source$.fromFile(Source.scala:54)
	at edu.ucr.dblab.sdcel.PartitionReader$.readQuadtree(PartitionReader.scala:26)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:56)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Run 2 ./sdcel2_debug gadm/l3vsl2/P24000 /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000/ 1e-3 "24000_gadm/l3vsl2_1e-3_2" yarn 
2022-04-06 12:08:44,779|31527|application_1648870353198_0275|31836|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.SDCEL2 --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 20g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/P24000/edgesA --input2 gadm/l3vsl2/P24000/edgesB --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000//quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000//boundary.wkt --tolerance 1e-3 --qtag 24000_gadm/l3vsl2_1e-3_2 --ooption 0 --level 4
2022-04-06 12:08:44,779|31527|application_1648870353198_0275|INFO|tolerance=0.001
2022-04-06 12:08:44,780|31528|application_1648870353198_0275|INFO|overlay_option=0
2022-04-06 12:08:44,780|31528|application_1648870353198_0275|INFO|overlay_level=4
Exception in thread "main" java.io.FileNotFoundException: /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000/quadtree.wkt (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at scala.io.Source$.fromFile(Source.scala:91)
	at scala.io.Source$.fromFile(Source.scala:76)
	at scala.io.Source$.fromFile(Source.scala:54)
	at edu.ucr.dblab.sdcel.PartitionReader$.readQuadtree(PartitionReader.scala:26)
	at edu.ucr.dblab.sdcel.SDCEL2$.main(SDCEL2.scala:56)
	at edu.ucr.dblab.sdcel.SDCEL2.main(SDCEL2.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
DATASET    = gadm/l3vsl2
TOLERANCE  = 1e-3
FIRST      = 22000
INCREMENT  = 2000
LAST       = 30000
./QuadPlusPart 22000 gadm/l3vsl2 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000 ...
2022-04-06 12:10:01,624|13886|application_1648870353198_0276|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/A.wkt --input2 gadm/l3vsl2/B.wkt --qpath /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000/quadtree.wkt --epath /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000/boundary.wkt --partitions 22000 --tolerance 1e-3
2022-04-06 12:10:01,625|13887|application_1648870353198_0276|INFO|scale=1000.0
2022-04-06 12:10:01,635|13897|application_1648870353198_0276|TIME|Start
2022-04-06 12:10:24,159|36421|application_1648870353198_0276|INFO|edgesA=68779746
2022-04-06 12:10:59,327|71589|application_1648870353198_0276|INFO|edgesB=64598411
2022-04-06 12:11:13,880|86142|application_1648870353198_0276|TIME|Read
2022-04-06 12:11:13,880|86142|Partition by number (22000)
2022-04-06 12:11:13,884|86146|Fraction: 0.01003722781272588
2022-04-06 12:11:18,772|91034|application_1648870353198_0276|INFO|partitions=60808
2022-04-06 12:11:18,772|91034|application_1648870353198_0276|TIME|Partition
2022-04-06 12:11:18,779|91041|Saved /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000/boundary.wkt in 0.00s [1 records].
2022-04-06 12:11:20,039|92301|Saved /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000/quadtree.wkt in 0.13s [60808 records].
2022-04-06 12:11:20,730|92992|application_1648870353198_0276|TIME|Close
Partitioning edges...
rm -f -r gadm/l3vsl2/P22000/edgesA/
rm -f -r gadm/l3vsl2/P22000/edgesB/
2022-04-06 12:11:37,838|13578|application_1648870353198_0277|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/A.wkt --input2 gadm/l3vsl2/B.wkt --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P22000/boundary.wkt --apath gadm/l3vsl2/P22000/edgesA --bpath gadm/l3vsl2/P22000/edgesB --tolerance 1e-3 --save
2022-04-06 12:11:37,839|13579|application_1648870353198_0277|INFO|scale=1000.0
2022-04-06 12:11:37,852|13592|application_1648870353198_0277|TIME|Start
2022-04-06 12:12:01,525|37265|application_1648870353198_0277|INFO|edgesA=68779746
2022-04-06 12:12:28,459|64199|application_1648870353198_0277|INFO|edgesB=64598411
2022-04-06 12:12:28,472|64212|application_1648870353198_0277|TIME|Read
2022-04-06 12:25:27,238|842978|application_1648870353198_0277|TIME|Saving
./QuadPlusPart 24000 gadm/l3vsl2 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000 ...
2022-04-06 12:25:49,141|15296|application_1648870353198_0278|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/A.wkt --input2 gadm/l3vsl2/B.wkt --qpath /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000/quadtree.wkt --epath /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000/boundary.wkt --partitions 24000 --tolerance 1e-3
2022-04-06 12:25:49,142|15297|application_1648870353198_0278|INFO|scale=1000.0
2022-04-06 12:25:49,150|15305|application_1648870353198_0278|TIME|Start
2022-04-06 12:26:11,172|37327|application_1648870353198_0278|INFO|edgesA=68779746
2022-04-06 12:26:28,337|54492|application_1648870353198_0278|INFO|edgesB=64598411
2022-04-06 12:26:48,154|74309|application_1648870353198_0278|TIME|Read
2022-04-06 12:26:48,155|74310|Partition by number (24000)
2022-04-06 12:26:48,160|74315|Fraction: 0.01003722781272588
2022-04-06 12:26:53,311|79466|application_1648870353198_0278|INFO|partitions=66718
2022-04-06 12:26:53,311|79466|application_1648870353198_0278|TIME|Partition
2022-04-06 12:26:53,319|79474|Saved /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000/boundary.wkt in 0.00s [1 records].
2022-04-06 12:26:54,791|80946|Saved /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000/quadtree.wkt in 0.17s [66718 records].
2022-04-06 12:26:55,204|81359|application_1648870353198_0278|TIME|Close
Partitioning edges...
rm -f -r gadm/l3vsl2/P24000/edgesA/
rm -f -r gadm/l3vsl2/P24000/edgesB/
2022-04-06 12:27:12,327|13795|application_1648870353198_0279|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/A.wkt --input2 gadm/l3vsl2/B.wkt --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P24000/boundary.wkt --apath gadm/l3vsl2/P24000/edgesA --bpath gadm/l3vsl2/P24000/edgesB --tolerance 1e-3 --save
2022-04-06 12:27:12,327|13795|application_1648870353198_0279|INFO|scale=1000.0
2022-04-06 12:27:12,342|13810|application_1648870353198_0279|TIME|Start
2022-04-06 12:27:36,246|37714|application_1648870353198_0279|INFO|edgesA=68779746
2022-04-06 12:28:01,998|63466|application_1648870353198_0279|INFO|edgesB=64598411
2022-04-06 12:28:02,023|63491|application_1648870353198_0279|TIME|Read
2022-04-06 12:43:40,417|1001885|application_1648870353198_0279|TIME|Saving
./QuadPlusPart 26000 gadm/l3vsl2 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/gadm/l3vsl2/P26000 ...
2022-04-06 12:44:02,050|14833|application_1648870353198_0280|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/A.wkt --input2 gadm/l3vsl2/B.wkt --qpath /home/acald013/RIDIR/local_path/gadm/l3vsl2/P26000/quadtree.wkt --epath /home/acald013/RIDIR/local_path/gadm/l3vsl2/P26000/boundary.wkt --partitions 26000 --tolerance 1e-3
2022-04-06 12:44:02,051|14834|application_1648870353198_0280|INFO|scale=1000.0
2022-04-06 12:44:02,060|14843|application_1648870353198_0280|TIME|Start
2022-04-06 12:44:24,534|37317|application_1648870353198_0280|INFO|edgesA=68779746
2022-04-06 12:44:45,331|58114|application_1648870353198_0280|INFO|edgesB=64598411
2022-04-06 12:44:52,843|65626|application_1648870353198_0280|TIME|Read
2022-04-06 12:44:52,844|65627|Partition by number (26000)
2022-04-06 12:44:52,849|65632|Fraction: 0.01003722781272588
2022-04-06 12:44:58,158|70941|application_1648870353198_0280|INFO|partitions=71965
2022-04-06 12:44:58,158|70941|application_1648870353198_0280|TIME|Partition
2022-04-06 12:44:58,164|70947|Saved /home/acald013/RIDIR/local_path/gadm/l3vsl2/P26000/boundary.wkt in 0.00s [1 records].
2022-04-06 12:44:59,395|72178|Saved /home/acald013/RIDIR/local_path/gadm/l3vsl2/P26000/quadtree.wkt in 0.10s [71965 records].
2022-04-06 12:44:59,574|72357|application_1648870353198_0280|TIME|Close
Partitioning edges...
rm -f -r gadm/l3vsl2/P26000/edgesA/
rm -f -r gadm/l3vsl2/P26000/edgesB/
2022-04-06 12:45:16,652|13797|application_1648870353198_0281|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/A.wkt --input2 gadm/l3vsl2/B.wkt --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P26000/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P26000/boundary.wkt --apath gadm/l3vsl2/P26000/edgesA --bpath gadm/l3vsl2/P26000/edgesB --tolerance 1e-3 --save
2022-04-06 12:45:16,652|13797|application_1648870353198_0281|INFO|scale=1000.0
2022-04-06 12:45:16,667|13812|application_1648870353198_0281|TIME|Start
2022-04-06 12:45:38,674|35819|application_1648870353198_0281|INFO|edgesA=68779746
2022-04-06 12:46:03,291|60436|application_1648870353198_0281|INFO|edgesB=64598411
2022-04-06 12:46:03,304|60449|application_1648870353198_0281|TIME|Read
2022-04-06 13:03:27,591|1104736|application_1648870353198_0281|TIME|Saving
./QuadPlusPart 28000 gadm/l3vsl2 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/gadm/l3vsl2/P28000 ...
2022-04-06 13:03:48,374|14086|application_1648870353198_0282|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/A.wkt --input2 gadm/l3vsl2/B.wkt --qpath /home/acald013/RIDIR/local_path/gadm/l3vsl2/P28000/quadtree.wkt --epath /home/acald013/RIDIR/local_path/gadm/l3vsl2/P28000/boundary.wkt --partitions 28000 --tolerance 1e-3
2022-04-06 13:03:48,375|14087|application_1648870353198_0282|INFO|scale=1000.0
2022-04-06 13:03:48,383|14095|application_1648870353198_0282|TIME|Start
2022-04-06 13:04:09,748|35460|application_1648870353198_0282|INFO|edgesA=68779746
2022-04-06 13:04:35,209|60921|application_1648870353198_0282|INFO|edgesB=64598411
2022-04-06 13:04:48,663|74375|application_1648870353198_0282|TIME|Read
2022-04-06 13:04:48,663|74375|Partition by number (28000)
2022-04-06 13:04:48,668|74380|Fraction: 0.01003722781272588
2022-04-06 13:04:53,742|79454|application_1648870353198_0282|INFO|partitions=78019
2022-04-06 13:04:53,742|79454|application_1648870353198_0282|TIME|Partition
2022-04-06 13:04:53,751|79463|Saved /home/acald013/RIDIR/local_path/gadm/l3vsl2/P28000/boundary.wkt in 0.00s [1 records].
2022-04-06 13:04:55,064|80776|Saved /home/acald013/RIDIR/local_path/gadm/l3vsl2/P28000/quadtree.wkt in 0.11s [78019 records].
2022-04-06 13:04:55,325|81037|application_1648870353198_0282|TIME|Close
Partitioning edges...
rm -f -r gadm/l3vsl2/P28000/edgesA/
rm -f -r gadm/l3vsl2/P28000/edgesB/
2022-04-06 13:05:13,201|14382|application_1648870353198_0283|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/A.wkt --input2 gadm/l3vsl2/B.wkt --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P28000/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P28000/boundary.wkt --apath gadm/l3vsl2/P28000/edgesA --bpath gadm/l3vsl2/P28000/edgesB --tolerance 1e-3 --save
2022-04-06 13:05:13,201|14382|application_1648870353198_0283|INFO|scale=1000.0
2022-04-06 13:05:13,214|14395|application_1648870353198_0283|TIME|Start
2022-04-06 13:05:35,964|37145|application_1648870353198_0283|INFO|edgesA=68779746
2022-04-06 13:05:58,684|59865|application_1648870353198_0283|INFO|edgesB=64598411
2022-04-06 13:05:58,694|59875|application_1648870353198_0283|TIME|Read
2022-04-06 13:26:17,039|1278220|application_1648870353198_0283|TIME|Saving
./QuadPlusPart 30000 gadm/l3vsl2 1e-3
Making folders...
Creating quadtree...
Checking /home/acald013/RIDIR/local_path/gadm/l3vsl2/P30000 ...
2022-04-06 13:26:39,133|14351|application_1648870353198_0284|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.QuadtreeGenerator --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar,/home/acald013/Spark/2.4/jars/spark-measure_2.11-0.16.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/A.wkt --input2 gadm/l3vsl2/B.wkt --qpath /home/acald013/RIDIR/local_path/gadm/l3vsl2/P30000/quadtree.wkt --epath /home/acald013/RIDIR/local_path/gadm/l3vsl2/P30000/boundary.wkt --partitions 30000 --tolerance 1e-3
2022-04-06 13:26:39,134|14352|application_1648870353198_0284|INFO|scale=1000.0
2022-04-06 13:26:39,142|14360|application_1648870353198_0284|TIME|Start
2022-04-06 13:27:02,980|38198|application_1648870353198_0284|INFO|edgesA=68779746
2022-04-06 13:27:25,104|60322|application_1648870353198_0284|INFO|edgesB=64598411
2022-04-06 13:27:27,870|63088|application_1648870353198_0284|TIME|Read
2022-04-06 13:27:27,871|63089|Partition by number (30000)
2022-04-06 13:27:27,875|63093|Fraction: 0.01003722781272588
2022-04-06 13:27:38,378|73596|application_1648870353198_0284|INFO|partitions=83428
2022-04-06 13:27:38,378|73596|application_1648870353198_0284|TIME|Partition
2022-04-06 13:27:38,386|73604|Saved /home/acald013/RIDIR/local_path/gadm/l3vsl2/P30000/boundary.wkt in 0.00s [1 records].
2022-04-06 13:27:40,226|75444|Saved /home/acald013/RIDIR/local_path/gadm/l3vsl2/P30000/quadtree.wkt in 0.19s [83428 records].
2022-04-06 13:27:40,417|75635|application_1648870353198_0284|TIME|Close
Partitioning edges...
rm -f -r gadm/l3vsl2/P30000/edgesA/
rm -f -r gadm/l3vsl2/P30000/edgesB/
2022-04-06 13:27:57,879|14164|application_1648870353198_0285|COMMAND|org.apache.spark.deploy.SparkSubmit --master yarn --deploy-mode client --conf spark.driver.memory=12g --conf spark.driver.maxResultSize=2G --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.DCELPartitionerByQuadtree --files /home/acald013/Spark/2.4/conf/log4j.properties --jars /home/acald013/Spark/2.4/jars/geospark-1.2.0.jar,/home/acald013/Spark/2.4/jars/scallop_2.11-3.1.5.jar --num-executors 12 --executor-cores 9 --executor-memory 30g /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar --input1 gadm/l3vsl2/A.wkt --input2 gadm/l3vsl2/B.wkt --quadtree /home/acald013/RIDIR/local_path/gadm/l3vsl2/P30000/quadtree.wkt --boundary /home/acald013/RIDIR/local_path/gadm/l3vsl2/P30000/boundary.wkt --apath gadm/l3vsl2/P30000/edgesA --bpath gadm/l3vsl2/P30000/edgesB --tolerance 1e-3 --save
2022-04-06 13:27:57,879|14164|application_1648870353198_0285|INFO|scale=1000.0
2022-04-06 13:27:57,893|14178|application_1648870353198_0285|TIME|Start
2022-04-06 13:28:18,910|35195|application_1648870353198_0285|INFO|edgesA=68779746
2022-04-06 13:28:37,231|53516|application_1648870353198_0285|INFO|edgesB=64598411
2022-04-06 13:28:37,241|53526|application_1648870353198_0285|TIME|Read
2022-04-06 13:51:58,432|1454717|application_1648870353198_0285|TIME|Saving
