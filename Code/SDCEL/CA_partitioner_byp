#!/bin/bash

PARTITIONS=$1

INPUT1=CA/CaliA.wkt
INPUT2=CA/CaliB.wkt
HDFS_PATH=CA
LOCAL_PATH=$HOME/RIDIR/local_path/CA
SCALE=1e3

HDFS_DIR="$HDFS_PATH/P$PARTITIONS"
echo "Checking $HDFS_DIR ..."
if hdfs dfs -test -e $HDFS_DIR; then
    hdfs dfs -rm -R $HDFS_DIR
    echo "HDFS Directory Deleted"
else
    echo "HDFS Directory does not Exist"
fi
hdfs dfs -mkdir $HDFS_DIR

LOCAL_DIR="$LOCAL_PATH/P$PARTITIONS"
echo "Checking $LOCAL_DIR ..."
[ ! -d $LOCAL_DIR ] && mkdir $LOCAL_DIR

EXECUTORS=12
CORES=9
DMEMORY=12g
EMEMORY=30g
SPARK_JARS=$HOME/Spark/2.4/jars/
JAR=$HOME/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.jar
CLASS="edu.ucr.dblab.sdcel.DCELPartitioner2"
LOG_FILE=$HOME/Spark/2.4/conf/log4j.properties
MASTER=yarn

spark-submit \
    --master $MASTER \
    --jars $HOME/Spark/2.4/jars/geospark-1.2.0.jar,$HOME/Spark/2.4/jars/scallop_2.11-3.1.5.jar \
    --files $LOG_FILE \
    --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:$LOG_FILE \
    --jars ${SPARK_JARS}geospark-1.2.0.jar,${SPARK_JARS}scallop_2.11-3.1.5.jar,${SPARK_JARS}spark-measure_2.11-0.16.jar \
    --master $MASTER --deploy-mode client \
    --num-executors $EXECUTORS --executor-cores $CORES --executor-memory $EMEMORY --driver-memory $DMEMORY \
    --class $CLASS $JAR \
    --input1 $INPUT1 \
    --input2 $INPUT2 \
    --apath $HDFS_DIR/edgesA \
    --bpath $HDFS_DIR/edgesB \
    --qpath $LOCAL_DIR/quadtree.wkt \
    --epath $LOCAL_DIR/boundary.wkt \
    --partitions $PARTITIONS \
    --scale $SCALE
